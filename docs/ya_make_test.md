# Опции тестирования
## Запуск тестов
* Опция `-t` используется в командной строке с целью запуска тестов в системах сборки. Эта опция может иметь несколько уточняющих модификаторов, которые позволяют более гранулярно контролировать, какие именно тесты будут запущены. В зависимости от системы сборки или тестовой инфраструктуры, семантика и реализация этих опций может немного отличаться, но базовая концепция остаётся схожей.

 `-t` — Запустить SMALL тесты
Опция `-t` без дополнительных модификаторов указывает системе выполнить запуск тестов, классифицированных как SMALL. 

SMALL тесты обычно включают в себя легковесные тесты, такие как unit-тесты, которые быстро выполняются и не требуют сложной конфигурации окружения или внешних зависимостей. Запуск исключительно SMALL тестов позволяет быстро получить обратную связь о качестве кода без значительного увеличения времени сборки или тестирования и выполняются не более 1 минуты

`-tt` — Запустить SMALL и MEDIUM тесты
Использование двойного модификатора `-tt` расширяет диапазон запускаемых тестов, добавляя к SMALL тестам ещё и те, что классифицированы как MEDIUM. 

MEDIUM тесты могут включать в себя более тяжёлые или затратные по времени проверки по сравнению с SMALL, например, интеграционные тесты и end-to-end тесты. Такая комбинация позволяет выполнить более широкое тестирование без значительного увеличения времени и ресурсов, хоть и с меньшей скоростью обратной связи, чем при запуске только SMALL тестов. Обычно выполняются не более 10 минут.

 `-ttt` — Запустить SMALL, MEDIUM и LARGE тесты
При добавлении третьего модификатора `-ttt` система будет запускать тесты всех размеров: SMALL, MEDIUM и LARGE.

LARGE тесты — это самые затратные по времени и ресурсам тесты. Их выполнение может занимать значительное время, обычно не более 1 часа, но позволяет максимально полно убедиться в качестве и стабильности продукта.

Строгого соответствия между размером тестов (SMALL, MEDIUM, LARGE) и типом тестов (unit, интеграционные, end to end) нет. В первую очередь нужно ориентироваться на максимальное время исполнения каждого теста.

* Опция `-A` или `--run-all-tests` используется для запуска всех доступных тестов в контексте заданной среды сборки или тестирования. Этот флаг тоже, что и `-ttt`

Основное предназначение этой опции — обеспечить комплексную проверку всего проекта путем выполнения всех заранее подготовленных и доступных тестов.
 
* Опция `-L` или `--list-tests` предоставляет функциональность для вывода списка доступных тестов  без их фактического запуска.

Инструмент полезен для получения обзора тестового покрытия проекта, а также для выборочного запуска конкретных тестов при необходимости.

Опция поддерживает выбор размера тестов, а также все параметры фильтрации.

`ya make -AL --regular-tests devtools/examples/tutorials/python`

После выполнения этой команды пользователь получит на стандартный вывод список тестов, доступных для запуска. 

* Опция `--test-threads=TEST_THREADS` используется в контексте автоматизированного тестирования программного обеспечения для управления количеством потоков, которые могут выполнять тесты параллельно.

Значение `TEST_THREADS`, указываемое в качестве параметра опции, определяет максимальное количество тестов, которые будут запущены одновременно. 

На серверах непрерывной интеграции или локальных машинах с ограниченными аппаратными ресурсами может быть целесообразно ограничить число параллельно выполняемых тестов, чтобы избежать излишней нагрузки на систему и потому по умолчанию в параллель запускается не больше 2х тестов.

* Опция `--fail-fast`  указывает инструменту тестирования прервать процесс выполнения тестов сразу же после обнаружения первого провального (непройденного) теста.

Такой подход используется для экономии времени при разработке и диагностике ошибок. Позволяет разработчикам быстро получить информацию о проблемах в коде, не дожидаясь завершения полного цикла тестирования.

`ya make -A --fail-fast devtools/examples/tutorials/python`

При запуске команда останавливает процесс после первого же провального теста и возвращает статус ошибки. Это значит, что оставшиеся тесты не будут запущены, и команда прекращает свою работу, предоставляя пользователю информацию о проваленном тесте.

* Опция `--add-peerdirs-tests=PEERDIRS_TEST_TYPE` представляет собой настройку в инструментах сборки и тестирования, которая определяет, какие тесты из зависимостей (обозначаются через механизм PEERDIR) следует включать в текущую сессию тестирования. Опция позволяет настроить процесс тестирования, выбирая, в какой степени тесты зависимостей должны учитываться при запуске. 

 Параметры `PEERDIRS_TEST_TYPE`:
 - `none`: Тесты из зависимостей не включаются автоматически. Единственные тесты, которые будут запущены, — это те, что явно указаны в текущей цели тестирования. Это поведение по умолчанию, исходя из предположения, что разработчик хочет запустить только тесты, непосредственно связанные с текущим компонентом или изменениями.
 - `gen`: Включаются только тесты, сгенерированные автоматически (например, для проверки API или контрактов интерфейсов) из зависимостей, указанных через `PEERDIR`. Применяется для проверки того, что изменения в текущем компоненте не нарушили ожидаемые правила использования взаимодействующих с ним компонентов.
 - `all`: Включаются все доступные тесты из зависимостей, создающее самое широкое покрытие. Режим полезен при проведении комплексного тестирования перед важными релизами или для проверки интеграции на уровне всего проекта.

* Опция `--split-factor=TESTING_SPLIT_FACTOR` является конфигурационным параметром,  позволяет управлять степенью параллелизма тестов, переопределяя значение параметра `SPLIT_FACTOR`.
* 
`SPLIT_FACTOR` определяет, как тесты могут быть разбиты на более мелкие группы (или “чанки”) для параллельного выполнения.

`SPLIT_FACTOR` является числовым параметром, который указывает величину, на которую могут быть разделены тесты для исполнения в параллельных потоках или процессах. 

Например, если для набора из 100 тестов установлен `SPLIT_FACTOR` равный 10 (значение по умолчанию), эти тесты могут быть разбиты на 10 групп по 10 тестов для параллельного выполнения.

`ya make -tt --split-factor=5`

Эта команда указывает системе тестирования разбить тесты на части таким образом, чтобы каждая часть могла быть исполнена в 5 параллельных потоков или “чанков”, что может привести к ускорению процесса тестирования за счет параллелизма.

* Опция `--test-prepare` предлагает  механизм для подготовки всего необходимого окружения для проведения тестов без их непосредственного запуска. Эта функциональность особенно полезна в контекстах, где требуется предварительная настройка тестового окружения, включая установку зависимостей, конфигурацию данных и создание вспомогательных сервисов, которые могут быть необходимы для успешного выполнения тестов.

Разработчики могут использовать эту опцию для конфигурации локального тестового окружения перед запуском тестов вручную.

После запуска команды `ya make -A --test-prepare` в директории с тестом будет лежать тестовый бинарный файл.
При обычных запусках, этот бинарный файл запускает тестовое окружение, в которое передается нужные параметры и путь до контекстного файла. 

Использование `--test-prepare` разделяет процесс подготовки тестов и их исполнение, что приводит к повышению управляемости тестового процесса.

* Опция `--no-src-changes` устанавливает директиву системе сборки не производить никаких изменений в исходных файлах проекта, гарантируя, что код и структура проекта останутся неизменными после выполнения операции. 

При выполнении тестов некоторые инструменты могут требовать временных изменений в коде или конфигурациях.
Опция `--no-src-changes` гарантирует, что все инструментальные изменения будут проведены с согласия разработчика и позволяет избежать неожиданных последствий в результате автоматизированных операций с кодом.

## Фильтрация
* Опция `-X` или `--last-failed-tests` позволяет автоматически запустить только те тесты, которые были неудачными (то есть “упали” или “провалились”) при последнем выполнении. Эта возможность значительно упрощает процесс исправления ошибок для разработчиков, позволяя быстро перепроверять решения проблем, не тратя время на повторный запуск уже пройденных успешно тестов.

Когда тесты запускаются с использованием данной опции, система тестирования ищет в своей истории о тестах, которые не прошли в последний раз. Затем, из большого пула тестов, выбираются только те, что были помечены как неудачные, и выполняются снова.

Указание дополнительных фильтров (например с помощью -F) расширяет множество тестов, которое будет запущено. Обычно это требуется, когда вы хотите следить за корректным статусом некоторых тестов, помимо перезапуска упавших от предыдущего прогона.

* Опция `-F=TESTS_FILTERS` или `--test-filter=TESTS_FILTERS` используется для тонкой фильтрации и выборочного запуска тестов в рамках большого тестового набора. Позволяет запускать только определённое подмножество тестов, которые соответствуют конкретным критериям.

Фильтры для тестов задаются в виде строк с использованием [специальных символов и паттернов](https://docs.python.org/3/library/fnmatch.html), таких как астериск (`*`) для обозначения любого количества символов и скобок (`[]`) для указания части имени теста или группы тестов. 

Астериск (`*`) служит шаблоном соответствия любому количеству символов в имени теста. Это позволяет выборочно запускать тесты, имена которых начинаются, заканчиваются или содержат определённые фрагменты.

Примеры: 
 - `-F=*DataTest` запустит все тесты, имена которых завершаются на `DataTest`.
 - `-F=Auth*` запустит все тесты, имена которых начинаются с `Auth`.
 - `-F=*Util*` запустит все тесты, содержащие `Util` в любом месте имени.
Шаблоны взяты в одинарные кавычки для того чтобы shell не развернул фильтр в список файлов, которому может соответствовать шаблон.

Использование скобок (`[]`)

Скобки (`[]`) используются для указания конкретных частей имени теста, которые должны быть соответствующим образом фильтрованы. Это может быть полезно для более точечного указания тестов по их порядковым номерам в рамках определённых групп или для реализации других механизмов выборки.

 Пример:
`-F="[X/Y] chunk"`, `--test-filter="[X/Y] chunk"` — фильтрация тестов по chunk'ам. Внутри `[]` можно использовать `*` для фильтрации.

Применение дать возможность разработчикам или тестировщикам эффективно управлять исполнением только тех тестов, которые актуальны для текущей задачи или для заданного контекста разработки.

* Опции `--style` и `--regular-tests` предоставляют возможность гибко управлять запуском тестов в процессе разработки программного обеспечения, фильтруя тесты на основе их типа: либо тесты стиля кода, либо обычные пользовательские тесты.

 `--style` Запуск тестов стиля кода

Опция `--style` используется для запуска тестов, направленных на проверку соответствия кода установленным стандартам и правилам оформления (стиль, линтинг). Это включает в себя автоматическую проверку форматирования кода, правильности использования синтаксиса и прочих аспектов стиля кодирования. 

При этом, с помощью флага `--strip-skipped-test-deps`, также происходит исключение зависимостей для пропущенных тестов, что оптимизирует процесс выполнения проверки стиля.

Поддерживаемые тесты стиля:
 - `classpath.clash`, `clang_tidy`, `eslint`, `gofmt`, `govet`, `java.style`, `ktlint`, `py2_flake8`, `flake8`, `black`, `ruff` Это инструменты для различных языков программирования (Java, C\+\+, JavaScript, Go, Kotlin, Python и т.д.), каждый из которых предназначен для автоматической проверки соответствия кода заранее определённым стилистическим стандартам и правилам.

`--regular-tests` Запуск пользовательских тестов

В противоположность опции `--style`, флаг `--regular-tests` позволяет запустить только те тесты, которые непосредственно проверяют функционал программного продукта, не затрагивая стилевые проверки. 

Поддерживаемые обычные тесты

`fuzz`, `g_benchmark`, `go_bench`, `go_test`, `gtest`, ` `java`, `jest`, `py2test`, `py3test`, `unittest` и [другие] (https://github.com/mtv2000/yatool/blob/newstyle/docs/ya_make_typetest.md) - представляют собой различные форматы и фреймворки тестирования для проверки функционала на многих языках программирования, включая С\+\+, Go, Java, Python, JavaScript и т.д.

* Опция `--test-size=TEST_SIZE_FILTERS` используется для запуска тестов, которые соответствуют определённым критериям размера. Эта возможность позволяет более точно контролировать объём и длительность тестирования путём выборочного запуска тестов на основе их классификации по размеру.

Размер тестов обычно определяется исходя из их сложности, времени выполнения и требуемых ресурсов:
 - **SMALL**: Тесты, требующие минимум времени и ресурсов для выполнения. Это обычно unit-тесты, которые проверяют функциональность в изоляции от внешних зависимостей.
 - **MEDIUM**: Тесты, занимающие больше времени и ресурсов, чем small-тесты, и могут включать в себя интеграционные тесты, тестирующие взаимодействие между различными частями системы.
 - **LARGE**: Самые затратные по времени и ресурсам тесты, включая системные, функциональные и E2E-тесты, охватывающие множество компонентов или всю систему в целом.

Используя `--test-size=TEST_SIZE_FILTERS`, можно указать, какие именно тесты следует выполнить. Например, параметр может использоваться для запуска только small-тестов в ранних этапах разработки для быстрой проверки изменений, или для выборочного запуска large-тестов перед релизом продукта.

* Опция `--test-type=TEST_TYPE_FILTERS` предназначена для выполнения фильтрации и выборочного запуска тестов в зависимости от их типа. Эта возможность  полезна в сценариях, когда требуется сосредоточить внимание на конкретном аспекте тестирования, например, при необходимости провести только функциональные тесты или только тесты производительности, не затрагивая другие виды тестов. 

Типом теста называется выполнение проверок с использованием одного конкретного инструмента, например, фреймворка pytest для Python или утилиты проверки форматирования кода go fmt для Golang. Полный список типов тестов приведен в [таблице](https://github.com/mtv2000/yatool/blob/newstyle/docs/ya_make_typetest.md)

* Опция `--test-tag=TEST_TAGS_FILTER` предоставляет возможность запускать конкретные тесты, отмеченные определёнными тегами. 

Теги  используются для категоризации и объединения тестов по различным признакам или характеристикам.

--test-tag=TEST_TAGS_FILTER — запускать только сюиты с определёнными тегами. 

Предположим, что в проекте имеются тесты, относящиеся к разработке новой функциональности и отмеченные тегом `feature/new-ui`. Если разработка этой функциональности идёт активно, и требуется часто запускать именно эти тесты, то команда может выглядеть следующим образом: `ya make -A --test-tag=feature/new-ui`
Такая команда запустит только те тесты, которые отмечены тегом `feature/new-ui`, позволяя сосредоточиться именно на текущей задаче.
Перед именами тегов можно использовать `+` для включения тега в фильтр и `-` для исключения. Таким образом `--test-tag tag1+tag2-tag3` запустит все тесты, у которых есть `tag1`, `tag2` и нет `tag3`. Фильтр `--test-tag -tag3` запустит все тесты без тега tag3. Фильтр `--test-tag ya:anytag` запустит все тесты со всеми тегами.

* Опция `--test-filename=TEST_FILES_FILTER` предоставляет возможность фильтрации и запуска тестов на основе имён файлов, содержащих тестовые сценарии.

Параметр актуален только для тестовых фреймворков, таких как `pytest` и `hermione`, которые поддерживают управление выполнением тестов на уровне отдельных файлов, другие тестовые фреймоврки не предоставляют такой информации.

При использовании `--test-filename=TEST_FILES_FILTER`, система тестирования будет искать тесты только среди тех, что расположены в файлах, имена которых соответствуют переданному шаблону, значительно сокращает объём тестов, подлежащих выполнению, и позволяет сфокусироваться на конкретной части кодовой базы или функциональности.

Примеры использования:
Отбор и запуск тестов, находящихся в файлах с определённым префиксом или постфиксом наименования: `ya make -A --test-filename=prefix_.py` 
Запуск тестов из конкретного набора файлов, имена которых точно указаны: `ya make -A --test-filename=test_module1.py`

* Опция `--test-size-timeout=TEST_SIZE_TIMEOUTS` предназначена для настройки продолжительности тайм-аутов для различных категорий тестов в зависимости от их размера.
Тесты классифицируются на несколько категорий (“small”, “medium”, “large”) на основе их ожидаемой продолжительности выполнения и ресурсных требований.
По умолчанию, тайм-аут теста для каждого размера в секундах (small=60, medium=600, large=3600)

Опция `--test-size-timeout` позволяет явно указать максимально допустимое время выполнения для каждой из этих категорий.

Формат значения `TEST_SIZE_TIMEOUTS`  следует шаблону `small=SECONDS, medium=SECONDS, large=SECONDS`, где `SECONDS` задаёт максимально допустимое время выполнения в секундах для тестов соответствующего размера.

Этот пример `–test-size-timeout=small=30,medium=300,large=1800` устанавливает тайм-ауты в 30 секунд для small-тестов, в 300 секунд для medium-тестов и в 1800 секунд для large-тестов.
## Отчет в консоли
Опция `-P` или `--show-passed-tests` предназначена для вывода детальной информации о тестах, которые были успешно пройдены во время текущего запуска тестового набора. 

В стандартном режиме выполнения большинство тестовых фреймворков и инструментов автоматизированного тестирования сконцентрированы на сообщениях о неудачных тестах, поскольку именно они требуют внимания разработчиков для диагностики и исправления обнаруженных проблем. 

В то же время, успешно пройденные тесты часто остаются без дополнительного внимания, и результаты их выполнения выводятся в общем виде, например, в виде общего количества пройденных тестов.

Полный вывод информации о пройденных тестах может быть полезен в ряде сценариев:

\- **Подтверждение ожидаемого поведения**: Детальный отчёт о пройденных тестах помогает разработчикам подтвердить, что внесённые изменения в код не повлияли негативно на уже существующую функциональность, гарантируя отсутствие регрессий.
\- **Документирование результатов тестирования**: Полные результаты тестов могут быть необходимы для дальнейшего анализа или отчётности, особенно в условиях, когда требуется строгая верификация соответствия требованиям качества и безопасности программного обеспечения.

Пример использования

Запуск тестов с отображением результата каждого пройденного теста может выглядеть так:
ya make -P

ya make --show-passed-tests

НЕ НАШЕЛ

Опция `--inline-diff` предназначена для использования в процессе тестирования программного обеспечения, особенно при работе с тестовыми фреймворками, поддерживающими сравнение ожидаемых (expected) и фактических (actual) результатов работы теста.

Эта опция влияет на форматирование и представление различий (diff) между ожидаемыми и фактическими результатами, которые возникают при неудачном прохождении теста. Включение `--inline-diff` обеспечивает более детальное и удобочитаемое отображение этих различий прямо в выводе в терминале.

\- **Более детальное представление различий**: В стандартном режиме вывода результатов некоторые тестовые фреймворки могут предоставлять сокращенное или агрегированное представление информации о различиях между ожидаемыми и фактическими результатами. Опция `--inline-diff` изменяет это поведение, предоставляя построчное сравнение с подсветкой конкретных изменений или различий.

\- **Отключение обрезки комментариев**: В некоторых случаях стандартный вывод различий может включать сокращение или обрезку комментариев и других потенциально важных деталей для упрощения отображения. Использование `--inline-diff` позволяет сохранить эти детали в выводе, что может быть критически важно для понимания контекста ошибок.

\- **Улучшение читаемости**: Благодаря построчному сравнению с подсветкой, визуальное восприятие и анализ различий становятся проще и быстрее. Это особенно актуально при выполнении сложных юнит-тестов и интеграционных тестов, где точное понимание расхождений между ожидаемыми и фактическими значениями является ключом к быстрой отладке и исправлению кода.

 Пример использования

Предположим, что вы используете тестовый фреймворк `pytest` для Python. Включение опции `--inline-diff` в командной строке будет выглядеть следующим образом:

ya make --inline-diff test_example.py

В результате, при возникновении ошибок в тесте `test_example.py`, pytest предоставит построчное сравнение ожидаемых и фактических результатов выполнения теста прямо в выводе терминала, с подробными различиями и сохранившимися комментариями для улучшения понимания контекста проблемы.

Опция `--show-metrics` предназначена для отображения метрик тестирования в консоли в процессе выполнения тестов. 

Метрики тестирования могут включать в себя различную информацию, такую как время выполнения теста, использование памяти, количество запросов к базе данных, производительность API и другие значимые данные, которые помогают оценить не только корректность работы программного обеспечения, но и его эффективность.

При использовании этой опции, после завершения каждого теста или группы тестов, в выводе в консоль будут показаны собранные метрики для них. 

Это позволяет разработчикам и тестировщикам получить дополнительные сведения о производительности и других аспектах работы тестируемого ПО, сразу же выявляя потенциальные узкие места или аномалии.

Чтобы увидеть метрики для успешно пройденных тестов, необходимо также использовать опцию `-P` (`--show-passed-tests`). Это связано с тем, что многие фреймворки и инструменты тестирования по умолчанию выводят в консоль информацию только о проваленных тестах, ограничивая вывод для успешных тестов общим итогом их количества. 

Опция `-P` заставляет инструмент показывать детальную информацию о каждом выполненном тесте, включая успешно пройденные, и, соответственно, когда используется вместе с `--show-metrics`, позволяет видеть собранные метрики и для успешных тестов.

Пример использования:

 ya make -P --show-metrics


Эта команда настроит инструмент тестирования таким образом, чтобы после выполнения каждого теста в консоль выводились детали по пройденным и не пройденным тестам, а также метрики, связанные с каждым из этих тестов.

 Практическая польза:

\- **Диагностика производительности**: Позволяет быстро идентифицировать тесты, которые выполняются слишком долго, потребляют слишком много ресурсов или иным образом влияют на производительность.
\- **Улучшение качества ПО**: Анализ метрик может выявить неоптимальные алгоритмы, избыточные операции, проблемы с эффективностью запросов к базе данных и другие аспекты, подлежащие оптимизации.

Опция `--disable-flake8-migrations` является специфической настройкой, используемой в контексте тестирования и проверки кода с помощью утилиты `flake8`, которая представляет собой популярный инструмент для анализа кода на Python. 

Он помогает идентифицировать ошибки стиля, сложности кода и потенциальные баги, проверяя код на соответствие рекомендациям PEP 8 и другим общепринятым стандартам написания кода.

`flake8` предоставляет возможность исключения или временного отключения определённых проверок (линтов), которые могут быть не всегда релевантны или предпочтительны для конкретных проектов или стадий разработки. Функциональность “миграций `flake8`” (также известная как “включение или отключение проверок `flake8`”) позволяет поэтапно вводить или исключать различные проверки для облегчения процесса адаптации кодовой базы к строгим стандартам.

Опция `--disable-flake8-migrations` используется для явного указания инструмента `flake8` игнорировать все настройки миграций (`flake8` migrations), которые могли быть определены разработчиками или командой проекта для поэтапного введения или отключения конкретных правил проверки. Эта опция “включает все проверки `flake8`”, тем самым применяя полный набор доступных проверок стиля и качества кода без исключения. 

В процессе разработки или при подготовке кода к финальной проверке перед слиянием в основную ветку проекта, разработчик может использовать эту опцию для гарантии того, что весь код полностью соответствует стандартам и рекомендациям:

 ya make --disable-flake8-migrations path/to/module.py

Эта команда выполнит `flake8` проверку для файла `module.py`, применив ко всему коду полный набор правил без учёта ранее заданных миграций.

Сценарии использования:

\- **Проверка перед слиянием**: Применение опции в CI/CD pipelines перед слиянием кода в основную ветку гарантирует, что все изменения полностью соответствуют требованиям к качеству кода.
\- **Локальная проверка**: Разработчики могут использовать эту опцию локально для обеспечения соответствия кода стандартам перед созданием pull request’ов или в процессе рефакторинга.
\- **Унификация стандартов**: В проектах, где требуется строгое соблюдение стилевых и качественных стандартов кода, применение этой опции позволяет обеспечить унификацию проверок на всех этапах разработки.

Опция `--disable-jstyle-migrations` предназначена для использования в среде разработки Java и управляет применением проверок стиля кода. Эта опция нацелена на программистов и команды, работающие над Java-проектами, и служит для управления стратегией внедрения стилевых правил кодирования в процессе разработки. 

Центральная цель данной опции — включение всех доступных проверок стиля для Java кода, игнорируя любые ранее заданные “миграции” или исключения. В контексте стилевых проверок “миграции” часто используются для поэтапного внедрения новых стандартов стиля кодирования или для временного отключения определённых правил в процессе рефакторинга или при внесении значительных изменений в кодовую базу.

Примеры использования

Для включения всех стилевых проверок Java в процессе тестирования или проверки кода, разработчик может добавить эту опцию в командную строку используемого инструмента анализа кода или сборки, например:

 ya make --disable-jstyle-migrations


Потенциальные сценарии использования:

\- **Перед финальным ревью кода**: Проверка кода с включёнными всеми правилами стиля перед слиянием в основную ветку помогает гарантировать соответствие кода общепринятым стандартам и внутренним регламентам проекта.
\- **Локальная проверка**: Разработчики могут использовать эту опцию локально для гарантии соответствия своего кода общим стилистическим правилам перед созданием Pull Request.
\- **Проведение рефакторинга**: В процессе рефакторинга старого кода или интеграции сторонних библиотек, опция позволяет убедиться, что внесённые изменения не противоречат установленным стандартам стиля.


Канонизация тестов - это процесс объединения и стандартизации различных версий тестовых случаев, чтобы устранить возможные дубликаты и противоречия. Она также включает в себя подтверждение того, что каждый тестовый случай соответствует установленным стандартам и правилам создания тестов. Это важный шаг в обеспечении эффективности и эффективности процесса тестирования, позволяющий обеспечить точность и надежность получаемых результатов.


Опция `-Z` или `--canonize-tests` предназначена для канонизации результатов выполнения тестов. Этот процесс важен в сценариях, когда тест возвращает данные, которые должны быть проверены на соответствие определенному эталону (канону). Канонизация позволяет зафиксировать текущие результаты выполнения теста в качестве правильных (эталонных), с которыми в дальнейшем будет сравниваться вывод теста при его повторных запусках.

При первом запуске тестов с этой опцией результаты выполнения тестов, которые предполагается канонизировать, сохраняются в специальном хранилище или на файловой системе в качестве эталонных. Далее, при повторном выполнении этих же тестов с учетом уже существующего канона, система будет сравнивать текущие результаты с эталонными. Если результаты совпадают, тест считается пройденным. В случае расхождения система отметит тест как не пройденный из-за несоответствия эталону.

 Применение `-Z` или `--canonize-tests`

Эта опция часто используется при разработке тестов и при обновлении функционала программы, когда известно, что изменения повлияют на результаты тестов, и эти новые результаты будут корректными. Заранее подготовленные тесты запускают с опцией канонизации для фиксации “правильных” результатов. В последующем, все изменения в коде, влияющие на результаты этих тестов, будут контролироваться на предмет соответствия новому эталону.

Технические аспекты - ПЕРЕПРОВЕРИТЬ

При использовании этой опции может потребоваться указать дополнительные параметры, такие как:

\- `--owner <OWNER>` для указания владельца данных канонизации.
\- `--token <TOKEN>` для авторизации в системе хранения канонизированных данных.

Канонизированные данные могут храниться локально или в облачном хранилище, также возможна регистрация путей к файлам с каноническими данными в системе контроля версий для обеспечения согласованности эталонов между всеми разработчиками и средами выполнения тестов.


Опция `--canon-diff=TEST_DIFF` используется для того, чтобы сравнить канонические данные тестов между различными состояниями кодовой базы. Это позволяет разработчикам и тестировщикам увидеть, как изменения в коде повлияли на результаты тестов, и помогает выявить регрессии или непреднамеренные эффекты от внесенных изменений. Возможные значения для `TEST_DIFF` теперь включают `r<revision>`, `rev1:rev2`, `HEAD`, и `PREV`, что дает гибкие возможности для анализа изменений.

 Допустимые значения для `TEST_DIFF`

1\. **r\<revision\>**: Этот параметр указывает на конкретную ревизию в системе контроля версий. Использование `r` с последующим номером ревизии (`r1234`) позволяет сравнить канонические данные текущей рабочей копии с каноническими данными указанной ревизии.

2\. **rev1:rev2**: Это значение позволяет сравнить канонические данные между двумя конкретными ревизиями. Например, использование `rev1:rev2` с двумя номерами ревизий (`r1234:r2345`) сравнит канонические данные между этими двумя точками в истории проекта.

3\. **HEAD**: Специальное значение `HEAD` относится к самой последней ревизии в текущей ветке кодовой базы. Использование `HEAD` позволяет сравнить текущие канонические данные с данными последнего коммита, что полезно для проверки последних изменений перед их фиксацией.

4\. **PREV**: Значение `PREV` относится к ревизии, предшествующей текущей в рабочей копии. Это позволяет сравнить изменения, внесенные в последнем коммите, с состоянием кода непосредственно перед этим коммитом.
 Примеры использования

\- `--canon-diff=r1234`: Сравнить текущие канонические данные с данными ревизии `r1234`.
\- `--canon-diff=r1234:r2345`: Сравнить канонические данные между ревизиями `r1234` и `r2345`.
\- `--canon-diff=HEAD`: Сравнить текущие канонические данные с данными последней ревизии в текущей ветке.
\- `--canon-diff=PREV`: Сравнить канонические данные текущего состояния с данными состояния перед последним коммитом.


НЕ ОПИСЫВАЕМ РАСПРЕДЕЛЕННАЯ СБОРКА

Опции для экспертов
\--canonize-via-skynet
используйте skynet для загрузки больших канонических данных


Уточнить только ли распределенная сборка, на всякий случай пробуем описать

\--canonize-via-http используйте http для загрузки больших канонических данных


Опция `--canonize-via-http` предназначена для использования в процессе канонизации тестов, когда необходимо загрузить большие объемы канонических данных. Эта опция указывает системе, что для загрузки этих данных следует использовать протокол HTTP.

 Это особенно актуально в средах, где прямой доступ к файловой системе или другим протоколам загрузки (например, FTP или SMB) ограничен или не предпочтителен по причинам безопасности, стабильности или скорости передачи данных.


При выполнении процесса канонизации с использованием этой опции, система тестирования генерирует HTTP запросы для загрузки канонических данных из указанного HTTP источника. Это может быть внутренний веб-сервер компании или облачное хранилище, доступное через HTTP.

 **Универсальность**: HTTP является широко поддерживаемым и универсальным протоколом, который позволяет загружать данные из различных источников без необходимости настройки специфического программного обеспечения.

Предположим, что у вас есть тест, который требует загрузки большого объема данных из облачного хранилища, доступного через HTTP. Вы можете запустить процесс канонизации следующим образом:
 ya make -t --canonize-tests --canonize-via-http

При этом система тестирования будет использовать HTTP запросы для загрузки необходимых канонических данных, обеспечивая эффективную и безопасную передачу данных.

Использование HTTP как транспортного протокола упрощает интеграцию с различными источниками данных и обеспечивает высокую скорость и безопасность передачи данных.


ОТЛАДКА

Опция `--pdb` используется в контексте выполнения тестов, написанных на Python, и предназначена для автоматического запуска отладчика Python (pdb - Python Debugger) в случае возникновения ошибок во время выполнения теста. Это позволяет разработчикам немедленно перейти к отладке проблемы, не прерывая процесс тестирования.

Когда тесты запускаются с использованием фреймворков, таких как `pytest`, опция `--pdb` может быть передана в качестве аргумента командной строки. Если во время выполнения тестов возникает исключение или другая ошибка, выполнение тестов приостанавливается, и `pdb` автоматически активируется, предоставляя интерактивную сессию отладки прямо на месте возникновения ошибки.

Преимущества использования `--pdb`

1\. **Немедленная отладка**: Эта опция позволяет разработчикам сразу же перейти к отладке проблемы, минимизируя время, необходимое для поиска и исправления ошибок в коде.
2\. **Интерактивная среда**: `pdb` предоставляет интерактивную среду отладки, где можно осмотреть текущее состояние стека вызовов, переменные и выполнять код в контексте, где произошла ошибка.
3\. **Улучшение качества кода**: Быстрая отладка и исправление ошибок способствует повышению общего качества кода и сокращению времени на тестирование и отладку.
4\. **Гибкость**: Опция `--pdb` может использоваться как для запуска всех тестов, так и для запуска конкретного теста, что делает её гибким инструментом в процессе разработки.

Пример использования

Допустим, вы используете `pytest` для выполнения тестов. Для активации `pdb` при возникновении ошибок, добавьте `--pdb` к команде запуска:

ya make --pdb my_test_file.py

Если во время выполнения `my_test_file.py` произойдет ошибка, выполнение тестов остановится, и вы автоматически войдете в интерактивную сессию `pdb`. В этой сессии можно будет использовать команды `pdb`, такие как `list` для просмотра кода, `where` для просмотра стека вызовов, `next` и `step` для шагов выполнения кода, и `print` для вывода значений переменных.


Опция `--gdb` предоставляется в контексте запуска C\+\+ юнит-тестов и позволяет автоматически запустить тесты в среде GNU Debugger (GDB), когда это необходимо. Эта функциональность особенно полезна для разработчиков, которым нужно детально исследовать причины сбоев и ошибок в C\+\+ коде во время выполнения тестов.

При запуске юнит-тестов с использованием фреймворков, таких как Google Test (gtest) или собственных тестовых фреймворков, опция `--gdb` может быть указана в командной строке. Если в процессе выполнения тестов возникает ошибка, которая приводит к аварийному завершению программы (например, segmentation fault) или к другим условиям, требующим отладки, выполнение теста приостанавливается, и активируется GDB с загруженным контекстом выполнения теста на момент сбоя.

Преимущества использования `--gdb`

1\. **Точная отладка на месте сбоя**: Отладчик GDB позволяет разработчикам исследовать состояние приложения в точке сбоя, просмотреть содержимое переменных, стек вызовов и выполнить другие действия для диагностики проблемы.
2\. **Интерактивное управление выполнением**: В GDB можно управлять выполнением программы, выполнять код пошагово, устанавливать точки останова и условные остановы, что делает процесс отладки гибким и мощным.
3\. **Автоматическая активация**: Не требуется вручную запускать GDB и настраивать окружение для воспроизведения сбоя. Опция `--gdb` автоматически переводит разработчика в среду отладчика при возникновении ошибки.
4\. **Ускорение процесса разработки**: Быстрый доступ к отладчику ускоряет процесс идентификации и устранения ошибок, что способствует повышению общей продуктивности разработки.

ТУТ ВСЕ ДОРАБОТАТЬ И ПЕРЕПРОВЕРИТЬ

Допустим, вы разрабатываете тесты для своего C\+\+ проекта с использованием фреймворка Google Test и хотите воспользоваться отладчиком GDB для анализа сбоев. Вы можете запустить свои тесты следующим образом:

 ya make --gdb


В этом случае, если во время выполнения тестов возникает сбой, вы будете автоматически перенаправлены в GDB с активным контекстом сбоя.

Опция `--gdb` представляет собой инструмент для разработчиков C\+\+, позволяя эффективно и быстро диагностировать и исправлять ошибки в коде с помощью GNU Debugger. 


Опция `--dlv` используется в контексте запуска юнит-тестов для языка программирования Go и позволяет автоматически запустить тесты в отладчике Delve (dlv). Delve является отладчиком для Go программ, предоставляющим возможности для пошагового выполнения кода, просмотра состояния переменных, управления точками останова и других действий, необходимых для детального анализа выполнения программы и поиска ошибок.

 Как работает `--dlv`

При запуске юнит-тестов Go с использованием тестовых фреймворков или стандартной команды `ya make -t`, добавление опции `--dlv` к команде запуска тестов приводит к тому, что вместо обычного выполнения тестов запускается отладчик Delve с загруженными тестами. Это позволяет разработчикам в интерактивном режиме исследовать выполнение тестов и кода, который они тестируют, непосредственно в среде отладчика.

Преимущества использования `--dlv`

1\. **Интерактивная отладка**: Delve предоставляет мощные возможности для интерактивной отладки Go программ, включая юнит-тесты. Это может значительно облегчить поиск и исправление сложных ошибок и багов.
2\. **Глубокий анализ**: С помощью Delve можно получить глубокое понимание о том, как работает ваш код, следить за изменениями состояния переменных в реальном времени, а также понять причины паник и других неожиданных ситуаций в программе.
3\. **Управление выполнением**: Отладчик позволяет управлять выполнением программы, останавливаться на точках останова, выполнять код пошагово, что делает процесс отладки гибким и удобным.
4\. **Безопасность**: Delve позволяет проводить отладку без необходимости вносить изменения в исходный код или использовать вывод отладочной информации напрямую в коде, что повышает безопасность и упрощает процесс разработки.

Пример использования???

Чтобы использовать `--dlv` для запуска тестов в Delve, необходимо иметь установленный Delve. Команда запуска может выглядеть следующим образом:

Отладчик Delve делает процесс поиска и устранения ошибок более эффективным и понятным, что способствует улучшению качества кода и ускорению разработки.


Опция `--test-debug` предназначена для использования в процессе тестирования программного обеспечения, обеспечивая разработчикам расширенные возможности для отладки тестов. Эта опция включает ряд параметров, оптимизирующих процесс запуска тестов для удобства отладки, и предоставляет дополнительную информацию, полезную при диагностике проблем.

Как работает `--test-debug`

При использовании опции `--test-debug`, система тестирования автоматически применяет несколько дополнительных параметров к процессу выполнения тестов:

1\. **–test-threads=1**: Устанавливает количество потоков (threads) для выполнения тестов равным 1. Это означает, что все тесты будут выполняться последовательно, один за другим. Последовательное выполнение упрощает процесс отладки, поскольку исключает возможные проблемы, связанные с параллельным выполнением тестов, такие как состояние гонки (race condition).

2\. **–test-disable-timeout**: Отключает тайм-ауты для тестов. Это позволяет избежать автоматического прерывания теста по истечении времени выполнения, что важно при отладке, когда разработчику может потребоваться больше времени для анализа состояния программы или выполнения дополнительных действий в отладчике.

3\. **–retest**: Принудительно повторно выполняет все тесты, даже если они не были изменены. Это гарантирует, что при каждом использовании `--test-debug` тесты будут запущены, независимо от результатов предыдущих запусков.

4\. **–test-stderr**: Перенаправляет стандартный поток ошибок (stderr) тестов в стандартный вывод (stdout) или делает его видимым в выводе тестов. Это обеспечивает, что все сообщения об ошибках, предупреждения и другая диагностическая информация, выводимая тестами, будут непосредственно доступны для анализа.

Помимо вышеупомянутых настроек, опция `--test-debug` также печатает идентификатор процесса (PID) каждого запущенного теста. Эта информация может быть полезна для прикрепления отладчика к конкретному процессу теста для детального анализа его выполнения в реальном времени.

Пример использования

Предположим, вы разрабатываете набор юнит-тестов и сталкиваетесь с проблемой, которую сложно диагностировать. Запуск тестов с опцией `--test-debug` может выглядеть так:

ya make `--test-debug`

После запуска вы увидите PID запущенного теста и сможете прикрепить к нему отладчик, если это необходимо, а также воспользоваться другими удобствами режима отладки.


Опция `--dlv-args=DLV_ARGS` предназначена для использования в контексте запуска Go юнит-тестов в отладчике Delve (dlv) и позволяет передать дополнительные аргументы командной строки непосредственно в Delve. Эта опция становится актуальной только в случае, если при запуске тестов также указана опция `--dlv`, которая инициирует запуск тестов в среде отладчика Delve.

Как работает `--dlv-args=DLV_ARGS`

Когда вы используете `--dlv` для запуска тестов в Delve, `--dlv-args=DLV_ARGS` позволяет уточнить поведение Delve, добавив специфические для отладчика параметры. Это может включать в себя настройки логирования, управления сессией отладки, опции для точек останова и другие возможности Delve, которые могут быть полезны для конкретной задачи отладки.

Преимущества использования `--dlv-args=DLV_ARGS`

1\. **Настройка сессии отладки**: Позволяет настроить сессию отладки под конкретные нужды разработки, например, активировать дополнительное логирование или настроить автоматическое выполнение команд при старте.
2\. **Гибкость**: Разработчики могут использовать все возможности Delve для более эффективной отладки, не ограничиваясь стандартным набором функций.
3\. **Улучшенная диагностика**: Дополнительные параметры могут помочь получить больше информации о состоянии программы или проблеме, что ускоряет процесс нахождения и исправления ошибок.

Пример использования

Предположим, вы хотите запустить юнит-тесты в Delve с опцией логирования и автоматически выполнить команду `list`, чтобы сразу увидеть контекст кода в точке останова. Для этого вы можете использовать следующую команду:

ya make 



Опция `--test-retries=TESTS_RETRIES` предоставляет возможность автоматически повторять выполнение тестов, которые завершились неудачно, указанное количество раз (по умолчанию: 1). Эта функциональность чрезвычайно полезна в ситуациях, когда тесты могут иногда завершаться сбоем из-за нестабильных условий окружающей среды, временных проблем с сетью, ресурсами системы или другими внешними факторами, не связанными напрямую с логикой тестируемого программного обеспечения.

Как работает `--test-retries=TESTS_RETRIES`

Когда вы запускаете тесты с использованием этой опции, система тестирования выполнит все указанные тесты и отслеживает те из них, которые завершились неудачно. Если какой-либо тест не прошел успешно, система автоматически попытается повторить его выполнение. Количество повторений для каждого неудачного теста задается значением `TESTS_RETRIES`. Например, если указано `--test-retries=2`, то каждый тест, который не прошел, будет автоматически повторен до двух раз в дополнение к его первоначальному запуску.

Преимущества использования `--test-retries=TESTS_RETRIES`

1\. **Снижение ложных срабатываний**: Повторные запуски помогают исключить случайные сбои, уменьшая количество ложноположительных результатов тестирования.
2\. **Увеличение надежности тестов**: В условиях, когда тесты могут временно проваливаться из-за внешних факторов, автоматические повторы помогают обеспечить, что результаты тестирования более точно отражают реальное состояние кода.
3\. **Экономия времени разработчиков**: Автоматизация процесса повторного запуска тестов снижает необходимость в ручном перезапуске, позволяя разработчикам сосредоточиться на решении действительно важных задач.

 Пример использования

Предположим, вы работаете над проектом и хотите автоматически повторять неудачные тесты до трех раз в случае их сбоя. Для этого вы можете использовать следующую команду:

.ya make --test-retries=3

Эта команда запустит тестовый набор и, в случае неудачи любого теста, попытается повторить его выполнение до трех раз. Если тест проходит успешно в одной из попыток, он считается пройденным и система переходит к следующему тесту.


Опция `--test-stderr` используется при запуске автоматизированных тестов и предназначена для того, чтобы выводить стандартный поток ошибок (stderr) тестов непосредственно в консоль в реальном времени. Это позволяет разработчикам и тестировщикам наблюдать за всеми сообщениями об ошибках, предупреждениями и другой важной диагностической информацией, генерируемой тестами, без необходимости ожидания завершения всего набора тестов или изучения лог-файлов после их выполнения.

В стандартной ситуации без использования специальных опций, стандартный поток ошибок (stderr) теста может быть перенаправлен в файл лога или обработан иначе в зависимости от настроек среды тестирования. Это означает, что во время выполнения тестов разработчики не видят сообщения об ошибках в реальном времени, что может затруднять быстрое обнаружение и диагностику проблем.

При использовании опции `--test-stderr`, stderr тестов перенаправляется непосредственно в консоль (или терминал), из которой были запущены тесты. Это обеспечивает мгновенный доступ к диагностической информации, что особенно полезно при разработке и отладке тестов.

Преимущества использования `--test-stderr`

1\. **Немедленная обратная связь**: Позволяет разработчикам и тестировщикам получать немедленную обратную связь об ошибках и предупреждениях, генерируемых их тестами, что ускоряет процесс исправления ошибок.
2\. **Упрощение диагностики**: Наличие доступа к stderr в реальном времени облегчает диагностику сложных проблем, которые могут быть неочевидны при анализе только итоговых результатов тестов.
3\. **Эффективность отладки**: В случае сбоев, которые трудно воспроизводить, наблюдение за потоком stderr в реальном времени может дать ключевые подсказки для выявления причин проблемы.
4\. **Удобство использования**: Не требует от разработчиков дополнительных действий по поиску и анализу лог-файлов, все необходимые данные представлены непосредственно перед их глазами.

Пример использования

Предположим, вы запускаете набор юнит-тестов для вашего приложения и хотите увидеть все сообщения об ошибках в консоли во время выполнения тестов. Для этого вы можете использовать следующую команду (здесь пример для фреймворка, поддерживающего данную опцию непосредственно или через соответствующие настройки среды тестирования):

ya make -t --test-stderr


Эта команда активирует вывод stderr тестов в консоль, позволяя вам наблюдать за возможными сообщениями об ошибках в режиме реального времени.


Опция `--test-stdout` предназначена для использования в процессе запуска автоматизированных тестов и позволяет выводить стандартный поток вывода (stdout) тестов непосредственно в консоль в реальном времени. Это дает возможность разработчикам и тестировщикам наблюдать за всеми сообщениями, логами и другой информацией, генерируемой тестами, сразу же во время их выполнения.

Когда тесты запускаются с использованием этой опции, система тестирования перенаправляет все, что тесты пишут в стандартный поток вывода (stdout), непосредственно в консоль или терминал, из которого были запущены тесты. Это позволяет разработчикам в режиме реального времени видеть все сообщения, добавленные в stdout, включая логи выполнения, результаты проверок, дополнительную диагностическую информацию и так далее.

Преимущества использования `--test-stdout`

1\. **Немедленная обратная связь**: Эта опция обеспечивает мгновенный доступ к выводу тестов, позволяя разработчикам быстро получать обратную связь и упрощая процесс идентификации и устранения ошибок.
2\. **Упрощение диагностики**: Наличие информации о выполнении теста в реальном времени может существенно облегчить диагностику сложных проблем, зачастую делая ненужным последующий анализ лог-файлов.
3\. **Эффективность отладки**: При отладке тестов, особенно в случаях, когда поведение теста зависит от множества условий, наблюдение за stdout в реальном времени может предоставить ценные подсказки и сократить время на отладку.
4\. **Удобство использования**: Опция устраняет необходимость в дополнительных шагах для просмотра результатов тестов, таких как поиск и открытие лог-файлов, предоставляя всю необходимую информацию непосредственно в процессе выполнения тестов.

Пример использования

Допустим, вы работаете над проектом и хотите запустить юнит-тесты, при этом видя результаты выполнения тестов (вывод тестов) в консоли в реальном времени. Использование опции `--test-stdout` может выглядеть так:

ya make --test-stdout - НАЙТИ НОРМАЛЬНЫЙ ПРИМЕР


Эта команда заставит тестовую систему выводить в консоль все сообщения из stdout каждого теста, позволяя вам отслеживать ход выполнения тестов и немедленно реагировать на возникающие проблемы или ошибки.


Опция `--test-disable-timeout` представляет собой команду, используемую при запуске автоматизированных тестов, и позволяет отключить механизм тайм-аута для тестов. Это означает, что тесты не будут автоматически прерваны системой тестирования, если они превышают определенное время выполнения. Опция особенно полезна в процессе разработки и отладки, когда необходимо глубоко исследовать проблему, из-за которой тест может выполняться дольше обычного.

 Как работает `--test-disable-timeout`

В обычных условиях, системы автоматизированного тестирования имеют настройку тайм-аута, чтобы ограничить максимальное время выполнения каждого теста. Это предотвращает “зависание” тестов и обеспечивает более эффективное использование ресурсов тестовой среды. Тайм-аут может быть задан глобально для всего набора тестов или индивидуально для каждого теста.

При использовании опции `--test-disable-timeout`, механизм тайм-аута отключается, и тесты могут выполняться неограниченное время. Это позволяет разработчикам выполнять тесты в условиях, когда требуется дополнительное время для выполнения, например, при подключении к отладчику или проведении масштабного анализа производительности.

Ограничения и совместимость

Опция `--test-disable-timeout` предназначена для использования в локальной среде разработки и не рекомендуется к использованию в среде непрерывной интеграции (CI) или при распределенном выполнении тестов (`--dist`), поскольку может привести к замедлению процесса тестирования или его “зависанию”. Также эта опция несовместима с опцией `--cache-tests`, которая предполагает кеширование результатов тестов для ускорения последующих запусков.

Пример использования

Предположим, что вы работаете над сложным юнит-тестом, который время от времени “зависает” из-за специфической проблемы, и вам необходимо подключиться к процессу теста с помощью отладчика для диагностики проблемы. В этом случае, вы можете запустить тесты с отключенным тайм-аутом:

 --test-disable-timeout
 
 
 Опция `--test-binary-args=TEST_BINARY_ARGS` используется в контексте запуска автоматизированных тестов, обеспечивая возможность передачи произвольных аргументов командной строки непосредственно в исполняемый файл теста (тестовый бинарник). Это позволяет настраивать поведение тестов на более глубоком уровне, используя механизмы, предусмотренные в самом тестовом приложении.

Как работает `--test-binary-args=TEST_BINARY_ARGS`

При запуске тестов с использованием этой опции, указанные аргументы (`TEST_BINARY_ARGS`) будут переданы в исполняемый файл теста как аргументы командной строки. Тестовое приложение может затем обрабатывать эти аргументы согласно своей внутренней логике, позволяя влиять на различные аспекты его выполнения.

Преимущества использования `--test-binary-args=TEST_BINARY_ARGS`

1\. **Гибкость настройки**: Эта опция предоставляет дополнительную гибкость при настройке тестов, позволяя изменять их поведение без необходимости изменения кода тестов или использования внешних конфигурационных файлов.
2\. **Удобство разработки и отладки**: Разработчики могут использовать различные аргументы для отладки тестов, активации дополнительного логирования, выборочного запуска подмножества тестов и т.д., что делает процесс разработки более удобным и эффективным.
3\. **Поддержка параметризации**: Аргументы командной строки могут использоваться для параметризации тестов, например, для запуска тестов с различными настройками или в различных тестовых сценариях.
4\. **Интеграция с внешними инструментами**: Опция может быть полезна для интеграции тестов с внешними инструментами и фреймворками, которые требуют передачи специфических параметров в тестовые приложения.

 Пример использования

Предположим, что ваше тестовое приложение поддерживает аргумент командной строки `--config`, который позволяет указать путь к файлу конфигурации. Вы хотите запустить тесты с использованием конкретного конфигурационного файла. Для этого вы можете использовать следующую команду:

 --test-binary-args=“–config=/path/to/config/file”



В этом примере, аргумент `--config=/path/to/config/file` будет передан непосредственно в исполняемый файл теста, позволяя тестам использовать указанный файл конфигурации.


Опция `--dump-test-environment` предназначена для использования в процессе автоматизированного тестирования программного обеспечения. Эта опция позволяет получить детальный снимок содержимого корня сборки теста, организованного в формате дерева, и записать эту информацию в файл `run_test.log` перед фактическим выполнением обертки теста. Это особенно полезно для диагностики и отладки, когда необходимо понимание того, какие файлы и ресурсы доступны в среде выполнения теста.

При запуске тестов с этой опцией, система тестирования автоматически генерирует представление файловой структуры корневого каталога сборки теста в виде дерева. Это представление включает в себя все файлы, директории и их вложенные элементы, доступные в момент запуска теста. Сгенерированная информация затем записывается в файл `run_test.log`, который можно использовать для последующего анализа.

 Преимущества использования `--dump-test-environment`

1\. **Детальная диагностика**: Эта опция обеспечивает детальное понимание того, какие файлы и ресурсы были доступны в среде выполнения теста, что может быть критически важно для диагностики сложных проблем и ошибок.
2\. **Упрощение отладки**: Предоставляя полный снимок среды тестирования, `--dump-test-environment` упрощает процесс отладки, позволяя разработчикам быстро идентифицировать отсутствующие или неправильно настроенные ресурсы.
3\. **Воспроизводимость**: Запись состояния среды тестирования в лог-файл помогает обеспечить воспроизводимость проблем, позволяя другим разработчикам точно видеть, в каком контексте возникла ошибка.
4\. **Анализ изменений среды**: Сравнение логов из разных запусков тестов может помочь выявить изменения в среде тестирования, которые могли повлиять на результаты тестов.

Пример использования

Допустим, вы столкнулись с проблемой, когда тест неожиданно не проходит из-за отсутствия определенного файла конфигурации в среде выполнения. Чтобы диагностировать эту проблему, вы можете запустить тесты с опцией `--dump-test-environment`, чтобы получить полное представление о содержимом корня сборки:

 --dump-test-environment

После выполнения тестов вы можете открыть файл `run_test.log` и изучить структуру директорий и файлов, доступных во время тестирования. Это поможет вам определить, отсутствует ли необходимый файл конфигурации или возможно он расположен в неправильном месте.


Опция `--no-random-ports` используется в контексте запуска сетевых тестов, которым требуются конкретные порты для их выполнения. Эта опция указывает системе тестирования использовать заранее определенные или “запрошенные” порты, указанные в тестовом коде или конфигурации, вместо того чтобы автоматически выбирать случайные порты во время выполнения тестов. 

\### Как работает `--no-random-ports`

Во многих средах тестирования, особенно при работе с сетевыми приложениями, тесты могут требовать открытия сетевых соединений на определенных портах. По умолчанию, системы тестирования часто используют механизмы для автоматического выбора случайных портов, чтобы избежать конфликтов и проблем с параллельным выполнением тестов. Однако, в некоторых случаях, например, при необходимости интеграции с внешними системами или специфическими настройками сетевого окружения, может потребоваться использование конкретных портов.

Использование опции `--no-random-ports` позволяет обойти стандартное поведение и явно указать системе тестирования использовать порты, заданные разработчиком. Это дает разработчикам контроль над сетевыми настройками тестовой среды и упрощает интеграцию тестов с определенными сетевыми условиями или конфигурациями.

Преимущества использования `--no-random-ports`

1\. **Контроль над сетевым окружением**: Позволяет разработчикам точно настраивать сетевое окружение тестов, что особенно важно при работе с интеграционными тестами или тестами, требующими взаимодействия с определенными сетевыми службами.
2\. **Упрощение конфигурации**: Избавляет от необходимости дополнительной настройки сетевых компонентов или внешних систем для работы с случайными портами, упрощая процесс настройки тестовой среды.
3\. **Совместимость с внешними системами**: Облегчает интеграцию с внешними системами и службами, которые требуют подключения к определенным портам.

Пример использования

Предположим, что вы разрабатываете набор интеграционных тестов для веб-сервера, который должен запускаться на определенном порте (например, порт 8080) для интеграции с другими сервисами в вашей инфраструктуре. В этом случае, вы можете запустить тесты с опцией `--no-random-ports`, чтобы гарантировать, что тестовый веб-сервер будет использовать именно этот порт:

 --no-random-ports

 актуально для интеграционных тестов и тестов, зависящих от взаимодействия с определенными сетевыми службами или внешними системами.
 
 
 Опция `--disable-test-graceful-shutdown` используется в контексте автоматизированного тестирования программного обеспечения для управления поведением тестового процесса в случае возникновения тайм-аута. Эта опция указывает системе тестирования, что в случае превышения заданного времени выполнения теста, тестовый процесс (узел теста) должен быть немедленно прекращен (“убит”) без попытки его “мягкой” остановки или корректного завершения.

Во многих системах тестирования, когда тест превышает заданное время выполнения (тайм-аут), система пытается корректно завершить тестовый процесс, давая ему возможность освободить занятые ресурсы, закрыть открытые соединения и корректно завершить работу. Это называется “мягким” завершением работы или “graceful shutdown”. Однако, в некоторых случаях, такое поведение может быть не предпочтительным или неэффективным, например, если процесс теста “завис” и не реагирует на попытки его корректного завершения.

Использование опции `--disable-test-graceful-shutdown` отключает механизм “мягкого” завершения работы тестового процесса. Вместо этого, в случае возникновения тайм-аута, система тестирования немедленно отправляет сигнал на принудительное завершение процесса, что обычно приводит к его мгновенному “убийству”.

 Преимущества использования `--disable-test-graceful-shutdown`

1\. **Быстрое освобождение ресурсов**: Эта опция обеспечивает более быстрое освобождение системных ресурсов, которые могли быть заняты “зависшим” тестовым процессом.
2\. **Упрощение диагностики**: В случаях, когда процесс теста “зависает” и не завершается корректно, принудительное завершение может упростить процесс диагностики, предотвращая дополнительные ожидания или вмешательства.
3\. **Повышение надежности тестирования**: Опция может помочь повысить общую надежность процесса тестирования, минимизируя влияние “зависших” тестов на общий процесс и другие тесты.

Пример использования

Предположим, вы запускаете комплексное тестирование вашего приложения и сталкиваетесь с проблемой “зависания” некоторых тестов, что затрудняет автоматизацию процесса. Для решения этой проблемы, вы можете запустить тесты с использованием опции `--disable-test-graceful-shutdown`, чтобы обеспечить немедленное прерывание “зависших” тестов:

 --disable-test-graceful-shutdown


Опция `--disable-test-graceful-shutdown` представляет собой полезный инструмент в арсенале разработчика для управления поведением тестов в случае возникновения тайм-аутов, особенно при работе с тестами, склонными к “зависанию”. Она позволяет повысить эффективность и надежность процесса тестирования за счет более решительного управления ресурсами и временем выполнения тестов.


## Среда выполнения


Опция `--test-param=TEST_PARAMS` предоставляет возможность передачи произвольных параметров непосредственно в тесты из командной строки. Эта функциональность является крайне полезной, когда необходимо настроить поведение тестов без изменения исходного кода, а также для параметризации тестов с целью их более гибкого использования.

При использовании этой опции, вы можете передать один или несколько параметров в формате `name=val`, где `name` — это имя параметра, а `val` — его значение. Эти параметры будут доступны внутри тестов, позволяя изменять их поведение в зависимости от переданных значений. Система тестирования обеспечивает передачу этих параметров в тестовое окружение, где они могут быть извлечены и использованы в логике тестов.

Преимущества использования `--test-param=TEST_PARAMS`

1\. **Гибкость**: Позволяет изменять условия выполнения тестов без необходимости изменения кода, делая тесты более универсальными и повторно используемыми.
2\. **Параметризация**: Упрощает запуск одного и того же теста с различными параметрами, что особенно полезно для тестирования разнообразных сценариев.
3\. **Упрощение конфигурации**: Облегчает конфигурацию тестов, особенно при их запуске в различных средах или с разными настройками.
4\. **Динамическая настройка**: Позволяет динамически настраивать тесты в зависимости от внешних условий или параметров сборки.

Пример использования

Предположим, что вы разрабатываете набор тестов, который должен работать с различными уровнями логирования. Вместо того чтобы создавать отдельный тест для каждого уровня логирования, вы можете использовать один тест и передавать уровень логирования как параметр:

 --test-param=log_level=DEBUG 

\--test-param=log_level=INFO


Внутри теста вы можете извлечь этот параметр и настроить уровень логирования в соответствии с переданным значением.

 Извлечение параметров в тестах

Механизм извлечения параметров зависит от используемой тестовой среды или фреймворка. В некоторых случаях может потребоваться дополнительная логика для разбора аргументов командной строки или использования специальных API для доступа к параметрам.


Опция `--autocheck-mode` предназначена для запуска тестов в локальной среде с набором ограничений, характерных для среды autocheck, что является системой автоматизированного тестирования, используемой, например, в процессах непрерывной интеграции (CI). Этот режим позволяет разработчикам испытывать тесты в условиях, максимально приближенных к продакшн-среде тестирования, не покидая локальной разработческой среды.

Как работает `--autocheck-mode`

Включение `--autocheck-mode` автоматически активирует несколько ключевых ограничений и настроек:

1\. **–private-ram-drive**: Создает изолированный RAM-диск для каждого теста, что позволяет избежать взаимного влияния тестов друг на друга из-за файловой системы и гарантирует, что файлы, созданные или измененные одним тестом, не будут видны или доступны другим тестам. Это способствует повышению изоляции и надежности тестов.

2\. **–private-net-ns**: Использует изолированное сетевое пространство имен для каждого теста, обеспечивая, таким образом, что сетевые операции, выполняемые в рамках одного теста, не влияют на другие тесты. Это особенно важно для тестов, которые предполагают взаимодействие с сетью или определенные сетевые настройки.

Преимущества использования `--autocheck-mode`

1\. **Повышение изоляции тестов**: Благодаря созданию изолированных сред для файловой системы и сети, тесты становятся более независимыми друг от друга, что повышает точность и надежность результатов тестирования.

2\. **Улучшение воспроизводимости**: Тесты, успешно выполненные в режиме `--autocheck-mode`, демонстрируют более высокую степень воспроизводимости результатов в различных средах, включая CI.

3\. **Упрощение отладки**: Разработчики могут легче диагностировать проблемы, возникающие в CI, запуская тесты локально в условиях, максимально приближенных к условиям CI.

 Пример использования

Для запуска тестов в режиме, максимально приближенном к autocheck, разработчик может использовать следующую команду:

 --autocheck-mode


Эта команда активирует все необходимые ограничения и настройки для имитации среды autocheck, позволяя разработчику локально тестировать код в условиях, аналогичных продакшн-среде тестирования.


Опция `--private-ram-drive` представляет собой команду для систем тестирования, которая призвана улучшить изоляцию и производительность тестов, создавая для каждого тестового узла частный RAM-диск. Эта опция особенно актуальна в средах, где тесты требуют интенсивной работы с файловой системой, и обеспечивает более высокую скорость доступа к данным по сравнению с обычными дисками, тем самым ускоряя выполнение тестов.

`--private-ram-drive`

При активации этой опции система тестирования автоматически создает виртуальный диск в оперативной памяти (RAM-диск) для каждого узла тестирования, который его запрашивает. Все операции чтения и записи в рамках теста производятся на этом RAM-диске. Поскольку оперативная память обеспечивает значительно более высокую скорость чтения и записи данных по сравнению с традиционными жесткими дисками или даже SSD, использование RAM-диска может существенно сократить время, необходимое для выполнения операций ввода-вывода, и, как следствие, ускорить выполнение тестов.

Преимущества использования `--private-ram-drive`

1\. **Улучшение производительности тестов**: Применение RAM-диска для операций ввода-вывода может значительно ускорить выполнение тестов, особенно тех, которые интенсивно работают с файловой системой.
2\. **Изоляция тестов**: Создание отдельного RAM-диска для каждого узла тестирования обеспечивает высокий уровень изоляции между тестами, предотвращая возможные конфликты и взаимное влияние тестов друг на друга через файловую систему.
3\. **Безопасность данных**: Данные на RAM-диске хранятся только во время выполнения теста и автоматически удаляются после его завершения, что способствует безопасности тестовых данных и предотвращает утечку информации.
4\. **Упрощение очистки**: Не требуется дополнительных шагов для очистки данных после выполнения тестов, поскольку RAM-диск автоматически очищается при его размонтировании или завершении работы тестового процесса.

Пример использования

Предположим, что вы запускаете комплексные интеграционные тесты для вашего приложения, которые требуют частого чтения и записи временных файлов. Использование опции `--private-ram-drive` может быть организовано следующим образом:

\--private-ram-drive

Эта команда обеспечит создание отдельного RAM-диска для файловой системы каждого тестового узла, улучшая производительность тестов и обеспечивая их изоляцию.

Опция `--private-ram-drive` является инструментом для оптимизации процесса тестирования, предлагая решение для ускорения выполнения тестов и обеспечения их надежности за счет использования виртуальных дисков в оперативной памяти.


Опция `--private-net-ns` предназначена для создания изолированного сетевого пространства имен (network namespace) для каждого запускаемого теста. Это позволяет обеспечить высокий уровень изоляции сетевого окружения между различными тестами, выполняемыми в рамках одной сессии тестирования. Особенностью создаваемого сетевого пространства имен является поддержка `localhost`, что позволяет тестам взаимодействовать с сервисами, запущенными на локальной машине, но при этом изолировать их сетевые взаимодействия друг от друга.

При активации этой опции тестовая система создает отдельное сетевое пространство имен для каждого теста. В контексте Linux и других UNIX-подобных операционных систем, сетевое пространство имен — это фича ядра, позволяющая разделять сетевой стек между разными процессами. Это означает, что каждый тест получает свой собственный набор сетевых интерфейсов и таблиц маршрутизации, изолированный от хост-системы и других тестов. Таким образом, даже если тесты пытаются открыть сокеты на одних и тех же портах `localhost`, они не будут мешать друг другу, поскольку их сетевые пространства имен изолированы.

Преимущества использования `--private-net-ns`

1\. **Изоляция тестов**: Гарантирует, что сетевые операции, выполняемые одним тестом, не влияют на другие тесты, улучшая надежность и предсказуемость тестового окружения.
2\. **Повышение безопасности**: Изоляция сетевого стека может помочь предотвратить нежелательный сетевой доступ к тестовым сервисам и данных, улучшая безопасность тестовой среды.
3\. **Упрощение конфигурации**: Упрощает написание тестов, требующих специфических сетевых настроек, поскольку каждый тест может настраивать сеть в своем пространстве имен независимо.
4\. **Поддержка параллельного выполнения**: Позволяет параллельно запускать тесты, которые слушают одни и те же порты на `localhost`, без конфликтов и необходимости координации портов между тестами.

 Пример использования

Если вы разрабатываете микросервисы или другие сетевые приложения и хотите автоматизировать тестирование сетевого взаимодействия в изолированной среде, вы можете запустить тесты с использованием опции `--private-net-ns`:

\--private-net-ns

Это гарантирует, что каждый тест будет выполнен в своем собственном сетевом пространстве имен, позволяя тестам взаимодействовать с локальными сервисами через `localhost`, не мешая друг другу.

Обеспечивает эффективную изоляцию сетевого окружения тестов, позволяя более точно моделировать сетевое взаимодействие приложений и сервисов в безопасной и контролируемой манере.


## Опции для экспертов -НЕ ОПИСЫВАЕМ
\--arcadia-tests-data=ARCADIA_TESTS_DATA_PATH
Пользовательский путь к arcadia_tests_data (по умолчанию: arcadia_tests_data)

Расчет UID теста

Опция `--cache-tests` является командой, используемой в системах автоматизированного тестирования для включения механизма кеширования результатов тестов. Эта опция позволяет сохранять результаты успешно выполненных тестов в кеше и при последующих запусках тестов избегать повторного выполнения тех, результаты которых уже присутствуют в кеше и считаются актуальными. Таким образом, `--cache-tests` направлена на ускорение процесса тестирования за счет сокращения количества фактически выполняемых тестов.

Когда эта опция активирована, система тестирования выполняет следующие действия:

1\. **Проверка Кеша**: Перед выполнением теста система проверяет наличие его результатов в кеше.
2\. **Пропуск Тестов**: Если результаты теста уже присутствуют в кеше и считаются валидными (то есть код, связанный с тестом, не был изменен с момента последнего успешного выполнения), тест пропускается.
3\. **Выполнение и Кеширование**: Тесты, для которых в кеше нет актуальных результатов, выполняются, а их результаты после успешного завершения сохраняются в кеше для использования в будущих запусках.

Использование `--cache-tests` дает:

1\. **Ускорение Тестирования**: Сокращает время, необходимое для выполнения полного набора тестов, поскольку повторно не выполняются тесты, результаты которых уже известны и считаются актуальными.
2\. **Эффективное Использование Ресурсов**: Позволяет более эффективно использовать вычислительные ресурсы, особенно в условиях ограниченных мощностей или при необходимости частого запуска тестов.
3\. **Повышение Производительности Разработки**: Уменьшение времени ожидания результатов тестирования способствует более быстрой итерации в процессе разработки, позволяя разработчикам сосредоточиться на задачах, требующих немедленного внимания.

 Ограничения 


\- **Актуальность Кеша**: Важно обеспечить, что механизм кеширования корректно определяет актуальность кешированных результатов. Изменения в коде, влияющие на логику тестов, должны инвалидировать соответствующие записи в кеше.
\- **Изоляция Тестов**: Результаты тестов должны быть независимы от внешних факторов и других тестов. В противном случае, кеширование может привести к пропуску важных проверок.
\- **Не для Всех Сценариев**: Не все тесты подходят для кеширования. Например, интеграционные тесты, зависящие от внешних сервисов или состояния баз данных, могут требовать выполнения при каждом запуске.

Пример использования

При запуске набора юнит-тестов для большого проекта, где только небольшая часть кода подверглась изменениям:
 --cache-tests

Эта команда позволит пропустить выполнение тестов, которые не затрагивают измененные участки кода, ускоряя процесс получения обратной связи для разработчиков.

Позволяет экономить время и ресурсы за счет уменьшения количества фактически выполняемых тестов. 


Опция `--retest` используется в контексте автоматизированных систем тестирования и предназначена для принудительного повторного выполнения всех тестов, игнорируя любые результаты, которые могли быть сохранены в кеше от предыдущих запусков. Это значит, что независимо от того, был ли тест успешно выполнен ранее и его результат сохранен в кеше, при использовании этой опции система тестирования выполнит тест заново.

Когда тесты запускаются с использованием опции `--retest`, механизм кеширования результатов тестов временно отключается или игнорируется. Система тестирования будет вести себя так, как если бы она запускалась в первый раз, без доступа к предыдущим результатам. Все тесты в наборе запускаются заново, и их результаты обновляются в соответствии с текущим состоянием кодовой базы и тестовой среды.

Преимущества использования `--retest`

1\. **Актуализация результатов тестирования**: Эта опция гарантирует, что все тесты будут выполнены с учетом последних изменений в коде, обеспечивая актуальность результатов тестирования.
2\. **Проверка стабильности тестов**: Повторное выполнение тестов может выявить проблемы со стабильностью тестов, такие как флаки (flaky tests) — тесты, результаты которых могут меняться от запуска к запуску без изменений в коде.
3\. **Интеграция с внешними изменениями**: В случаях, когда изменения внесены не в сам код, а в зависимости, окружение или конфигурацию, `--retest` позволяет убедиться, что тесты корректно работают в новых условиях.
4\. **Упрощение процесса разработки**: Разработчики могут использовать `--retest` для упрощения процесса интеграции и тестирования изменений, минуя необходимость ручного управления кешем тестов.

Ограничения и соображения

\- **Время выполнения**: Использование `--retest` может значительно увеличить время, необходимое для выполнения полного набора тестов, особенно в больших проектах.
\- **Ресурсы**: Повторное выполнение всех тестов требует дополнительных вычислительных ресурсов, что может быть критичным в средах с ограниченными ресурсами.

Пример использования

Предположим, вы работаете над проектом и вносите значительные изменения в код, которые могут повлиять на поведение существующих тестов. Чтобы убедиться в корректности работы после изменений, вы можете запустить:

\--retest

Эта команда гарантирует, что все тесты будут выполнены заново, предоставляя актуальную картину состояния проекта после внесенных изменений.

Обеспечивает дополнительный уровень уверенности в качестве и надежности программного обеспечения, хотя и может увеличить время и ресурсы, необходимые для тестирования.

## Зависимости тестов

Опция `-b` или `--build-all`  указывает системе сборки собрать все цели, которые могут быть достигнуты через директивы `RECURSE` в `ya.make` файле, даже если эти цели не требуются непосредственно для запуска текущих тестов.

Зачем это нужно?

В большом и сложном проекте, содержащем множество зависимостей и подпроектов, не всегда очевидно, какие именно компоненты требуются для выполнения определенного набора тестов. По умолчанию, система сборки пытается оптимизировать процесс, собирая только то, что действительно необходимо для запуска запрашиваемых тестов. Это хорошо с точки зрения экономии времени и ресурсов.

Тем не менее, в некоторых случаях может возникнуть потребность в полной сборке всех компонентов программного продукта, даже тех, которые не используются в тесте напрямую. Например:

\- **Проверка полной интеграции:** Чтобы убедиться в том, что все компоненты системы способны корректно работать вместе, требуется сборка полного проекта.
\- **Обновления в зависимостях:** Если в проекте были сделаны обновления, которые могут косвенно повлиять на работу других компонентов, полезно провести полную сборку для выявления возможных проблем.
\- **Подготовка к деплою:** В рамках подготовки к деплою или публикации проекта важно убедиться, что все его части собраны и готовы к использованию.

Как это работает?

При вызове системы сборки с опцией `-b` или `--build-all`, система анализирует `ya.make` файлы на предмет директив `RECURSE`, прослеживая все возможные пути сборки до каждого компонента проекта.

Это включает в себя все библиотеки, программы, тесты и прочие цели, которые можно собрать. В результате, процесс сборки охватывает весь проект в полном объеме, не ограничиваясь только требуемыми для тестирования компонентами.

Важно понимать, что использование этой опции может значительно увеличить время сборки, особенно для больших проектов с множеством зависимостей. Поэтому важно применять её осознанно, когда действительно требуется полная сборка.

Пример использования

Предположим, у вас есть проект со множеством модулей и подмодулей, и вы хотите убедиться, что недавно внесенные изменения не поломали сборку других не связанных напрямую с тестами компонентов. Вызывая команду:

ya make -t -b

вы инициируете полную сборку проекта, что позволит обнаружить и предотвратить возможные проблемы до момента деплоя или передачи продукта заказчику.

Опция `--build-only-test-deps`  позволяет оптимизировать процесс сборки, фокусируясь исключительно на тех компонентах системы, которые необходимы для выполнения заданных тестов. Эта опция существенно снижает время и ресурсы, требуемые для сборки, поскольку исключает из процесса компоненты, не участвующие в тестировании.

При запуске системы сборки с этой опцией, механизм сборки проанализирует зависимости тестов, которые были запрошены для выполнения. Включение только необходимых для тестов зависимостей позволяет исключить из сборочного процесса все лишнее, что не имеет отношения к текущему тестовому прогону.

Вместо того, чтобы следовать всем путям в директивах `RECURSE` и собирать весь проект полностью (что может быть весьма времязатратно и ресурсоемко), система сборки сфокусирована только на той части проекта, которая действительно используется в тестах.

Основная цель опции `--build-only-test-deps` – повышение эффективности процесса разработки и тестирования. Минимизируя количество собираемых компонентов, разработчики могут быстрее получить результаты тестов и сэкономить ресурсы сборочной машины.

Эта опция особенно полезна в больших проектах со множеством модулей и компонентов, когда необходимо быстро проверить изменения в конкретной части системы, не тратя время на сборку нерелевантных частей.

Пример использования

Предположим, разработчик внес изменения в модуль, отвечающий за логику работы сетевых запросов, и хочет запустить только тесты, относящиеся к этому модулю, не собирая остальную часть проекта. В этом случае команда для сборки и тестирования будет выглядеть примерно так:

 ya make -t --build-only-test-deps network_tests


Здесь `network_tests` – это идентификатор или путь к тестам, которые необходимо выполнить. Система сборки выполнит анализ, определит, какие компоненты проекта требуются для выполнения данного набора тестов, и соберет только их.

\- Использование `--build-only-test-deps` предполагает, что разработчик знает, какие тесты ему нужно запустить, и какие компоненты системы они затрагивают.
\- Несмотря на удобство этой опции для быстрого тестирования, периодически следует выполнять полную сборку проекта, чтобы убедиться в корректной интеграции всех его частей.

Опция `--strip-skipped-test-deps` позволяет исключить из процесса сборки зависимости тех тестов, которые по тем или иным причинам будут пропущены. 

Это означает, что система сборки не будет тратить время и ресурсы на подготовку тестов и их зависимостей, которые итак не будут выполнены. Давайте более подробно рассмотрим работу этой опции и её влияние на процесс разработки.

Когда вы запускаете систему сборки с этой опцией, механизм сборки проводит предварительный анализ запрашиваемых для выполнения тестов. Если на основании конфигурации запуска или внешних условий (например, фильтров, указанных разработчиком) определённые тесты маркированы к пропуску, то все зависимости, которые необходимы исключительно для этих тестов, будут исключены из сборки.

Польза использования `--strip-skipped-test-deps`

\- **Уменьшение времени сборки**: Основным и, пожалуй, самым очевидным преимуществом является сокращение общего времени на процесс сборки, поскольку система не будет заниматься бесполезной генерацией артефактов для пропущенных тестов.
\- **Снижение нагрузки на ресурсы**: Уменьшается потребление ресурсов машины (CPU, оперативная память, дисковое пространство), так как работа будет сосредоточена только на актуальных для запуска целях.
\- **Более чистое тестирование**: Тестовый процесс становится более предсказуемым и менее подверженным случайным факторам, связанным с поведением не используемых компонентов.

Сценарий использования

Рассмотрим пример, когда команда разработки работает над большим проектом с множеством модулей и подмодулей. Изменения вносятся в один модуль, и разработчики хотят запустить только тесты, связанные с этим модулем, пропуская все остальные. В данном случае запуск сборки с опцией `--strip-skipped-test-deps` позволит существенно ускорить процесс, исключив несвязанные с текущим заданием проверки и их зависимости.

Использование опции `--strip-skipped-test-deps` требует от разработчиков ясного представления о тестовом покрытии кода и зависимостях между различными частями системы. Важно помнить, что пропуск сборки зависимостей для неиспользуемых тестов может привести к отсутствию важных проверок, если выборка тестов настроена неправильно.

Опция `--strip-idle-build-results` позволяет системе сборки удалить результаты сборки, которые в конечном итоге не используются непосредственно для запуска тестов. Данная функциональность ценится за возможность экономии как времени, так и дискового пространства, освобождая ресурсы для других задач.

Когда вы запускаете систему сборки со включенной опцией `--strip-idle-build-results`, в процессе сборки система активно отслеживает, какие именно артефакты (файлы результата сборки) требуются для успешного выполнения заданных тестов. По завершении процесса сборки, вся информация о “лишних” узлах — т.е., те, которые не связаны с запуском тестов — удаляется.

Преимущества использования `--strip-idle-build-results`

\- **Экономия дискового пространства**: Особенно актуально для масштабных проектов, где артефакты сборки могут занимать значительное пространство.
\- **Уменьшение времени сборки**: Удаление ненужных узлов сборки может уменьшить общее время, требуемое для сборки и подготовки тестов.
\- **Повышение эффективности**: Освобождение системных ресурсов позволяет более эффективно использовать их для других процессов, например, для параллельной работы или выполнения более важных задач.

Сценарии использования

\- **Большие проекты**: Где сборка всех модулей и их тестов может затягиваться на длительное время и занимать много места на диске. Это может быть особенно актуально для CI/CD систем, где каждая сборка проекта должна быть максимально эффективной по времени и ресурсам.
\- **Ограниченные ресурсы**: Например, при сборке на локальном компьютере разработчика с ограниченным диском или в условиях ограниченных ресурсов сборочных серверов.

\- Важно понимать, что использование данной опции требует точного понимания зависимостей проекта, так как преждевременное удаление “лишних” узлов может привести к необходимости пересборки некоторых модулей или даже к невозможности выполнения некоторых тестов.
\- Также следует быть осторожным с этой опцией при локальной разработке, когда в процессе работы над одной задачей предполагается последующий запуск других тестов или использование собранных артефактов для других целей. 



Опция `--no-strip-idle-build-results` директивно указывает сохранить все результаты сборки (или узлы сборки), включая те, которые не нужны для прямого запуска тестов. Эта опция является противоположностью к `--strip-idle-build-results`, о которой шла речь ранее.

 Она обеспечивает более широкий охват сборки, гарантируя, что ничего не будет исключено или удалено из результата сборки, даже если это не нужно непосредственно для тестирования.

При запуске системы сборки с использованием опции `--no-strip-idle-build-results`, механизм сборки производит компиляцию и сборку всех целей проекта, включая те, что указаны в файлах `ya.make` через директивы `RECURSE`, без исключения. Это означает, что результаты сборки всех модулей, библиотек, вспомогательных утилит и тестов будут сохранены.

 Зачем использовать эту опцию?

Использование `--no-strip-idle-build-results` может быть полезным в нескольких сценариях:

\- **Разработка и отладка**: В процессе разработки и отладки может потребоваться доступ ко всем артефактам сборки, включая те, что не связаны напрямую с текущим тестом, чтобы вносить изменения и немедленно видеть результаты в контексте всего проекта.

\- **Подготовка к деплою**: Перед деплоем или релизом проекта полезно убедиться, что все компоненты системы собраны правильно и полностью. Это помогает обнаружить возможные проблемы или недостающие компоненты до публикации.

\- **Полная сборка проекта**: В некоторых случаях требуется выполнение полной сборки проекта для оценки зависимостей, проверки интеграции модулей или генерации полного набора артефактов.

Пример использования

Предположим, команда разработчиков работает над большим проектом и хочет выполнить полную сборку проекта (включая все модули и тесты) для проведения комплексной проверки перед релизом. В этом случае команда сборки может быть запущена с опцией `--no-strip-idle-build-results`, что гарантирует сохранение всех артефактов сборки.

 ya make --no-strip-idle-build-results


Важные моменты

\- Эта опция может значительно увеличить время сборки, особенно для крупных проектов, поскольку требует компиляции и сохранения всех компонентов проекта.

\- Опция может привести к увеличению потребления дискового пространства из-за сохранения всех артефактов сборки.


## Отчеты в файлах

Опция `--junit=JUNIT_PATH` предназначена для генерации отчёта о результатах выполнения тестов в формате JUnit. Формат JUnit стал де-факто стандартом для представления результатов тестирования в многих инструментах непрерывной интеграции (CI), таких как Jenkins, GitLab CI и других, благодаря своей универсальности и широкой поддержке.

При запуске тестов с указанием этой опции, система сборки выполняет все запрашиваемые тесты, а затем агрегирует информацию о прохождении каждого теста, результаты (удачные и неудачные исполнения), время выполнения и возможные сообщения об ошибках в один отчет в формате XML, соответствующем спецификации JUnit.

`JUNIT_PATH` здесь — это путь к файлу, куда будет записан сгенерированный отчет. Этот путь может указывать как на локальный файловый путь в системе разработчика, так и на путь в среде непрерывной интеграции, где отчет будет использоваться для дальнейшего анализа и представления результатов тестирования.

 Зачем использовать эту опцию?

\- **Интеграция с системами CI/CD**: Упрощает анализ результатов тестирования, интегрируясь с внешними инструментами и сервисами, которые могут автоматически интерпретировать результаты тестов в формате JUnit.
\- **Унификация отчетности**: Позволяет использовать единый формат отчетов при работе с разными языками программирования и тестовыми фреймворками, поддерживающими формат JUnit.
\- **Более глубокий анализ результатов**: Системы CI часто предоставляют расширенные возможности для анализа и визуализации результатов на основе отчетов JUnit, включая тренды, статистики и даже отслеживание изменений в динамике выполнения тестов.

Пример использования

Предположим, что вы разрабатываете проект и используете систему сборки для запуска тестов. Вы хотите получить отчет о результатах тестирования в формате JUnit для интеграции с Jenkins. В этом случае вы можете добавить опцию в вашу команду запуска тестов следующим образом:

 ya make -t --junit=/path/to/your/project/test-results/results.xml


После выполнения команды в указанном месте `(/path/to/your/project/test-results/results.xml)` будет создан файл XML с отчетом о результатах тестирования в формате JUnit, который затем может быть импортирован в Jenkins или любую другую систему, поддерживающую анализ JUnit отчетов.

Внимание

\- До запуска тестов с этой опцией убедитесь, что указанный каталог для сохранения отчета существует, или ваша система сборки имеет разрешение на создание файлов и каталогов в указанном месте.
\- Для максимальной совместимости результатов и визуализаций в CI/CD стоит ознакомиться с дополнительными опциями и настройками используемой системы CI по работе с отчетами JUnit.


## Выходные данные теста

Опция `--no-test-outputs` в системе сборки используется для контроля над сохранением выводов тестов, а именно файлов и данных, которые тесты могут генерировать в процессе их выполнения. Это может включать в себя логи выполнения, временные файлы, результаты выполнения и другие “artifacts”, созданные тестами. Обозначение `testing_out_stuff` можно интерпретировать как "вещи, созданные в процессе тестирования".

Назначение и применение `--no-test-outputs`

Опция `--no-test-outputs` представляет собой директиву системе сборки, указывающую не сохранять вышеупомянутые файлы и данные, созданные во время тестирования. Это может быть полезно в различных сценариях, например:

\- **Сокращение объема используемого дискового пространства**: Тесты, особенно в больших и комплексных проектах, могут генерировать значительный объем выходных данных. Не сохраняя эти данные, можно значительно экономить место на диске.
\- **Ускорение процесса сборки и тестирования**: Процесс записи данных на диск может занять некоторое время, особенно если генерируемые файлы велики или если тестов много и каждый из них создает выходные данные.
\- **Улучшение чистоты среды сборки и тестирования**: В некоторых случаях может быть важно, чтобы среда сборки и тестирования оставалась максимально “чистой” и не загромождалась лишними файлами, что упрощает анализ результатов и управление средой.

При этом стоит учитывать, что использование `--no-test-outputs` может также означать, что будет потерян важный контекст или диагностическая информация, которую выходные данные могли бы предоставить для анализа проблем и ошибок, выявленных во время тестирования. Поэтому решение о применении этой опции следует принимать, взвешивая нужду в данных против потребностей в ресурсах и чистоте среды.

Пример использования

Допустим, проект находится в активной фазе разработки, и разработчики выполняют зацикленные итерации сборки и тестирования на локальной машине. Чтобы минимизировать влияние на дисковое пространство и ускорить процесс выполнения тестов, они могут принять решение временно не сохранять выходные данные тестов с помощью `--no-test-outputs`.

 ya make -t --no-test-outputs


В этом случае система сборки выполнит все запрашиваемые тесты, но не сохранит никаких файлов, созданных в процессе их выполнения.


Использование опции `--no-test-outputs` предоставляет гибкость в управлении процессом сборки и тестирования, позволяя ускорить выполнение тестов и сохранить ресурсы системы за счет отказа от сохранения выходных данных тестов. Однако при её применении важно учитывать потенциальные недостатки, связанные с потерей возможности детального анализа результатов тестирования. Поэтому выбор между сохранением и отказом от выходных данных тестов должен базироваться на текущих потребностях и условиях разработки, а также на важности выходных данных для дальнейшего анализа и отладки.


*\--no-dir-outputs (устаревшее)
Архивировать директорию выходных данных теста в промежуточном оборудовании

Не описываем*

Опция `--dir-outputs-in-nodes` в системе сборки обеспечивает поддержку директорий в качестве выходных данных узлов сборки. Это означает, что при включении этой опции система сборки может обрабатывать целые директории как результат выполнения задачи сборки, а не только отдельные файлы.

В обычном режиме работы системы сборки каждый узел (или задача сборки) генерирует один или несколько файлов в качестве выходных данных. Такой подход хорошо подходит для большинства задач, но иногда требуется, чтобы результатом работы узла была целая директория со множеством файлов и поддиректорий. Примером может служить сборка документации, генерация ресурсов для веб-приложений или компиляция ассетов для игр, где результатом работы является набор файлов и структура директорий.

Опция `--dir-outputs-in-nodes` разрешает создание таких узлов, указывая системе сборки, что она должна ожидать и корректно обрабатывать директории как выходные данные узлов.

Преимущества использования `--dir-outputs-in-nodes`

\- **Улучшенная поддержка для комплексных задач сборки**: Эта опция позволяет более эффективно справляться с задачами, где результатом работы является не один файл, а целая иерархия директорий и файлов.
\- **Упрощение конфигурации сборки**: Вместо необходимости описывать каждый файл в выходной директории как отдельный узел или ресурс, разработчики могут работать с директорией как с одним логическим блоком.
\- **Оптимизация работы системы сборки**: Использование директорий как единичных выходных единиц упрощает отслеживание изменений и сокращает время на анализ зависимостей и определение необходимости пересборки.

Пример использования

Предположим, вы работаете над веб-проектом, и ваша задача состоит в генерации оптимизированных изображений для сайта. Исходные файлы изображений находятся в одной директории, и вы хотите получить оптимизированные версии в другой директории, сохраняя исходную структуру папок.

 ya make --dir-outputs-in-nodes /path/to/source/images/directory /path/to/destination/optimized/images/directory


В этом случае система сборки обработает генерацию оптимизированных изображений, рассматривая всю директорию `/path/to/destination/optimized/images/directory` как выходной результат работы узла, а не каждый файл по отдельности.

Важные замечания

Использование этой опции требует внимательного планирования структуры сборки, поскольку она изменяет подход к определению выходных данных сборки. Необходимо убедиться, что все связанные задачи и узлы корректно настроены на работу с директориями как с выходными единицами, а также что инструменты и скрипты, обрабатывающие результаты сборки, правильно обрабатывают случай, когда выходными данными являются директории.

Использование `--dir-outputs-in-nodes` обеспечивает большую гибкость в работе системы сборки и позволяет адаптировать процесс сборки под конкретные задачи и требования проекта, но требует тщательной настройки и проверки конфигурации.

Опция `--keep-full-test-logs` в системе сборки – это специализированная директива, используемая в контексте распределённой сборки (`distbuild`), главная функция которой заключается в сохранении полных логов исполнения тестов, вместо их обрезки или урезания.


В распределённых системах сборки, где процесс сборки и тестирования проекта распределяется между множеством серверов или агентов, для ускорения обработки и минимизации времени сборки, часто применяются различные оптимизации. Одной из таких оптимизаций является урезание логов тестов, которое помогает снизить объём трафика данных между узлами и центральными хранилищами логов, а также облегчает последующий анализ результатов тестирования, удаляя излишнюю информацию.

Однако, в некоторых случаях, полная информация из логов тестов необходима для детального анализа проблем, выявленных в процессе тестирования, особенно когда речь идет о сложных сбоях или ошибках, проявляющихся только в специфических условиях.

 Как работает `--keep-full-test-logs`?

Система сборки, вызванная с опцией `--keep-full-test-logs`, изменяет стандартное поведение урезания логов, указывая инфраструктуре отказаться от оптимизации удаления части данных из лог файлов. В результате этого все строки, сгенерированные процессом исполнения тестов, сохраняются в логах полностью, не подвергаясь фильтрации или скрытию частей информации.

Применение

Эту опцию целесообразно использовать в ситуациях, когда требуется максимально подробное понимание действий и реакций тестируемой системы, а также для выявления и диагностики непростых, редких или малоизученных проблем, которые были обнаружены в процессе тестирования.

 ya make -t --keep-full-test-logs


Плюсы и минусы

**Преимущества**:
\- Упрощается процесс выявления и исправления ошибок благодаря доступности всех деталей исполнения тестов;
\- Облегчается процесс аудита и верификации результатов тестирования, так как вся история исполнения остаётся доступной для анализа.

**Недостатки**:
\- Увеличивается объём используемого дискового пространства для хранения логов;
\- Может увеличиться время передачи данных между узлами сборки и хранилищем логов из-за большего объёма передаваемой информации;
\- Потребуется больше времени на прохождение через подробные логи при анализе результатов.


Использование опции `--keep-full-test-logs` в системе сборки представляет собой важный инструмент для глубокого анализа и диагностики проблем в процессе разработки ПО, особенно при работе в условиях распределённой системы сборки. Несмотря на потенциальное увеличение ресурсных затрат, получаемое преимущество в виде полной прозрачности процесса тестирования может значительно облегчить поиск и исправление сложных, редких или новых ошибок в программном коде.

Опция `--test-node-output-limit=TEST_NODE_OUTPUT_LIMIT` используется для установления ограничения на максимальный размер файлов вывода, которые генерируются в процессе выполнения тестов.

Это позволяет контролировать объём данных, сохраняемых после работы тестов, важно для управления использованием дискового пространства, особенно в условиях ограниченных ресурсов или при работе с большим количеством тестов.

При выполнении теста система сборки отслеживает размер файлов вывода (логов, дампов, временных файлов и пр.), генерируемых каждым тестовым узлом. Если объём данных превышает установленный лимит `TEST_NODE_OUTPUT_LIMIT`, указанный в байтах, система может обрезать эти файлы до указанного размера или же не сохранять часть вывода, превышающую этот лимит. В результате, для каждого теста сохраняется лишь наиболее важная часть вывода, позволяя снизить потребление ресурсов хранения.

 Применение (GiB, MiB)

Опция `--test-node-output-limit=` особенно полезна в следующих сценариях:

\- **Ограниченное дисковое пространство**: на некоторых CI серверах или локальных машинах может быть ограничено доступное дисковое пространство для хранения результатов тестирования. Установив лимит на размер вывода, можно предотвратить забивание дисковой квоты.

\- **Большое количество тестов**: в проектах с большим объёмом тестов объем данных может быстро увеличиться до огромных размеров. Установление лимитов помогает держать общий объём данных под контролем.

\- **Сложные тесты**: некоторые комбинации тестов могут выдавать чрезмерно много данных, что делает анализ результатов затруднительным. Ограничение размера вывода помогает сохранить только самую важную информацию.

Пример использования

Предположим, что вы хотите ограничить вывод каждого тестового узла размером не более 1 МБ (1048576 байт). В этом случае команда запуска сборки и тестирования будет выглядеть так:

ya make -t --test-node-output-limit=1048576

Учитывать необходимо

\- **Выбор размера лимита**: определяя значение `TEST_NODE_OUTPUT_LIMIT`, необходимо найти баланс между желанием сэкономить место и необходимостью сохранения достаточного объёма информации для анализа и дебага тестов. Слишком маленький лимит может привести к потере важных данных, в то время как слишком большой лимит снижает эффективность опции.

\- **Последствия применения**: хотя этот параметр помогает управлять ресурсами, важно помнить, что его использование может привести к тому, что некоторая важная информация для диагностики и исправления ошибок будет потеряна из-за обрезки вывода.

\- **Гибкость**: В некоторых ситуациях может оказаться целесообразным использовать различные лимиты для разных групп тестов в зависимости от их характеристик и важности получаемой информации.

Опция `--test-node-output-limit`  позволяет  сохранять контроль над объёмом генерируемых данных и предотвращая ненужное потребление дискового пространства и затраты на обработку избыточных данных.

Опция `--test-keep-symlinks` для системы сборки специально разработана для управления сохранением символических ссылок, которые возникают в ходе выполнения тестов. При использовании этой опции система сборки не будет удалять символические ссылки из выходных данных теста, что может быть полезно в различных сценариях разработки и тестирования.

Символические ссылки (или симлинки) — это файлы, которые указывают на другие файлы или директории в файловой системе. Они могут использоваться в процессе тестирования для имитации определённых структур файловой системы, обращения к файлам без копирования реального содержимого или создания контролируемых условий тестовой среды.

По умолчанию, система сборки может удалять символические ссылки после теста с целью очистки и возврата к изначальному, “чистому” состоянию тестовой среды. Однако, в некоторых случаях, сохранение симлинков может быть желательным или даже необходимым для дальнейшего анализа результатов исполнения тестов или для передачи данных между различными тестами.

При запуске тестов с этой опцией система сборки изменяет своё стандартное поведение таким образом, чтобы символические ссылки, созданные в процессе выполнения тестов, не удалялись после их завершения. Это означает, что вся структура директорий, файлы и симлинки, созданные или использованные тестами, будут сохранены в их исходном виде, давая возможность для последующего анализа или использования.

Применение

1\. **Анализ проблем с зависимостями**: если тестирование включает анализ правильности разрешения и использования зависимостей (например, библиотек или модулей), сохранение символических ссылок может помочь в диагностике проблем с путями доступа.

2\. **Передача состояния между тестами**: в некоторых комплексных тестовых сценариях состояние из одних тестов (например, настроенная структура директорий с помощью симлинков) может быть использовано последующими тестами.

3\. **Отладка источников данных**: при тестировании систем, которые работают с разнообразными источниками данных (например, медиа-серверы или базы данных), сохранение симлинков может облегчить отладку путей доступа к данным в тестовой среде.


\- Сохранение симлинков может повлиять на поведение последующих тестов, особенно если они ожидают “чистую” среду.
\- Необходимо учитывать, что сохранённые символические ссылки могут ссылаться на данные, которые изменились или были удалены после проведения тестов, что может привести к неверным результатам при их анализе или повторном использовании.

\ Заключение

Опция `--test-keep-symlinks`  позволяет улучшить понимание и отладку сложных взаимодействий внутри тестируемой системы.

## Покрытие кода

https://st.yandex-team.ru/DOCSUP-69368


Опция --coverage-verbose-resolve предназначена для использования в контексте инструментов анализа покрытия кода исполнения тестами, таких как gcov для C/C\+\+, JaCoCo для Java или любых других инструментов, применяемых в различных языках программирования. Эта опция управляет выводом детальных отладочных логов во время процесса разрешения данных о покрытии, то есть на этапе, когда анализируются собранные данные о покрытии, обрабатываются файлы покрытия и готовится итоговый отчет о покрытии кода тестами.

Контекст и необходимость опции

В процессе сбора и анализа данных о покрытии кода могут возникать различные сложности и вопросы, например:

* Почему определенные строки кода или ветвления не покрыты исполнением тестов?
* Как обрабатываются данные о покрытии из разных источников или сессий тестирования?
* В чем причина расхождений в данных о покрытии между разными запусками тестов на одном и том же наборе кода?

Включение детальных отладочных логов помогает ответить на эти и многие другие вопросы, предоставляя дополнительные сведения о процессе работы инструмента анализа покрытия.

Пример использования

Допустим, вы используете инструмент JaCoCo для анализа покрытия кода Java-проекта и хотите подробно изучить, как именно происходит обработка данных о покрытии и генерация отчета.

1. Стандартный запуск JaCoCo для сбора данных о покрытии и генерации отчета может выглядеть следующим образом:

   java -jar jacoco-cli.jar report jacoco.exec --classfiles myproject/target/classes --sourcefiles myproject/src/main/java --html report

   Здесь jacoco.exec - файл с данными о покрытии, собранными во время исполнения тестов; --classfiles и --sourcefiles указывают на классы и исходные коды проекта; --html report генерирует HTML-отчет о покрытии.

2. Запуск с включенным отладочным логированием может требовать модификации команды или использования специального параметра окружения или файла настроек, который бы активировал --coverage-verbose-resolve (внимание, детальная реализация может отличаться в зависимости от версии и конфигурации инструмента):

   java -Djacoco.log=debug -jar jacoco-cli.jar report jacoco.exec --classfiles myproject/target/classes --sourcefiles myproject/src/main/java --html report

   Предположим, что -Djacoco.log=debug в данном примере выполняет функцию, аналогичную --coverage-verbose-resolve, активируя дополнительное логирование во время процесса разрешения и обработки данных о покрытии.

После выполнения такой команды вы получите в логах дополнительную информацию о каждом шаге обработки данных покрытия, включая загрузку и анализ файлов покрытия, разрешение символов и адресов, а также возможные ошибки или предупреждения, возникшие в процессе. Это значительно упрощает отладку и помогает оптимизировать процесс сбора и анализа покрытия, делая его более прозрачным и контролируемым.


*НЕ ОПИСЫВАЕМ

\--upload-coverage Загрузить собранную информацию о покрытии на YT*


Опция `--merge-coverage` используется в контексте инструментов и систем сборки, которые поддерживают сбор данных о покрытии кода исполнением тестов. Цель данной опции - объединение всех найденных данных о покрытии, обычно распределенных по разным файлам, в единый совокупный файл покрытия. Это позволяет агрегировать информацию о покрытии кода из разных источников или тестовых прогонов в один удобный для анализа документ.

 Сценарий использования

В современной разработке программного обеспечения часто используется модульное тестирование. При этом, каждый модуль или набор тестов может генерировать свой собственный файл данных о покрытии кода исполнением тестов. Если проект велик, то и количество таких файлов может быть значительным, что усложняет анализ общего покрытия кода проекта. В таких случаях, объединение всех данных о покрытии в один файл может значительно упростить задачу анализа.

 Пример использования

Допустим, у нас есть проект на языке C\+\+ с использованием инструментов GCC для сборки и Gcov для анализа покрытия кода. Проект состоит из нескольких модулей, и после запуска модульных тестов для каждого из них, мы имеем набор файлов покрытия `*.gcov`.

1\. **Генерация отдельных файлов покрытия**:

После выполнения тестов для каждого модуля, например, с использованием `make test`, в разных поддиректориях проекта генерируются файлы покрытия.

2\. **Объединение файлов покрытия в один**:

Для объединения файлов покрытия в единый файл можно использовать специальный инструмент или скрипт, поддерживающий опцию `--merge-coverage`. Допустим, роли такого инструмента выполняет `gcov-tool merge`. Команда для объединения может выглядеть так:

gcov-tool merge --output=merged_coverage.info module1/coverage.info module2/coverage.info module3/coverage.info  

3\. Анализ общего покрытия:  После объединения данных о покрытии в одном файле merged_coverage.info, можно использовать инструменты визуализации и анализа покрытия, такие как LCOV или его графический фронтенд Gcovr, чтобы оценить общее тестовое покрытие кода проекта: 

lcov --summary merged_coverage.info     

или для генерации HTML отчета:

 genhtml -o coverage_report merged_coverage.info 

 Этот пример демонстрирует, как можно автоматизировать процесс объединения и анализа данных о покрытии кода для облегчения задачи оценки качества тестирования в проектах любого размера
 

Опция `--coverage-report-path=COVERAGE_REPORT_PATH` используется для указания конкретного пути относительно каталога вывода (output directory), куда будет сохранен отчет о покрытии кода, сгенерированный инструментом gcov для C\+\+ проектов. 

Это позволяет более гибко управлять расположением файлов покрытия и интегрировать их в вашу систему CI/CD или процесс анализа качества кода. 

Для работы данной опции требуется также использовать опцию `--output`, которая задает корневую директорию для всех выходных файлов сборки.

 Контекст использования

Gcov — это инструмент покрытия кода, входящий в состав компиляторов GNU Compiler Collection (GCC), который предоставляет данные о том, сколько раз каждая строка кода была исполнена. Эта информация крайне полезна для оценки эффективности тестового покрытия и для выявления участков кода, не затронутых тестами.

 Пример использования

Предположим, что вы строите свой проект с помощью утилиты сборки, поддерживающей этот параметр, и хотите сохранить отчет о покрытии в каталоге `coverage_reports` внутри каталога, указанного в опции `--output`. В этом случае команда может выглядеть следующим образом:

build_tool --output=/path/to/output --coverage-report-path=coverage_reports/report.xml


В данной команде:
\- `--output=/path/to/output` задает каталог, в который будет собираться весь вывод сборки, включая бинарные файлы, объектные файлы, и файлы покрытия.
\- `--coverage-report-path=coverage_reports/report.xml` указывает на то, что отчет о покрытии будет сохранен по пути `/path/to/output/coverage_reports/report.xml`.

Практическая польза

\- **Централизация отчетов о покрытии**: Позволяет собирать все отчеты о покрытии в одном месте, упрощая доступ к информации о покрытии для всей команды разработки.
\- **Интеграция с инструментами анализа**: Указание конкретного пути к отчету упрощает интеграцию с внешними инструментами и сервисами, которые анализируют данные о покрытии, такими как SonarQube, Coveralls или Codecov.
\- **Автоматизация**: Фиксированный путь к отчету об упрощает написание скриптов и процессов CI/CD, которые автоматически обрабатывают и публикуют информацию о покрытии после каждого прогона тестов.
\- **Гибкость организации данных о покрытии**: Позволяет структурировать и хранить данные о покрытии в соответствии с предпочтениями проекта или организации, например, разделяя отчеты по модулям или версиям.


Опция `--enable-contrib-coverage` предназначена для расширения процесса сбора данных о покрытии кода в проектах, зависящих от внешних библиотек или компонентов, загруженных из каталога `contrib` в системе сборки. Эта опция влияет на то, как собираются эти внешние компоненты и какие дополнительные действия выполняются для генерации данных о покрытии кода этими компонентами.

Как работает опция

Сборка contrib с опциями для покрытия
Когда вы включаете данную опцию, система сборки автоматически добавляет необходимые флаги компиляции и линковки для всех библиотек и бинарных файлов из `contrib`, чтобы генерировать данные о покрытии кода по мере их исполнения. Эти флаги включают в себя, например, инструменты, такие как gcov для GCC или profile-instr-generate для Clang, которые позволяют отслеживать использование строк кода, ветвлений и других элементов во время выполнения программы.

Вставка тестов coverage.extractor
Кроме изменения процесса сборки, эта опция также добавляет специальные тесты, именуемые here как “coverage.extractor”, для каждого собранного из `contrib` бинарного файла. Эти тесты автоматически извлекают и сохраняют собранные данные о покрытии после выполнения любых тестов, использующих соответствующие `contrib` компоненты. Обычно это достигается путем вызова утилит после завершения тестов, которые читают и обрабатывают специальные файлы, содержащие сырые данные о покрытии, собранные во время исполнения.

Практическое применение

Эта опция особенно важна в следующих сценариях:
\- **Глубокая интеграция с внешними компонентами:** В проектах, которые тесно интегрированы с внешними компонентами и библиотеками, важно понимать, не только как части собственного кода используются в тестах, но и как исполняемый код contrib компонентов покрывается тестами.
\- **Отладка и профилирование:** Данные о покрытии могут использоваться для профилирования представления проекта и поддержания его качества на высоком уровне, позволяя идентифицировать неиспользованные или малоиспользуемые ветви логики в contrib коде.
\- **Оптимизация зависимостей:** Информация о том, какие части contrib кода фактически используются, может способствовать оптимизации списка зависимостей, позволяя устранять лишние или мало используемые библиотеки.

Рассмотрения и ограничения

Использование опции `--enable-contrib-coverage` увеличивает время сборки и исполнения тестов из-за необходимости компиляции с дополнительными флагами и выполнения дополнительного шага для извлечения данных о покрытии. Поэтому включайте эту опцию только в том случае, если информация о покрытии contrib кода имеет ключевое значение для разработки или тестирования вашего проекта. 

Также стоит учитывать, что полнота и точность собранных данных о покрытии могут зависеть от специфики используемых компиляторов, инструментов покрытия и самих тестов. Это подразумевает необходимость тщательной настройки процесса сборки и анализа данных о покрытии для достижения наиболее достоверных и полезных результатов.

Опция `--enable-java-contrib-coverage` предназначена для интеграции исходных кодов и скомпилированных классов из внешних библиотек или пакетов, установленных из `contrib/java`, в итоговый отчет о покрытии кода, генерируемый инструментом JaCoCo. JaCoCo — это инструмент для анализа покрытия кода Java-программ, который позволяет оценить, какие строки кода и ветви были выполнены во время запуска тестов.

Контекст и необходимость опции
В большинстве случаев разработчики интересуются покрытием только того кода, который напрямую относится к их проекту. Однако, в некоторых ситуациях важно понимать, как тесты проекта взаимодействуют с кодом внешних библиотек, добавленных через `contrib/java`. Это может быть актуально, например, для определения “мертвого кода” в используемых библиотеках, или если разработка ведется в тесной интеграции с внешней библиотекой, к которой вносятся изменения параллельно с основным проектом.

Как работает опция
При сборе отчета о покрытии без данной опции JaCoCo анализирует только исполняемые файлы `.class`, сгенерированные для вашего проекта, и соответствующие им исходные коды. Использование `--enable-java-contrib-coverage` указывает системе сборки включить в анализ также исходные коды и классы из указанных пакетов `contrib/java`.

 Что добавляется в отчет
Опция влияет на содержание итогового отчета о покрытии JaCoCo следующим образом:
\- **Исходные коды (`*.java` файлы)** из внешних библиотек пакетов `contrib/java` добавляются в отчет. Это позволяет видеть визуализацию использования этих исходников в интерфейсе JaCoCo.
\- **Классы (`*.class` файлы)**, скомпилированные из этих исходников, также анализируются на предмет выполнения, что позволяет расширить покрытие за счет кода внешних компонентов.

 Практическое значение
\- **Углубленный анализ покрытия:** позволяет оценить, как тесты покрывают не только напрямую написанный код, но и код, на который проект опирается через внешние зависимости.
\- **Оптимизация использования внешних библиотек:** может помочь обнаружить части библиотек `contrib/java`, которые не используются и потенциально могут быть исключены из зависимостей проекта.

Применение данной опции увеличивает область анализа покрытия и может быть полезно для комплексной оценки влияния внешних компонентов на качество кода и тестов проекта. Включение исходников и классов из `contrib/java` делает отчеты о покрытии более полными и информативными, особенно в сложных проектах с множеством внешних зависимостей.

Опция `--fast-clang-coverage-merge` используется при сборке и запуске тестов с поддержкой покрытия кода, в частности, когда осуществляется сбор информации о покрытии Clang source-based coverage. Данная опция предназначена для оптимизации процесса мержа (объединения) профилей покрытия, собранных во время выполнения различных тестов или исполняемых файлов.

В общем контексте, профили покрытия содержат информацию о том, какие строки кода и ветки условий были исполнены в процессе работы программы. После запуска набора тестов необходимо объединить собранные профили покрытия в один общий отчет. Традиционный подход к объединению профилей предполагает их последовательное слияние с использованием специализированных инструментов после завершения всех тестов, что может быть ресурсоемкой и времязатратной операцией, особенно для крупных проектов.

Опция `--fast-clang-coverage-merge` использует FUSE (Filesystem in Userspace) механизм для того, чтобы процедура мержа происходила “на лету”, прямо во время выполнения тестов, что значительно ускоряет процесс. FUSE позволяет создавать виртуальные файловые системы, управляемые пользовательскими программами. В контексте объединения профилей покрытия это означает, что вместо физического создания промежуточных файлов профилей на диске, все операции с профилями происходят в памяти. Это позволяет минимизировать затраты на ввод/вывод и ускорить подготовку итогового отчета о покрытии.

Преимущества использования опции `--fast-clang-coverage-merge`:

1\. **Уменьшение времени сборки:** быстрое объединение профилей покрытия во время работы тестов уменьшает общее время, необходимое для генерации финального отчета о покрытии.
2\. **Оптимизация использования ресурсов:** минимизирует количество операций чтения и записи на диск, тем самым снижая нагрузку на файловую систему и улучшая общую производительность.

Для включения данной опции, ее нужно указать в параметрах запуска инструментов сбора и обработки информации о покрытии в вашей системе сборки или в командной строке утилиты, отвечающей за работу с покрытием. Обратите внимание, что для использования FUSE могут потребоваться дополнительные разрешения или настройки системы.


Опция `--sancov` представляет собой параметр системы сборки, который активирует сбор данных о покрытии кода при помощи инструментов санитайзеров (Sanitizers), таких как AddressSanitizer, ThreadSanitizer, MemorySanitizer и других. 

Санитайзеры — это мощные инструменты, обеспечивающие динамический анализ кода для выявления различных видов ошибок, таких как обращения за границы массивов, использование неинициализированной памяти и состязания данных. В контексте опции `--sancov`, основное внимание уделяется построению отчетов о покрытии кода на основе анализа, проведенного данными инструментами.

\### Как работает `--sancov`?

При использовании `--sancov` в команде сборки, система настраивает среду выполнения и компиляцию тестовых и целевых модулей таким образом, чтобы включить механизмы отслеживания исполнения кода санитайзерами.

Эти механизмы генерируют специальные данные о покрытии кода в ходе выполнения тестов, позволяя точно определить, какие части кода были задействованы. По завершении тестов система сборки обрабатывает сгенерированные данные и формирует отчет о покрытии кода.

Преимущества использования `--sancov`

\- **Точное покрытие кода**: Предоставляет подробные сведения о том, какие участки кода были исполнены во время тестирования, что позволяет идентифицировать не охваченные тестами части программы.
\- **Улучшение качества кода**: Использование данных о покрытии помогает нацелить усилия разработчиков на улучшение тестов и расширение охвата критически важных участков кода.
\- **Оптимизация ресурсов**: Помогает определить избыточные или неэффективные тесты, сокращая время, затрачиваемое на тестирование, и ускоряя цикл разработки.
\- **Автоматическое увеличение таймаута тестов**: Учитывая дополнительную нагрузку на производительность, вызванную активацией санитайзеров, автоматическое увеличение времени ожидания выполнения тестов на 1.5 раза помогает избежать ложных сбоев из-за превышения времени исполнения.

Использование `--sancov` с `--output`

Для сохранения отчетов о покрытии кода рекомендуется использовать `--sancov` совместно с опцией `--output`, указывая путь для сохранения результата:

 ya make -t --sancov --output /path/to/coverage/report

Эта команда запустит процесс тестирования с активацией санитайзеров для сбора данных о покрытии и сохранит полученный отчет в указанной директории.

Важные моменты

\- **Поддержка санитайзерами**: Не все санитайзеры могут поддерживать сбор данных о покрытии кода. Убедитесь, что используемые вами санитайзеры поддерживают эту функциональность.
\- **Производительность при тестировании**: Активация санитайзеров может существенно снизить производительность выполнения программ, поэтому следует учитывать потенциальное увеличение времени тестирования.
\- **Анализ отчетов о покрытии**: Интерпретация данных о покрытии требует внимательности, так как высокий процент покрытия не всегда означает высокое качество тестов.


Опция `--coverage-exclude-regexp=COVERAGE_EXCLUDE_REGEXP`  позволяет явно указать регулярное выражение (regexp), соответствующие пути к файлам или каталогам в проекте, которые следует исключить из отчета о покрытии кода. Таким образом, разработчики могут фильтровать и исключать специфические участки кода, которые по тем или иным причинам не должны учитываться при оценке покрытия тестами.

При активации этой опции и выполнении тестов с параллельным сбором данных о покрытии кода, система сборки применит заданное регулярное выражение для фильтрации путей файлов и директорий. Любые файлы или директории, пути которых совпадают с указанным регулярным выражением, будут исключены из финального отчета о покрытии кода. Это позволяет исключить из анализа вспомогательные библиотеки, тестовый код, сгенерированный код и прочие части проекта, которые не представляют интереса в контексте текущей задачи анализа.

 Преимущества использования `--coverage-exclude-regexp`

\- **Фокус на важных частях кода**: Позволяет сосредоточить анализ покрытия на значимых и критических участках кода, исключая шум от вспомогательных и предопределенных частей проекта.
\- **Улучшение производительности**: Исключение нерелевантных файлов и папок может сократить время выполнения анализа покрытия и размер генерируемого отчета, делая процесс более быстрым и эффективным.
\- **Удобство анализа отчетов**: Сокращение объема лишней информации в отчетах о покрытии упрощает их анализ и интерпретацию, позволяя быстрее принимать решения по улучшению качества кода.

 Пример использования

Предположим, что в проекте есть каталоги с автоматически сгенерированным кодом или с внешними библиотеками, которые не нужно учитывать при оценке покрытия кода. Для исключения этих каталогов можно использовать следующую команду с определенным регулярным выражением:

 ya make -t --coverage-exclude-regexp=‘/externals/\|/generated/’

В этом примере `'/externals/|/generated/'` является регулярным выражением, которое исключает все пути, содержащие `/externals/` или `/generated/`, тем самым убирая код из этих директорий из отчета о покрытии.

Важные моменты

\- **Точность регулярных выражений**: Необходимо точно формулировать регулярные выражения, чтобы избежать случайного исключения важного кода. Рекомендуется тестировать регулярные выражения на небольшом наборе данных перед применением их в большом проекте.
\- **Перекрестная проверка**: После применения фильтров стоит перекрестно проверить, что все необходимые участки кода попали в отчет о покрытии, и что исключения были применены корректно.



Опция `--coverage-prefix-filter=COVERAGE_PREFIX_FILTER` предназначена для фильтрации данных о покрытии кода по определенному шаблону пути в проектах, где включен сбор информации о покрытии кода. 

Эта функциональность важна для сосредоточения анализа покрытия на специфических участках проекта и исключения из отчетов о покрытии кода тех частей программы, анализ которых не представляет интереса или является нецелесообразным.

Когда активирована опция сбора данных о покрытии кода, процесс тестирования может собирать информацию о всех исполняемых строках кода в проекте. Это может привести к созданию очень обширных и детализированных отчетов, в которых информация о ключевых модулях или компонентах смешивается с данными о вспомогательных библиотеках, тестовых данных или автоматически сгенерированном коде. 

Чтобы избежать этого, опция `--coverage-prefix-filter` позволяет указать шаблон или префикс пути, ограничивая тем самым анализ покрытия только интересующими разработчиков директориями и файлами.

`COVERAGE_PREFIX_FILTER` — это шаблон пути (или несколько шаблонов, если их несколько), который указывает, какие файлы или директории следует анализировать на предмет покрытия кода тестами. 

Пути, не соответствующие указанному шаблону, будут исключены из анализа и отчета о покрытии.

 Пример использования

Предположим, проект содержит модули `src/` с основным кодом приложения и `lib/` с внешними зависимостями. Если требуется сосредоточить анализ покрытия кода только на модуле `src/`, можно использовать следующую команду:

 ya make -t --coverage-prefix-filter=src/

Эта команда скажет системе сборки собрать данные о покрытии кода, ограничив анализ путями, которые начинаются с `src/`, исключая из отчета код из директории `lib/` и других несоответствующих фильтру путей.

\- **Точность фильтрации**: Чем точнее задан фильтр, тем более релевантной будет информация в отчете о покрытии кода. Важно правильно указать шаблон, чтобы не исключить важные части кода из анализа.
\- **Производительность**: Фильтрация может сократить время анализа покрытия и размер генерируемых отчетов, что упрощает их последующий анализ и сокращает время, необходимое для обработки данных о покрытии кода.


Не описываем, устаревшее

\--coverage (устаревшее)
Собрать информацию о покрытии кода. (устаревший алиас для “–gcov --java-coverage --python-coverage --coverage-report”)


НЕ описываем

NLG, или Natural Language Generation, это процесс генерирования естественного языка компьютером. Это одна из областей искусственного интеллекта и вычислительной лингвистики, которая охватывает создание текста на естественном языке из структурированных данных.

\--nlg-coverage Собрать информацию о покрытии NLG для Alice


Опция `--coverage-report` в системах сборки используется для создания подробного отчёта о покрытии кода в формате HTML, который является визуальным и удобным средством для анализа покрытия кода тестами. Эта опция должна использоваться в сочетании с опцией `--output`, которая указывает место для сохранения сгенерированного отчёта.

Когда вы запускаете процесс тестирования с активированным сбором информации о покрытии кода, опция `--coverage-report` запускает дополнительный процесс по обработке собранных данных о покрытии и генерации на их основе отчёта в HTML формате. Этот отчет содержит детализированную информацию о проценте покрытия кода тестами, выделяя те участки кода, которые были исполнены во время тестирования, и те, которые остались без внимания.

 **Визуализация**: HTML отчет обладает высокой читаемостью и удобен для анализа. Он может предоставлять графики, цветовые индикаторы и навигацию по коду проекта для более глубокого понимания покрытия.


Использование `--coverage-report` с `--output`

Для генерации HTML отчета о покрытии кода следует использовать опцию `--coverage-report` вместе с `--output`, указывая директорию для сохранения отчета. Например:

 ya make -all --coverage-report --output /path/to/coverage/report


Эта команда запустит процесс сборки и тестирования с активацией сбора данных о покрытии кода и последующей генерацией HTML отчета, который будет сохранен в указанной директории.

Опция `--clang-coverage`  используется для активации сбора информации о покрытии кода (code coverage) для проектов, написанных на языках C и C\+\+, с использованием компилятора Clang. 

Функция покрытия кода — это критически важная практика в процессе разработки программного обеспечения, позволяющая измерить, какая часть кода была выполнена в процессе тестирования, выявляя неохваченные участки кода, которые потенциально могут содержать ошибки или уязвимости.

Эта опция включает инструменты Clang для сбора данных о покрытии исходного кода при выполнении тестов. Clang поддерживает различные механизмы для измерения покрытия кода, в том числе Source-based Code Coverage, который обеспечивает подробный и точный анализ покрытия с минимальным влиянием на производительность исполняемых тестов. 

Этот подход базируется на использовании профилировщика LLVM, который собирает информацию о исполнении кода во время выполнения программы, записывая данные о количестве проходов каждой строки кода или исполнении каждой ветви условий.

Повышение таймаута тестов

Собрать информацию о покрытии кода интенсивнее в плане использования ресурсов, по сравнению с обычным процессом тестирования. В связи с этим опция `--clang-coverage` автоматически увеличивает таймаут тестов в 1.5 раза, чтобы обеспечить достаточно времени для сбора всех необходимых данных о покрытии без риска прерывания теста из-за превышения лимита времени.

 Пример использования

Для активации сбора информации о покрытии кода в проекте при помощи Clang, используйте команду:

 ya make -t --clang-coverage


\- **Выбор компилятора**: Убедитесь, что ваш проект компилируется с использованием компилятора Clang, так как опция `--clang-coverage` рассчитана на инструментарий именно этого компилятора.


Опция `--java-coverage`  предназначена для активации сбора данных о покрытии кода в проектах на языке программирования Java. Сбор информации о покрытии кода является важным элементом в процессе разработки и тестирования программного обеспечения, поскольку он позволяет оценить, какую часть кода затрагивают выполненные тесты, выявить части кода, не покрытые тестами, и определить потенциальные уязвимые места в логике приложения.

Использование опции `--java-coverage` при запуске сборки проекта или его тестов задействует инструменты для сбора данных о покрытии кода в Java, такие как JaCoCo (Java Code Coverage), Emma или Cobertura. Эти инструменты анализируют, какие строки и ветви кода исполняются при запуске автоматизированных тестов (например, JUnit тестов), и генерируют отчеты о покрытии, которые помогают разработчикам оптимизировать набор тестов и обеспечивают более высокое качество кода.

\- **Определение покрытия тестами**: Информация о том, какие конкретно участки кода были задействованы при выполнении тестов, помогает разработчикам локализовать участки, требующие дополнительного внимания, и написания новых тестов.

Пример использования

Допустим, вы разрабатываете Java-проект и хотите убедиться в том, что ваши тесты покрывают достаточный объем кода. В этом случае вы бы использовали команду сборки с опцией `--java-coverage`, чтобы активировать сбор данных о покрытии:

ya make -t --java-coverage

После выполнения тестов система сборки сгенерирует отчет о покрытии кода, который вы можете просмотреть, чтобы оценить эффективность текущих тестов и определить области кода без достаточного покрытия.

\- **Выбор инструмента покрытия**: В зависимости от того, какой инструмент используется для сбора данных о покрытии (JaCoCo, Emma, Cobertura), могут отличаться методы генерации и форматы отчетов о покрытии. Стоит выбрать тот инструмент, который наилучшим образом соответствует потребностям проекта и интеграции с системами CI/CD.


Опция `--go-coverage` в системе сборки применяется для сбора информации о покрытии кода в проектах, написанных на языке программирования Go. Это критически важная функциональность для оценки эффективности существующего набора тестов и идентификации участков кода, которые не покрываются тестами, что позволяет повысить качество и надёжность программного обеспечения.

При использовании опции `--go-coverage` , система сборки активирует инструментарий Go для измерения покрытия кода тестами. В Go средство покрытия встроено непосредственно в стандартный пакет `go test`, который не только выполняет тесты, но и может собирать данные о покрытии кода при добавлении флага `-cover`.

Процесс сбора покрытия работает за счет внедрения специальных аннотаций в исходный код перед его выполнением, что позволяет инструменту отслеживать, какие строки кода были выполнены во время тестирования. После завершения выполнения тестов данные покрытия собираются и обычно представляются в виде отчета.

\- **Улучшение тестового покрытия**: С помощью отчётов о покрытии кода можно определить, какие именно участки кода были или не были исполнены во время тестов, что дает возможность разработчикам создать дополнительные тесты для неохваченных областей.
\- **Повышение качества кода**: Информация о покрытии кода помогает обеспечить, что все важные части программы тщательно протестированы, уменьшая количество ошибок и повышая общую надёжность программного продукта.

Пример использования

Если вы работаете над проектом на Go и хотите получить отчёт о покрытии кода тестами, вы могли бы использовать следующую команду:

 ya make -t --go-coverage


Эта команда запустит доступные тесты для вашего проекта и соберёт данные о покрытии кода. 


Опция `--ts-coverage` в системе сборки служит для сбора информации о покрытии кода специально для проектов на TypeScript. Покрытие кода (code coverage) — критически важная метрика для оценки качества тестирования программного обеспечения, которая показывает, какая часть кода была исполнена в процессе запуска тестов.

Цель этой метрики — предоставить четкое понимание того, какие участки кода были проверены тестами, а какие остались без внимания. Это позволяет разработчикам улучшить качество тестов и уверенно вносить изменения в код.

Сбор данных о покрытии кода для TypeScript

TypeScript является надмножеством JavaScript, добавляющим строгую типизацию и другие функции для улучшения масштабируемости и поддержки кода. По своей сути, после компиляции TypeScript-код преобразуется в JavaScript, который уже и выполняется в целевой среде (например, в браузере или на сервере Node.js).

Опция `--ts-coverage` активирует инструменты, которые анализируют, какие части исходного кода на TypeScript были исполнены во время тестирования, и генерируют отчеты о покрытии. Для этого могут использоваться специализированные инструменты покрытия, адаптированные или совместимые с TypeScript, такие как Istanbul (nyc), которые могут работать с исходным кодом на TypeScript напрямую или через его карты кода (source maps).

Преимущества использования `--ts-coverage`

\- **Улучшенное тестирование**: Предоставление данных о покрытии кода напрямую для TypeScript позволяет разработчикам напрямую видеть, какие именно участки типизированного кода охвачены тестами, что особенно важно для выявления неочевидных проблем, связанных с типами.
\- **Оптимизация тестов**: Информация о покрытии помогает определить участки кода, которые не покрыты тестами, что позволяет оптимизировать дальнейшую разработку тестов и сосредоточить усилия на ключевых областях.

Как использовать `--ts-coverage`

Во время запуска процесса тестирования проекта через систему сборки добавление опции `--ts-coverage` активирует сбор данных:

ya make -t --ts-coverage

Важные моменты и ограничения

\- **Инструменты покрытия**: Проверьте совместимость используемых инструментов для анализа покрытия с TypeScript, так как некоторые инструменты могут требовать дополнительной настройки или использования плагинов.
\- **Компиляция TypeScript**: Поскольку TypeScript компилируется в JavaScript, важно убедиться, что механизм покрытия кода корректно учитывает карты кода (source maps) для правильного отображения информации о покрытии на исходные файлы TypeScript.
\- **Обработка результатов**: Понимание и анализ отчетов о покрытии кода требует внимательного рассмотрения, особенно в свете специфики TypeScript, таких как его система типов и компиляция в JavaScript.


Опция `--python-coverage` призвана активировать сбор информации о покрытии кода (code coverage) для проектов, написанных на Python, в рамках процесса тестирования. Покрытие кода — это метрика, используемая для измерения степени, в которой исходный код программы исполнен при тестировании. Эта метрика позволяет разработчикам понять, какие части кода были и не были проверены тестами, выделяя области, которые потенциально могут содержать непойманные ошибки.

Запуская тесты с использованием `--python-coverage`, система сборки интегрируется с инструментами покрытия кода Python (например, с популярной утилитой `coverage.py`), чтобы автоматически измерить и собрать данные о том, какие строки кода были выполнены в процессе исполнения тестов. По завершении тестов собранная информация о покрытии кода обычно представляется в форме детальных отчётов, которые могут содержать процент покрытия, а также указывать конкретные строки кода, которые не были исполнены.

Применение

Опция `--python-coverage` наиболее ценна в контекстах, где разработчики стремятся улучшить качество кода и надежность программного обеспечения, так как позволяет:

1\. **Идентифицировать пробелы в тестовом покрытии**: Помогает выявить части кода, которые не покрыты тестами, и может служить руководством для разработки дополнительных тестов.
2\. **Оптимизировать существующие тесты**: Позволяет разработчикам определить избыточные тесты, которые не увеличивают общее покрытие кода, и тем самым оптимизировать тестовую среду.
3\. **Повысить надежность программного обеспечения**: Путем сосредоточения внимания на увеличении покрытия тестами критически важных частей кода.

 Пример использования

Допустим, ваш проект содержит множество Python модулей, и вы хотели бы получить общее представление о покрытии кода тестами. Для этого можно запустить следующую команду в системе сборки:

 ya make -t --python-coverage

После выполнения тестов система сборки генерирует отчет о покрытии кода, который можно анализировать для дальнейших улучшений в тестовом покрытии.

Покрытие кода в системах сборки — это метрика, используемая для измерения степени, в которой исходный код программы испытан автоматическими тестами. Она выражается в процентах и показывает, какая часть кода была выполнена при запуске тестов, помогая определить не протестированные участки кода.

Покрытие кода помогает разработчикам улучшить качество программного обеспечения, указывая на то, какие части кода нуждаются в дополнительном тестировании. В контексте систем сборки, инструменты для измерения покрытия кода могут интегрироваться с процессом сборки для автоматического создания отчетов о покрытии после каждого выполнения тестов. Это позволяет командам разработчиков быстро идентифицировать риски, связанные с недостаточным тестовым покрытием, и принимать меры для их устранения.

## Fuzzing (методика фаззинга)

https://st.yandex-team.ru/DOCSUP-69387

Опция `--fuzzing` используется в контексте разработки программного обеспечения для активации процесса фаззинга, то есть автоматического тестирования приложения или его компонентов путем подачи на вход большого количества случайных, некорректных или неожиданных данных. 

Цель фаззинга - выявление ошибок, уязвимостей или нестабильностей в работе тестируемого кода, которые могут проявляться при непредвиденных условиях ввода.

 Принцип работы фаззинга 

При использовании опции `--fuzzing`, система сборки инструктируется запустить процесс фаззинга для указанного модуля (или модулей), создав исполняемый файл (fuzzer), который затем будет запущен для генерации и подачи случайных данных на вход тестируемого компонента.

Для эффективного фаззинга рекомендуется, чтобы тестируемая функция (`LLVMFuzzerTestOneInput` в случае использования libFuzzer) была как можно более изолированной и конкретизированной, с минимальной зависимостью от остального кода приложения. Это позволяет фаззеру более эффективно исследовать возможное поведение функции и обнаруживать потенциальные проблемы.

 Использование опции `--fuzzing` с libFuzzer

Чтобы начать фаззинг с libFuzzer, необходимо скомпилировать FUZZ модуль с указанием дополнительных опций санитайзера и покрытия. Санитайзеры (например, AddressSanitizer) помогают фаззеру определять различные типы ошибок во время выполнения (например, доступ к памяти за пределами массива), а опции покрытия позволяют libFuzzer определить, приводят ли новые входные данные к достижению новых участков кода.

Пример команды для сборки с libFuzzer:

 ya make -A --sanitize=address --sanitize-coverage=trace-div,trace-gep

Использование опции `--fuzzing` с AFL

Для фаззинга с AFL (American Fuzzy Lop), команда сборки будет аналогичной, но с другим набором опций:

 ya make -A --sanitize=undefined --sanitize-coverage=trace-pc

АFL использует другой подход к мониторингу выполнения кода, что отражается в опциях сборки.

 Пример применения `--fuzzing`

1\. **Создание модуля FUZZ**:
Создание файла с реализацией `LLVMFuzzerTestOneInput`, которая содержит код, подлежащий фаззингу.

2\. **Сборка модуля с опциями фаззинга**:

 ya make -A --sanitize=address --sanitize-coverage=trace-div,trace-gep --fuzzing

3\. **Запуск**:
После сборки исполняемый файл (fuzzer) готов к запуску. libFuzzer или AFL начнет генерировать входные данные и подавать их на вход функции `LLVMFuzzerTestOneInput`.

4\. **Анализ результатов**:
По завершении или во время фаззинга анализируются результаты работы fuzzer, включая найденные краш-тесты и утечки памяти.

Использование опции `--fuzzing` c санитайзерами и опциями покрытия является ключевым элементом процесса обнаружения многих классов ошибок в программном обеспечении. Это позволяет значительно повысить надежность и безопасность разрабатываемых приложений.


Опция `--fuzz-case=FUZZ_CASE_FILENAME` предназначена для указания конкретного тестового случая (case) или файла с данными, который будет использоваться при фаззинге тестируемого компонента или приложения. Эта опция предназначена для ситуаций, когда необходимо запустить фаззер с конкретным набором данных, а не позволять ему генерировать данные случайным образом, как это происходит в режиме стандартного фаззинга (`--fuzzing`).

 Контекст использования

Фаззинг — это процесс автоматического тестирования программного обеспечения путем генерации большого количества случайных входных данных для выявления ошибок, уязвимостей или других проблем в поведении тестируемой системы. В ряде случаев возникает необходимость запустить фаззер с заранее определенным набором входных данных, например, для воспроизведения ошибки или более детального анализа поведения программы в конкретных условиях. Для этих целей и используется опция `--fuzz-case`.

Объяснение и пример использования

Предположим, что в ходе предыдущего прогона фаззинга был найден интересный кейс, который приводит к ошибке, и теперь необходимо детальнее исследовать поведение программы на этом конкретном примере. Путь к файлу с данными для этого кейса - `crash_case1.dat`.

Тогда команда для запуска теста с использованием этого кейса будет выглядеть следующим образом:

 ya make -r --sanitize=address --sanitize-coverage=trace-div,trace-gep -A --fuzz-case=crash_case1.dat



В этом примере:
\- `--sanitize=address` и `--sanitize-coverage=trace-div,trace-gep` - указания для использования санитайзера и соответствующих опций покрытия, что позволяет обнаруживать различные виды ошибок,
\- `--fuzz-case=crash_case1.dat` - команда для запуска теста с конкретным файлом данных.

 Важные детали

\- Опция `--fuzz-case` предназначена для запуска фаззера с предопределенным набором входных данных и конфликтует с опцией `--fuzzing`, которая активирует процесс генерации случайных входных данных фаззером.
\- Это значит, что использование `--fuzz-case` будет запускать тестируемое приложение или функцию ровно один раз с данными из указанного файла, а не подвергать их повторному фаззингу.
\- Данный подход применяется для узкоспециализированных тестов, направленных на проверку конкретных условий или на воспроизведение ранее обнаруженных ошибок.


Опция `--fuzz-opts=FUZZ_OPTS` представляет собой мощный способ настройки процесса фаззинга за счет предоставления возможности напрямую передавать специальные параметры или опции в инструмент фаззинга, такой как libFuzzer или AFL. Эти параметры могут контролировать поведение фаззера, например, изменяя стратегию генерации данных, устанавливая ограничения времени или памяти на исполнение, а также включая специфические механизмы отладки или логирования.

Принцип работы

Когда вы используете фаззинг в процессе разработки программного обеспечения, особенно в больших и сложных проектах, может возникнуть потребность в более детальном контроле над процессом. Например, вы можете обнаружить, что для более эффективного поиска уязвимостей нужно сконцентрироваться на определенных аспектах приложения или увеличить время выполнения фаззинга для более глубокого анализа. Именно тут и пригождается опция `--fuzz-opts`.

 Пример использования с libFuzzer

Допустим, вы используете libFuzzer для фаззинга некоторой функции в вашем приложении и хотите ограничить расход памяти для процесса фаззинга, а также установить максимальное время работы фаззера. В этом случае ваша команда для запуска фаззинга может выглядеть так:
 ya make -r --sanitize=address --sanitize-coverage=trace-pc -A --fuzz-opts=“-rss_limit_mb=2048 -max_total_time=3600”

В данном примере:
\- `-rss_limit_mb=2048` указывает максимальный расход памяти на уровне 2 ГБ,
\- `-max_total_time=3600` ограничивает время работы фаззера одним часом.

 Разъяснения

\- `--fuzz-opts` принимает строку с параметрами, разделенными пробелами. Эта строка передается напрямую фаззеру в момент его запуска.
\- Важно точно знать, какие параметры поддерживает ваш инструмент фаззинга, так как они могут отличаться между различными фаззерами (libFuzzer, AFL и т.д.).
\- Опция позволяет не только изменять параметры отладки и исполнения, но и влиять на стратегию генерации входных данных, что может быть критично для выявления скрытых уязвимостей в программе.

 Важные детали и рекомендации

\- Перед использованием любых опций рекомендуется ознакомиться с документацией выбранного инструмента фаззинга.
\- Используйте опцию `--fuzz-opts` с осторожностью в сценариях автоматизированного тестирования, так как слишком жесткие ограничения или специфические стратегии могут снизить вероятность обнаружения уязвимостей.
\- Рассмотрите возможность использования опции для тонкой настройки процесса фаззинга в соответствии с особенностями вашего проекта для достижения наилучших результатов тестирования.


Опция `--fuzz-minimization-only` является специализированным параметром командной строки, используемым в контексте фаззинга программ или тестов. Фаззинг — это техника тестирования программного обеспечения, которая автоматически вводит различные входные данные (часто случайные или искусственно сгенерированные) в программу с целью выявления ошибок или уязвимостей. 

Для эффективности фаззинга важна не только генерация входных данных, но и их последующая оптимизация. Корпус (corpus) фаззинга — это набор данных или тестовых случаев, используемый фаззером для проверки программы. Со временем корпус может стать слишком большим, содержать избыточные или неэффективные тесты, что замедляет процесс тестирования и затрудняет анализ результатов.

Опция `--fuzz-minimization-only` служит для активации режима, в котором проводится минимизация корпуса фаззинга без дополнительного его расширения путем поиска новых входных данных. Это означает, что система будет анализировать существующий набор данных на предмет их значимости и уникальности воздействия на тестируемую программу, удаляя те, что не приводят к новым сценариям в коде или похожи на уже существующие в корпусе.

Пример использования:
ya make -t --fuzzing --fuzz-minimization-only

В данном контексте ключ `--fuzzing` указывает на то, что процесс будет выполняться в рамках фаззинг-сессии, а `--fuzz-minimization-only` направляет действия исключительно на минимизацию, не пытаясь расширить корпус за счет новых тестов.

Таким образом, опция `--fuzz-minimization-only` предоставляет следующие преимущества:
1\. **Оптимизация корпуса**: Удаляет неэффективные и избыточные данные из корпуса, что может ускорить последующие сессии фаззинга.
2\. **Улучшение анализа результатов**: Помогает сосредоточиться на более значимых и разнообразных тестах, упрощая анализ выявленных проблем.
3\. **Экономия ресурсов**: Редуцирует размер корпуса, что может снизить требования к хранилищу и вычислительным ресурсам.


Опция `--fuzz-local-store` используется в контексте фаззинг-тестирования программного обеспечения и представляет собой ключ, который модифицирует стандартное поведение сохранения результатов фаззинга, а именно добытого (или “майненного”) корпуса входных данных. Давайте разберемся подробно, что это означает и в каких случаях может быть полезно.

 Что такое фаззинг?

Фаззинг — это методика тестирования программного обеспечения, которая автоматизированно подает на вход тестируемой программы большое количество различных, в том числе случайно сгенерированных, данных с целью найти ошибки обработки непредвиденных или граничных значений входных данных. “Добытый корпус” — это набор входных данных, который был специально отобран или сгенерирован в процессе фаззинга. Эти данные уникальны тем, что приводят к интересным, необычным, или ошибочным путям выполнения в коде программы.

Стандартное поведение

По умолчанию, когда вы выполняете фаззинг с использованием инструментов, интегрированных в сборочную систему, например `ya make`, после завершения фаззинг-сессии полученный корпус данных обычно сохраняется в облачное хранилище или в специализированную систему управления тестовыми данными. Это позволяет легко переиспользовать добытый корпус в дальнейшем для повторных тестов, а также обмениваться данными с другими участниками проекта.

Опция --fuzz-local-store

Использование опции `--fuzz-local-store` модифицирует это поведение. Вместо загрузки добытого корпуса в облачное хранилище или специализированную систему, результаты сохраняются локально на машине, где выполняется тест. Это может быть полезно в различных ситуациях:

1\. **Разработка и отладка фаззеров**: В процессе создания и настройки нового фаззера или теста часто возникает необходимость быстро анализировать результаты без загрузки данных в удаленное хранилище.
2\. **Локальные эксперименты**: Иногда разработчикам необходимо провести серию экспериментов локально, прежде чем результаты будут готовы к общему доступу.
3\. **Ограниченное сетевое подключение**: В условиях ограниченного интернет-соединения или политики безопасности, предотвращающей загрузку данных внешним сервисам, сохранение результатов локально позволяет продолжить эффективную работу.

Использование опции `--fuzz-local-store`  позволяет конкретизировать анализ и оптимизировать следующие шаги в разработке и тестировании ПО.


Опция `--fuzz-runs=FUZZ_RUNS` представляет собой параметр командной строки, используемый в контексте фаззинга — техники тестирования программного обеспечения, которая включает автоматическую генерацию входных данных для программы в целях обнаружения ошибок обработки этих данных. Этот параметр позволяет контролировать количество индивидуальных запусков теста (или, другими словами, количество “итераций” фаззинга), которое должно быть выполнено в рамках сессии фаззинга.

Понятие “индивидуальных запусков тестов”

Под “индивидуальным запуском” понимается однократное исполнение целевой функции или программы с определенным набором входных данных, сгенерированных фаззером. Каждый такой запуск направлен на проверку реакции программы на уникальные данные входа, что дает возможность обнаружить потенциальные уязвимости или некорректные обработки различных ситуаций, которые могут возникнуть в процессе исполнения.

 Зачем контролировать количество запусков

Управление количеством запусков тестов важно по нескольким причинам:

1\. **Ограничение ресурсов**: Мощность вычислительных ресурсов, доступных для фаззинга, может быть ограничена. Указание максимального числа запусков помогает провести тестирование в пределах доступных ресурсов.

2\. **Управление временем фаззинг-сессии**: Время — критический ресурс в процессе разработки. Определенные задачи или циклы разработки могут требовать выполнения фаззинга в заданных временных рамках, и контроль за числом запусков позволяет соответствовать этим требованиям.

3\. **Регулирование глубины тестирования**: Более высокое количество запусков увеличивает глубину тестирования, предоставляя фаззеру больше возможностей для генерации и проверки разнообразных входных данных. Напротив, меньшее количество запусков может подходить для поверхностной проверки или при отладке фаззинг-процесса.

Пример использования
 ya make -t --fuzzing --sanitize=address --fuzz-runs=10000

В данном примере утилита сборки (`ya make`) запускает фаззинг с инструментацией адресного санитайзера (`--sanitize=address`), и процесс фаззинга будет ограничен 10,000 индивидуальными запусками тестов (`--fuzz-runs=10000`).

Заключение

Использование параметра `--fuzz-runs=FUZZ_RUNS` позволяет более гибко настраивать процесс фаззинг-тестирования, сбалансированно распределяя вычислительные и временные ресурсы, а также адаптируя стратегию тестирования под конкретные цели и задачи. Это ключевой инструмент в арсенале разработчика или тестировщика, стремящегося к максимальной эффективности и результативности фаззинг-процесса.


Опция `--fuzz-proof=FUZZ_PROOF` представляет собой параметр командной строки, использующийся в процессе фаззинг-тестирования программного обеспечения для выполнения особого этапа фаззинга — доказательства стабильности корпуса (corpus). Параметр `FUZZ_PROOF` задается в секундах и определяет продолжительность дополнительного этапа фаззинга, начиная с момента обнаружения последнего интересного (приводящего к новому поведению программы) случая тестовых данных.

 Цель опции --fuzz-proof

Целью использования данной опции является подтверждение того, что корпус тестовых данных (входных значений для фаззинга), сгенерированный либо обновленный на предыдущих этапах сессии фаззинга, является достаточно полным и устойчивым. Другими словами, этот дополнительный этап фаззинга направлен на подтверждение того, что дальнейшее продолжение фаззинга вряд ли приведет к обнаружению новых ошибок или уязвимостей в тестируемом программном обеспечении за указанный промежуток времени. Это может быть полезно в процессе подготовки к релизам или для оценки эффективности и полноты существующего корпуса тестов.

Как это работает

\- Если в течение установленного времени `FUZZ_PROOF` (после последнего найденного интересного кейса) фаззер не обнаруживает новых кейсов, которые приводят к неизведанным ранее путям выполнения программы, фаззинг завершается с успехом. Это подтверждает, что корпус достаточно хорош для текущего состояния программного обеспечения.

\- Если за время `FUZZ_PROOF` фаззер находит новые интересные кейсы, фаззинг завершается с ошибкой (или предупреждением, в зависимости от контекста выполнения и настройки среды), указывая на то, что корпус еще можно улучшить.

Пример использования

Предположим, что после проведения фаззинга на протяжении некоторого времени с корпусом тестов вы хотите убедиться, что в течение следующего часа (3600 секунд) фаззер не сможет найти новых интересных кейсов:

 ya make -t --fuzzing --sanitize=address --fuzz-proof=3600

Данный запуск фаззинга добавляет дополнительный этап, длительностью в час, с тем чтобы подтвердить устойчивость текущего корпуса к дальнейшему поиску уникальных кейсов.

Использование опции `--fuzz-proof=FUZZ_PROOF` предоставляет возможность получить дополнительную уверенность в том, что тесты в текущем корпусе обеспечивают достаточное покрытие кода, а фаззинг-сессия исчерпала свои возможности в выявлении новых уязвимостей на данном этапе разработки. Это помогает разработчикам сфокусировать усилия на исправлении уже известных проблем, имея подтверждение о высоком качестве тестового фаззинга корпуса.


Опция `--fuzz-minimize`  указывает инструменту фаззинга на необходимость выполнения процесса минимизации корпуса тестовых данных сразу после завершения основного этапа фаззинга. 

Давайте разберемся, что это значит на практике и почему это важно.

Фаззинг — это процесс автоматического тестирования программного обеспечения путем подачи на вход тестируемой программы большого количества различных, часто случайно сгенерированных, входных данных (тестов). Цель фаззинга — обнаружить ошибки в программе, которые могут привести к сбоям, утечкам памяти, нарушениям безопасности и другим нежелательным последствиям.

 Корпус тестов и его минимизация

Ключевым элементом фаззинга является корпус тестов — набор данных, который используется фаззером для проверки программы. Корпус должен быть достаточно обширным и разнообразным, чтобы обеспечивать эффективное тестирование, но в то же время оптимизированным, чтобы не тратить ресурсы на проверку избыточных или повторяющихся тестов.

Минимизация корпуса — это процесс удаления из корпуса лишних тестов, которые не увеличивают покрытие кода, а также попыток уменьшить размер отдельных тестов без потери “интересности” для фаззера. Эта операция помогает ускорить последующие запуски фаззинга и упрощает анализ результатов.

 Опция --fuzz-minimize

Использование опции `--fuzz-minimize` гарантирует, что после каждого сеанса фаззинга будет автоматически выполнена минимизация корпуса тестов. Это особенно актуально при работе с фаззерами, как libFuzzer, где такой подход может значительно улучшить эффективность фаззинга за счет сокращения времени исполнения тестов и упрощения процесса нахождения и исправления ошибок.

Зачем использовать --fuzz-minimize

\- **Эффективность:** Минимизированный корпус позволяет фаззеру быстрее проходить через тесты, тем самым увеличивая шансы обнаружения новых ошибок за тот же период времени.
\- **Экономия ресурсов:** Сокращение размера корпуса помогает сэкономить дисковое пространство и уменьшить нагрузку на систему.
\- **Упрощение анализа результатов:** Анализ ошибок и уязвимостей становится проще, когда корпус не содержит избыточных данных.

Пример использования

ya make -t --fuzzing --sanitize=address --fuzz-minimize

В данном примере, кроме выполнения фаззинга с адресным санитайзером, указывается необходимость минимизации корпуса после завершения фаззинга.

Опция `--fuzz-minimize`  позволяет не только увеличить эффективность тестирования за счет сокращения времени на прохождение корпуса, но и облегчает процесс нахождения и исправления ошибок благодаря более четкому и сжатому набору тестов.


Опция `--test-log-level=TEST_LOG_LEVEL` является параметром командной строки для настройки уровня логирования в процессе выполнения тестов, в частности, при использовании фреймворка Pytest для языка Python. Этот параметр позволяет контролировать, какой объем сообщений лога будет выводиться в процессе тестирования, делая вывод информации более релевантным для текущих задач и предпочтений пользователя.

Уровни логирования

Уровни логирования определяют приоритет лог-сообщений и позволяют фильтровать вывод так, чтобы отображались только сообщения от установленного уровня и выше. Возможные значения `TEST_LOG_LEVEL` включают:

\- `debug`: самый низкий уровень, выводит наибольшее количество информации, включая отладочные сообщения.
\- `info`: отображает информационные сообщения, которые могут быть полезны для понимания хода выполнения программы, помимо предупреждений и ошибок.
\- `warning`: выводит предупреждения, которые указывают на потенциальные проблемы, требующие внимания, а также ошибки.
\- `error`: демонстрирует только сообщения об ошибках, которые указывают на непредвиденные проблемы в программе, требующие исправления.
\- `critical`: самый высокий уровень, отображает только критические ошибки, которые могут потребовать немедленного внимания.

Выбор подходящего уровня логирования зависит от цели тестирования. Например, при настройке и отладке тестов может быть полезен уровень `debug`, чтобы получить максимум информации. В то же время, для регулярного выполнения тестов в рамках CI/CD процесса может быть предпочтительнее использовать уровень `info` или `warning`, чтобы сократить объем выводимой информации и фокусироваться только на наиболее значимых сообщениях.


Опция `--test-traceback=TEST_TRACEBACK` представляет собой параметр командной строки, используемый совместно с фреймворком Pytest для Python-проектов. Этот параметр позволяет настроить формат вывода трассировки стека (stack trace) при возникновении ошибок во время выполнения тестов. В зависимости от выбранной опции, трассировки могут быть представлены в различных форматах, что может упростить процесс отладки и ускорить нахождение причин сбоев.

Варианты значений параметра TEST_TRACEBACK:

\- `long`: Этот режим является наиболее подробным и выводит полную трассировку стека для каждой ошибки. Помимо стандартной информации о месте возникновения ошибки, `long` позволяет видеть контекст вызовов функций и цепочки вложенных вызовов, которые привели к ошибке.

\- `short`: По умолчанию Pytest использует этот формат. Он предоставляет сокращенную версию трассировки стека, фокусируясь на самом важном и исключая менее значимые детали. Обычно включает в себя информацию о месте возникновения непосредственной ошибки.

\- `line`: Отображает только одну строку для каждой ошибки, которая указывает на место в коде, где ошибка была обнаружена. Этот формат полезен для получения быстрого обзора ошибок без глубокой детализации.

\- `native`: Выводит трассировку стека в формате, стандартном для самого Python, без применения специфических для Pytest модификаций и улучшений. Может быть полезно для разработчиков, предпочитающих работать с трассировкой в “сыром” виде.

\- `no`: Полностью отключает вывод трассировки стека при возникновении ошибок в тестах. Этот режим может быть удобен при необходимости минимизировать количество информации в отчетах о тестировании.

 Пример использования:

Для запуска тестов с настройкой вывода трассировки стека можно использовать следующую команду:

 pytest --test-traceback=long


Это заставит Pytest вывести полную трассировку стека для каждой ошибки, встреченной во время выполнения тестов.

Важность выбора формата трассировки:

Формат трассировки стека может существенно повлиять на эффективность отладки. В то время как полный формат (`long`) предоставляет исчерпывающую информацию для глубокого анализа проблемы, более сокращенные форматы (`short`, `line`, `no`) позволяют быстрее получить общее представление об ошибке и сократить время на просмотр результатов тестов. Выбор подходящего режима зависит от конкретной задачи и предпочтений разработчика.


Опция `--profile-pytest` представляет собой специализированный инструмент для профилирования тестов, написанных с использованием фреймворка Pytest в Python. Эта опция активирует процесс профилирования с помощью модуля `cProfile`, который является стандартным модулем профилирования в Python, и обрабатывает результаты для предоставления более детального и визуализированного представления данных о производительности тестов.

 Как работает профилирование с `--profile-pytest`

1\. **Сбор данных профилирования**: Включение опции `--profile-pytest` инициирует запуск тестов с одновременным сбором данных профилирования при помощи `cProfile`. Это включает информацию о времени выполнения различных частей тестового кода, количество вызовов функций и другие метрики производительности, что позволяет идентифицировать узкие места в тестах и коде, который они тестируют.

2\. **Вывод в stderr**: По завершении тестов данные профилирования сбрасываются непосредственно в стандартный поток ошибок (stderr). Это дает немедленное текстовое представление о производительности без необходимости останавливаться на анализе и интерпретации сложных файлов или использовании дополнительных инструментов для чтения результатов.

3\. **Генерация `pytest.profile.dot`**: Кроме текстового вывода в stderr, создается файл в формате DOT (`pytest.profile.dot`), который затем может быть использован для генерации графика вызовов функций. Этот файл сохраняется в директории `testing_out_stuff/`, что облегчает его последующий анализ.

4\. **Использование `gprof2dot` для визуализации**: Файл `.dot`, сгенерированный на предыдущем шаге, обработывается утилитой `gprof2dot` для создания визуализации графа вызовов функций. `gprof2dot` — это инструмент командной строки, который может трансформировать данные профилирования в цветной график, иллюстрирующий, какие функции вызываются, сколько времени они выполняются, и как они связаны друг с другом. Для создания графического представления из `.dot` файла потребуется дополнительный инструмент, например Graphviz.

Использование `--profile-pytest` дает глубокое понимание временных затрат на различные участки кода в тестах. Это особенно полезно при оптимизации тестов с большим временем выполнения, а также при поиске и исправлении участков кода приложения, которые могут стать причиной снижения производительности.

 Пример команды

 ya make -t  --profile-pytest


Эта команда запустит тесты с активированным профилированием, результаты которого будут доступны как непосредственно в командной строке, так и в виде визуализированного графика после обработки сгенерированного файла с помощью `gprof2dot` и Graphviz.


Опция `--pytest-args=PYTEST_ARGS` представляет собой параметр командной строки, который поддерживается инструментами и средствами сборки, интегрированными с фреймворком Pytest для проведения тестирования кода на Python. Этот параметр позволяет пользователям передавать дополнительные аргументы и опции непосредственно в Pytest, расширяя стандартное поведение или настройки запуска тестов. 

Основной контекст использования

Pytest является мощным инструментом для тестирования кода на Python и обладает многими возможностями для конфигурации тестовых сессий благодаря широкому спектру поддерживаемых аргументов командной строки. Однако при запуске Pytest не напрямую, а через обертки или другие инструменты (например, в контексте интеграций с системами сборки), может возникнуть необходимость дополнительно настроить поведение Pytest. Вот тут и приходит на помощь опция `--pytest-args`.

Примеры аргументов Pytest
Возможности Pytest, которые можно настроить с помощью `--pytest-args`, включают, но не ограничиваются следующим:

\- Задание пути к тестам: можно указать конкретные файлы или директории для запуска;
\- Управление выводом: настроить уровень детализации выводимой информации (`-v` для более подробного вывода, `-q` для более тихого);
\- Маркировка тестов: запуск только тех тестов, которые отмечены определенными метками (`-m`), что позволяет гибко управлять наборами тестов;
\- Параллельное выполнение тестов: при наличии плагина `pytest-xdist`, можно распределить тесты на несколько процессов для их параллельного выполнения (`-n`);

Как использовать `--pytest-args`

Допустим, вы хотите запустить Pytest с определенным набором аргументов через инструмент сборки или обертку. В этом случае вы воспользуетесь параметром `--pytest-args`, за которым следует строка с аргументами Pytest:

 ya make --pytest-args=“-v -k some_test_function”


В приведенном выше примере `some-build-tool` — это гипотетический инструмент, поддерживающий интеграцию с Pytest. Параметр `--pytest-args="-v -k some_test_function"` говорит инструменту, что необходимо запустить Pytest в более подробном режиме (`-v`) и выполнить только тесты, название которых соответствует выражению `some_test_function` (`-k some_test_function`).

## Специфика тестов Java

https://st.yandex-team.ru/DOCSUP-69420

Опция `--system-property=PROPERTIES` (или в сокращенной форме `-R=PROPERTIES`) используется в контексте запуска Java-приложений и тестов, чтобы установить одно или несколько системных свойств JVM (Java Virtual Machine) перед выполнением приложения или теста. Системные свойства в Java — это ключевые значения, которые можно использовать для конфигурации поведения JVM и приложения. Они могут влиять на работу стандартных классов Java и могут быть использованы для передачи конфигурационной информации в ваше приложение.

Формат опции:
–system-property=PROPERTIES
или
ПРОВЕРИТЬ

\-R=PROPERTIES
где `PROPERTIES` — это пары ключ-значение в формате `name=value`. Если требуется передать несколько системных свойств, опция может быть указана несколько раз с разными парами ключ-значение.

Пример использования:
–system-property=my.prop1=val1 --system-property=my.prop2=val2
или с использованием сокращенной формы:
\-R=my.prop1=val1 -R=my.prop2=val2
В этом примере перед запуском Java-приложения или теста устанавливаются два системных свойства: `my.prop1` со значением `val1` и `my.prop2` со значением `val2`.

Зачем это нужно:
\- **Конфигурация приложения**: Системные свойства могут использоваться для конфигурирования различных аспектов работы приложения, например, для указания путей к файлам конфигурации, настройки логирования и т.д.
\- **Тестирование**: В контексте тестирования, системные свойства могут использоваться для изменения поведения тестов, например, для включения или отключения определенных тестовых случаев на основе конфигурации или для указания различных параметров тестового окружения.
\- **Настройка JVM**: Системные свойства также могут использоваться для настройки работы самой JVM, например, для установки максимального размера кучи или настройки сборщика мусора.

Важно понимать, что системные свойства, установленные таким образом, будут доступны во всем приложении через вызов `System.getProperty("name")`, где `"name"` — это ключ системного свойства. Это делает их удобным средством для передачи конфигурационной информации в приложение в момент его запуска.


Опция `--system-properties-file=PROPERTIES_FILES` представляет собой механизм, используемый при запуске Java-приложений или тестов, для загрузки и установки системных свойств JVM из внешнего файла. Эта возможность особенно полезна, когда необходимо установить большое количество системных свойств или когда значения этих свойств должны быть легко изменяемы без перекомпиляции кода или перезапуска среды разработки.

**Формат опции:**
–system-properties-file=PROPERTIES_FILES
где `PROPERTIES_FILES` указывает на путь к файлу, содержащему системные свойства.

**Формат файла свойств:**
Файл, из которого загружаются системные свойства, обычно имеет простой текстовый формат, где каждая строка содержит одно свойство в формате `ключ=значение`. Комментарии могут быть добавлены, начиная строку с символа `#`. Например:
`# Это комментарий￼property1=value1￼property2=value2`

**Пример использования:**
Предположим, у вас есть файл `app.properties` со следующим содержимым:
app.config.path=/path/to/config
app.logging.level=DEBUG
Чтобы загрузить эти свойства при запуске приложения, используйте опцию:
–system-properties-file=app.properties

**Зачем это нужно:**
\- **Централизованная конфигурация**: Управление системными свойствами через внешний файл позволяет централизованно изменять конфигурацию приложения без необходимости изменения кода или команды запуска.
\- **Упрощение команды запуска**: Вместо того, чтобы указывать множество системных свойств через командную строку с использованием `-Dkey=value`, можно указать один файл, что делает команду запуска более читаемой и удобной для восприятия.
\- **Динамическая конфигурация**: Файл свойств может быть легко изменен администраторами системы или разработчиками для тонкой настройки поведения приложения в зависимости от среды выполнения, не требуя пересборки или перезапуска приложения.

**Важные моменты:**
\- При использовании этой опции важно убедиться, что файл свойств доступен по указанному пути в момент запуска приложения.
\- Системные свойства, загруженные из файла, будут доступны во всем приложении через `System.getProperty("key")`, что делает их удобным способом для передачи конфигурационной информации в приложение.


Опция `--jvm-args=JVM_ARGS` используется в системах сборки и исполнения, связанных с Java-приложениями, для передачи дополнительных аргументов непосредственно виртуальной машине Java (JVM) при её запуске. Эти аргументы позволяют настроить работу JVM, влияя на производительность, поведение сборщика мусора, использование памяти и другие важные аспекты исполнения Java-приложений.

**Формат опции:**
–jvm-args=JVM_ARGS
где `JVM_ARGS` — это строка, содержащая один или несколько аргументов, которые должны быть переданы JVM. Аргументы разделяются пробелами и могут включать в себя как стандартные опции JVM, так и специфичные для конкретной реализации JVM.

**Пример использования:**
–jvm-args=“-Xmx1024m -Xms512m -XX:\+UseG1GC”
В данном примере:
\- `-Xmx1024m` устанавливает максимальный размер кучи (heap) в 1024 мегабайта. Это предел, до которого может вырасти куча в процессе работы приложения.
\- `-Xms512m` задает начальный размер кучи в 512 мегабайт. JVM будет стартовать с кучей данного размера.
\- `-XX:+UseG1GC` включает использование сборщика мусора G1 (Garbage-First), который подходит для приложений с большим объемом памяти и требующих предсказуемого времени паузы на сборку мусора.

**Зачем это нужно:**
\- **Настройка производительности**: Оптимизация использования памяти и выбор подходящего сборщика мусора могут существенно повлиять на производительность Java-приложения.
\- **Отладка и профилирование**: Некоторые аргументы JVM активируют режимы отладки или профилирования, позволяя разработчикам анализировать выполнение приложения.
\- **Настройка безопасности**: Через аргументы JVM можно настроить параметры безопасности, например, ограничить доступ к определенным функциям.
\- **Управление ресурсами**: Указание ограничений на использование памяти предотвращает чрезмерное потребление ресурсов системы.

**Важные моменты:**
\- Необходимо с осторожностью использовать аргументы JVM, так как неправильные настройки могут привести к снижению производительности или даже к ошибкам в работе приложения.
\- Доступные аргументы и их эффекты могут различаться в зависимости от версии и реализации JVM. Следует ознакомиться с документацией конкретной версии JVM, которая используется в вашем проекте.


Опция `--hermione-config=HERMIONE_CONFIG` в системе сборки `ya make` используется для указания пути к файлу конфигурации для запуска тестов, использующих Hermione — инструмент для автоматизированного тестирования веб-приложений с помощью Selenium. Эта опция позволяет тонко настроить процесс тестирования, указав различные параметры исполнения тестов, включая настройки браузеров, таймауты, пути к тестам и многое другое.

**Hermione** — это популярный инструмент для автоматизации тестирования веб-приложений, который позволяет писать тесты на высоком уровне абстракции. Тесты, написанные для Hermione, могут выполняться в различных браузерах, позволяя разработчикам убедиться, что их веб-приложение работает корректно в разных средах.

**Формат опции:**
–hermione-config=путь/к/файлу/конфигурации

**Пример использования:**
ya make --hermione-config=./configs/hermione.conf.js
В этом примере команда `ya make` запустит тесты Hermione, используя конфигурационный файл `hermione.conf.js`, расположенный в директории `configs`.

**Содержание файла конфигурации:**
Файл конфигурации Hermione обычно представляет собой JavaScript файл, который экспортирует объект с настройками. В нем можно указать:

\- **browsers**: конфигурации для браузеров, в которых будут запускаться тесты;
\- **baseUrl**: базовый URL тестируемого веб-приложения;
\- **gridUrl**: URL Selenium Grid, через который будут запускаться браузеры;
\- **timeout**: таймауты для тестов;
\- **retry**: количество попыток перезапуска тестов в случае их неудачного выполнения;
\- **plugins**: настройки плагинов, расширяющих функциональность Hermione.

**Зачем это нужно:**
\- **Гибкость настроек**: Опция позволяет указать конкретный файл конфигурации для запуска тестов, что дает возможность иметь несколько разных конфигураций для разных сред или целей тестирования.
\- **Удобство управления**: Централизованное управление настройками тестирования через один файл конфигурации упрощает поддержку и обновление параметров тестирования.
\- **Множественные среды тестирования**: Можно легко переключаться между различными конфигурациями для запуска тестов в разных средах (разработка, тестирование, продакшн) без изменения кода тестов.

**Важные моменты:**
\- При использовании этой опции убедитесь, что указанный путь к файлу конфигурации корректен и файл доступен в момент запуска `ya make`.
\- Возможности и параметры конфигурации могут изменяться в зависимости от версии Hermione и подключенных плагинов, поэтому рекомендуется ознакомиться с документацией Hermione для понимания всех доступных настроек.

Опция `--hermione-browser=HERMIONE_BROWSERS` предназначена для использования в контексте запуска автоматизированных тестов веб-приложений с помощью инструмента Hermione. Эта опция позволяет ограничить выполнение тестов только выбранными браузерами, что полезно при необходимости запустить тесты в конкретной среде или при отладке проблем, связанных с определенным браузером.

**Hermione** — это инструмент для автоматизации тестирования веб-приложений, работающий поверх WebDriver и Selenium. Он позволяет писать тесты на JavaScript, которые могут выполняться в различных браузерах, имитируя действия пользователя.

 Формат опции:
–hermione-browser=HERMIONE_BROWSERS
где `HERMIONE_BROWSERS` — это строка, содержащая имя браузера или список имен браузеров, разделенных запятыми, в которых должны выполняться тесты.

 Пример использования:
ya make --hermione-browser=chrome
Эта команда запустит Hermione тесты только в браузере Chrome.

Если требуется запустить тесты в нескольких браузерах, можно указать их через запятую:
ya make --hermione-browser=chrome,firefox
Эта команда запустит тесты в браузерах Chrome и Firefox.

 Зачем это нужно:
1\. **Фокусировка на конкретном браузере**: При разработке веб-приложений часто возникают ситуации, когда функционал нужно протестировать в конкретном браузере из-за его специфики или известных проблем совместимости.
2\. **Экономия времени**: Запуск тестов только в одном или нескольких целевых браузерах может существенно сократить время, необходимое для прохождения тестового набора, особенно когда полный прогон всех тестов во всех поддерживаемых браузерах занимает много времени.
3\. **Отладка**: При поиске и исправлении ошибок, специфичных для определенного браузера, возможность запустить тесты только в этом браузере упрощает и ускоряет процесс отладки.

Важные моменты:
\- Убедитесь, что указанные браузеры настроены в конфигурационном файле Hermione и доступны для запуска тестов. Конфигурация браузеров включает в себя не только их названия, но и параметры запуска, версии и пути к драйверам.
\- Для эффективного использования этой опции важно иметь хорошо структурированные тесты, способные корректно выполняться в различных браузерах с учетом их особенностей.


Опция `--hermione-grep=HERMIONE_GREP` используется в контексте запуска автоматизированных тестов с помощью инструмента Hermione, который предназначен для тестирования веб-приложений. Эта опция позволяет запускать только те тесты, названия которых соответствуют указанному шаблону, используя механизм фильтрации посредством регулярных выражений или подстрок.

**Hermione** — это инструмент для автоматизации тестирования веб-приложений на основе Selenium WebDriver. Он позволяет писать тесты на JavaScript, которые могут взаимодействовать с веб-страницами так же, как это делает пользователь, обеспечивая тем самым высокую точность тестирования пользовательского интерфейса.

 Формат опции:
–hermione-grep=HERMIONE_GREP
где `HERMIONE_GREP` — это шаблон (регулярное выражение или просто подстрока), по которому будет производиться поиск среди названий тестов или групп тестов (тестовых сценариев).

Пример использования:
ya make --hermione-grep=“Логин”
Эта команда запустит все тесты Hermione, в названиях которых содержится слово “Логин”.

Если требуется более специфичный отбор тестов, можно использовать регулярные выражения:
ya make --hermione-grep=“\^Логин.\*успех\$”
Эта команда запустит тесты, названия которых начинаются со слова “Логин” и заканчиваются словом “успех”.

 Зачем это нужно:
\- **Фокусировка на конкретных тестах**: Позволяет запускать только те тесты, которые соответствуют определенному критерию, что особенно полезно при разработке или отладке тестов.
\- **Экономия времени**: Запуск только релевантных тестов экономит время, особенно когда общее количество тестов велико, а необходимо проверить только определенную функциональность.
\- **Упрощение интеграции с CI/CD**: Можно настроить разные пайплайны для запуска разных групп тестов в зависимости от контекста изменений в коде.


Опция `--hermione-test-path=HERMIONE_TEST_PATHS` предназначена для запуска автоматизированных тестов веб-приложений с использованием инструмента Hermione, ограничивая выполнение тестов только теми, что расположены в указанных файлах. Это позволяет более гибко управлять процессом тестирования, запуская тесты из конкретных файлов, что особенно удобно при разработке новых тестов или при необходимости провести тестирование только определенной части приложения.

Формат опции:
–hermione-test-path=HERMIONE_TEST_PATHS
где `HERMIONE_TEST_PATHS` — это один путь или список путей к файлам с тестами, разделенных запятыми. Пути должны быть указаны относительно текущей рабочей директории (cwd - current working directory).

Пример использования:
ya make -t --hermione-test-path=./tests/loginTest.js
Эта команда запустит выполнение тестов, расположенных в файле `loginTest.js`, который находится в директории `tests` относительно текущей рабочей директории.

Если необходимо запустить тесты из нескольких файлов, пути к этим файлам перечисляются через запятую:
ya make -t --hermione-test-path=./tests/loginTest.js,./tests/registrationTest.js
В этом случае будут выполнены тесты из двух файлов: `loginTest.js` и `registrationTest.js`.

\- **Точечное тестирование**: Позволяет запускать тесты из конкретных файлов, что удобно при разработке новых тестов или при отладке существующих.
\- **Экономия времени**: Запуск только определенных тестов экономит время, особенно когда полный прогон всех тестов занимает значительное количество времени.
\- **Гибкость**: Дает возможность гибко настраивать запуск тестов в зависимости от потребностей разработки или тестирования.


Опция `--hermione-set=HERMIONE_SETS` используется в контексте запуска тестов с помощью инструмента Hermione, который предназначен для автоматизированного тестирования веб-приложений. Эта опция позволяет ограничить выполнение тестов только теми, которые включены в определенный набор (или наборы), предварительно сконфигурированный в файле конфигурации Hermione.

**Hermione** позволяет группировать тесты в наборы (sets), чтобы можно было легко запускать различные подгруппы тестов в зависимости от текущих требований. Например, можно создать отдельные наборы для smoke-тестов, тестов регрессии, тестов определенной функциональности и т.д. Это особенно полезно в больших проектах с обширным набором тестов, где запуск всех тестов за один раз может быть нецелесообразным.

Формат опции:
–hermione-set=HERMIONE_SETS
где `HERMIONE_SETS` — это имя одного набора или список имен наборов, разделенных запятыми, которые должны быть выполнены.

 Пример использования:
ya make -t --hermione-set=smoke
Эта команда запустит выполнение только тех тестов Hermione, которые включены в набор `smoke`.

Если требуется запустить тесты из нескольких наборов, имена наборов перечисляются через запятую:
ya make --hermione-set=smoke,regression
В этом случае будут выполнены тесты, включенные в наборы `smoke` и `regression`.

 Как настроить наборы в Hermione:
Конфигурация наборов производится в файле конфигурации Hermione (обычно `hermione.conf.js` или аналогичном). Для определения наборов используется секция `sets` в конфигурационном объекте. Пример:

```
module.exports = {
    sets: {
        smoke: {
            files: [‘tests/smoke/.js’]
        },
        regression: {
            files: ['tests/regression/**/.js’]
        }
    },
    // Другие настройки конфигурации…
};
```


В этом примере определены два набора тестов: `smoke` и `regression`, каждый из которых содержит пути к тестовым файлам, входящим в соответствующий набор.

Зачем это нужно:
\- **Гибкость запуска тестов**: Позволяет запускать только те тесты, которые актуальны в данном контексте разработки или деплоя.
\- **Оптимизация времени тестирования**: Сокращает время, необходимое на прогон тестов, позволяя фокусироваться на конкретных аспектах приложения.
\- **Удобство управления**: Упрощает управление тестами, разделяя их на логические группы.

 Важные моменты:
\- Важно корректно настроить наборы в файле конфигурации Hermione, чтобы использование опции `--hermione-set` было эффективным.
\- При использовании этой опции следует учитывать, что тесты, не входящие в указанные наборы, не будут выполнены. Это необходимо учитывать, чтобы избежать пропуска важных проверок.


Опция `--hermione-gui` предназначена для запуска тестов, использующих инструмент Hermione, в графическом интерфейсе пользователя (GUI).

 Формат опции:
\--hermione-gui

Как это работает:
При запуске с опцией `--hermione-gui`, Hermione инициирует веб-сервер, который предоставляет графический интерфейс для управления процессом тестирования. Этот интерфейс позволяет выбирать конкретные тесты для запуска, просматривать результаты их выполнения и взаимодействовать с тестовым окружением в более удобной и наглядной форме, чем при работе через командную строку.

Пример использования:
ya make -t  --hermione-gui
После запуска команды в консоли появится URL, по которому доступен графический интерфейс Hermione. Открыв этот URL в браузере, вы увидите список доступных для запуска тестов и сможете управлять процессом тестирования непосредственно из браузера.

\- **Удобство и наглядность**: Графический интерфейс делает процесс настройки и запуска тестов более интуитивно понятным и удобным, особенно для новых пользователей или в ситуациях, когда необходимо быстро настроить выполнение определенных тестов.


Опция `--hermione-gui-auto-run` предназначена для использования в контексте запуска тестов с помощью инструмента Hermione в графическом интерфейсе пользователя (GUI). Эта опция автоматизирует процесс тестирования, позволяя автоматически запустить выбранные тесты сразу после того, как пользователь открывает веб-интерфейс Hermione в браузере.

Как это работает:
При запуске Hermione с опцией `--hermione-gui`, инструмент инициирует веб-сервер, который предоставляет доступ к графическому интерфейсу для управления тестами. Обычно, после открытия интерфейса в браузере, пользователю необходимо вручную выбрать и запустить тесты. Однако, если при запуске использовать дополнительно опцию `--hermione-gui-auto-run`, тесты будут запущены автоматически, минуя необходимость ручного взаимодействия для их старта.

 Пример использования:
ya make  -t --hermione-gui --hermione-gui-auto-run
После выполнения этой команды и открытия GUI Hermione в браузере, тесты начнут выполняться автоматически, без дополнительных действий со стороны пользователя.

Зачем это нужно:
\- **Ускорение процесса тестирования**: Эта опция позволяет сэкономить время, автоматически запуская тесты сразу после загрузки GUI, что особенно удобно при частом перезапуске тестов в процессе разработки или отладки.
\- **Упрощение демонстраций**: При демонстрации работы тестов или тестового окружения перед коллегами или клиентами, автоматический запуск тестов может сделать демонстрацию более плавной и впечатляющей.


\- Опция `--hermione-gui-auto-run` может быть не подходящей для сценариев, в которых требуется тщательный отбор или настройка тестов перед их выполнением.
\- Необходимо учитывать, что автоматический запуск большого количества тестов может привести к высокой нагрузке на тестируемую систему или тестовое окружение сразу после запуска GUI.


Опция `--hermione-gui-no-open` используется в контексте запуска автоматизированных тестов с помощью инструмента Hermione в графическом интерфейсе пользователя (GUI). Эта опция предназначена для сценариев, когда необходимо запустить веб-сервер для работы с GUI Hermione, но при этом избежать автоматического открытия окна браузера с интерфейсом Hermione сразу после запуска сервера.

 Как это работает:
По умолчанию, при запуске Hermione с опцией `--hermione-gui`, инструмент инициирует веб-сервер и автоматически открывает веб-страницу с GUI Hermione в браузере по умолчанию. Это удобно для непосредственной работы с тестами через графический интерфейс. Однако, в некоторых случаях может потребоваться только запуск сервера без автоматического открытия браузера — например, при запуске в средах, где нет графического интерфейса, или когда разработчик предпочитает самостоятельно управлять моментом открытия GUI в браузере. В таких ситуациях и используется опция `--hermione-gui-no-open`.

Пример использования:
ya make -t --hermione-gui --hermione-gui-no-open
После выполнения этой команды сервер для работы с GUI Hermione будет запущен, но окно браузера открываться не будет. Адрес веб-страницы для доступа к GUI, как правило, будет выведен в консоль, и разработчик сможет перейти по нему самостоятельно, когда посчитает нужным.

 Зачем это нужно:
\- **Запуск в средах без графического интерфейса**: Позволяет использовать Hermione GUI в средах без графической оболочки или в автоматизированных скриптах.
\- **Контроль за открытием GUI**: Дает разработчикам гибкость в управлении процессом тестирования, позволяя самостоятельно решать, когда именно открыть GUI в браузере.

После запуска сервера с опцией `--hermione-gui-no-open` важно обратить внимание на консольный вывод, чтобы получить URL для доступа к GUI, так как браузер не откроется автоматически.
Эта опция особенно полезна для сценариев автоматизации и тестирования в удаленных средах или в средах непрерывной интеграции, где пользовательский интерфейс может быть недоступен.


Опция `--hermione-gui-hostname=HERMIONE_GUI_HOSTNAME` используется при запуске автоматизированных тестов веб-приложений с помощью инструмента Hermione в графическом интерфейсе пользователя (GUI). Эта опция позволяет указать конкретный хост (hostname), на котором будет запущен веб-сервер для работы с GUI Hermione. Это может быть полезно в различных сценариях, например, когда требуется запустить GUI на определенном интерфейсе или адресе, доступном в сети.

 Как это работает:
По умолчанию, при запуске Hermione с опцией `--hermione-gui`, веб-сервер для GUI запускается на локальном хосте (`localhost`). Это означает, что доступ к GUI возможен только с той же машины, на которой запущен сервер. Опция `--hermione-gui-hostname` позволяет изменить это поведение, указав другой хост, на котором должен быть запущен сервер, делая GUI доступным по сети.

Пример использования:
ya make  -t --hermione-gui --hermione-gui-hostname=192.168.1.5
В этом примере сервер для работы с GUI Hermione будет запущен на хосте с IP-адресом `192.168.1.5`. Это означает, что к GUI можно будет получить доступ не только с локальной машины, но и с любого устройства в сети, которое может подключиться к этому IP-адресу.

 Зачем это нужно:
\- **Доступность в сети**: Позволяет сделать GUI Hermione доступным для других устройств в сети, что удобно для совместной работы над тестами или демонстрации результатов тестирования.
\- **Гибкость настройки**: Указание хоста для запуска сервера дает возможность запускать GUI на определенных сетевых интерфейсах или адресах, что может быть требованием безопасности или инфраструктуры.
\- **Удаленный доступ**: При запуске сервера GUI на публичном IP-адресе или виртуальной машине, к Hermione GUI можно получить доступ из любой точки мира, что упрощает удаленную работу и тестирование.


Опция `--hermione-gui-port=HERMIONE_GUI_PORT` используется в контексте запуска автоматизированных тестов с помощью инструмента Hermione в графическом интерфейсе пользователя (GUI). Эта опция позволяет указать конкретный сетевой порт, на котором будет запущен веб-сервер для доступа к GUI Hermione. Это дает возможность контролировать, через какой порт будет осуществляться взаимодействие с интерфейсом управления тестами.

Как это работает:
При запуске Hermione с опцией `--hermione-gui`, инструмент инициирует веб-сервер, который предоставляет доступ к графическому интерфейсу для управления тестами. Если порт не указан явно, используется порт по умолчанию (обычно это `8000` или первый доступный порт после него). Опция `--hermione-gui-port` позволяет явно задать порт, на котором будет запущен веб-сервер, обеспечивая таким образом гибкость настройки среды тестирования.

Пример использования:
ya make -t --hermione-gui --hermione-gui-port=8080
В этом примере веб-сервер для GUI Hermione будет запущен на порту `8080`. Это означает, что для доступа к графическому интерфейсу Hermione необходимо будет открыть в браузере URL `http://localhost:8080`.

Зачем это нужно:
\- **Избегание конфликтов портов**: Если порт по умолчанию уже используется другим приложением или сервисом, указание другого порта позволяет избежать конфликта.
\- **Настройка сетевой конфигурации**: В некоторых сетевых окружениях или при использовании контейнеризации (например, Docker) может потребоваться запускать веб-сервер на определенном порту, который разрешен фаерволом или настроен в правилах проброса портов.
\- **Удобство доступа**: Указание заранее известного порта упрощает доступ к GUI, особенно если Hermione используется разными членами команды или интегрировано в более крупную систему автоматизации тестирования.

 Важные моменты:
\- Перед указанием порта стоит убедиться, что он не занят другими приложениями и доступен для использования.
\- В некоторых операционных системах для использования портов с номером ниже `1024` может потребоваться повышение привилегий.
\- Если тесты запускаются в изолированной среде (например, в CI/CD пайплайне или на удаленном сервере), необходимо учитывать настройки сети и доступности порта извне этой среды.


Опция `--junit-args=JUNIT_ARGS` предназначена для использования в контексте запуска Java-тестов, основанных на фреймворке JUnit. Эта опция позволяет передать дополнительные аргументы непосредственно в JUnit-раннер, что дает возможность настроить процесс выполнения тестов более гибко.

 Как это работает:
JUnit поддерживает различные аргументы командной строки, которые могут влиять на выбор и поведение тестов, например, фильтрацию тестов по имени, ограничение времени выполнения и другие настройки. Опция `--junit-args` позволяет указать эти параметры при запуске тестов через систему сборки.

Формат опции:
\--junit-args=“аргумент1 аргумент2 … аргументN”
где каждый `аргумент` соответствует поддерживаемым JUnit аргументам командной строки.

 Пример использования:
Предположим, вы хотите запустить только те тесты, имена которых соответствуют определенному шаблону, и установить таймаут для каждого теста. В таком случае можно использовать следующую команду:
ya make -t --junit-args=“-Dtest=MyTest\* -Dtimeout=100”
В этом примере:
\- `-Dtest=MyTest*` указывает JUnit запускать только те тесты, имена которых начинаются на `MyTest`.
\- `-Dtimeout=100` устанавливает максимальное время выполнения каждого теста в 100 миллисекунд.

Зачем это нужно:
\- **Фильтрация тестов**: Вы можете запускать только определенную подгруппу тестов, что особенно полезно при большом наборе тестов или когда нужно сфокусироваться на конкретной проблеме.
\- **Настройка выполнения**: Настройте поведение JUnit, например, установив таймауты для тестов, что помогает избежать зависания тестов и ускоряет процесс разработки.


НЕ ОПИСЫВАЕМ

\--strict-inputs (устаревшее)
Включить строгий режим


ОБЩЕЕ не опция

Для импорта библиотек из maven репозиториев в аркадию используется команда `ya maven-import groupId:artifactId:version` (которая взаимодействует с maven). В результате выполнения команды нужная библиотека со всеми зависимостями появится в [contrib/java](https://a.yandex-team.ru/arc/trunk/arcadia/contrib/java) в виде модуля `JAVA_LIBRARY`, описанного в `groupId/artifactId/version/ya.make`(закоммитить нужно самостоятельно). После этого можно зависеть от этого модуля, используя `PEERDIR`.



Опция `--sonar` в системе сборки `ya make` предназначена для запуска анализа качества кода с помощью инструмента SonarQube. 

SonarQube — это платформа для непрерывного анализа и измерения качества кода, которая позволяет обнаруживать различные типы проблем в коде, такие как ошибки, уязвимости, “запахи кода” (code smells), и другие потенциальные проблемы, которые могут негативно сказаться на качестве, безопасности или производительности программного обеспечения.

 Как это работает:
При использовании опции `--sonar`, `ya make` инициирует процесс анализа кода, в ходе которого код проекта сканируется, и результаты сканирования отправляются в SonarQube сервер для дальнейшего анализа и отображения в его веб-интерфейсе. Это позволяет разработчикам и командам получить детальный отчет о качестве кода, включая выявленные проблемы и рекомендации по их устранению.

Пример использования:
Для использования этой опции необходимо иметь установленный и настроенный SonarQube сервер, а также сконфигурированный проект в SonarQube, к которому будет отправлен результат анализа. Пример команды для запуска анализа:
ya make -t --sonar
Эта команда запустит процесс анализа кода проекта и отправит результаты на SonarQube сервер.

 Зачем это нужно:
\- **Повышение качества кода**: Анализ с помощью SonarQube помогает выявлять и устранять проблемы в коде на ранних этапах разработки, что способствует повышению его качества и надежности.
\- **Обеспечение безопасности**: SonarQube способен обнаруживать потенциальные уязвимости и проблемы безопасности, что критически важно для создания безопасных приложений.
\- **Контроль технического долга**: Платформа позволяет оценивать и контролировать технический долг, предоставляя инструменты для его управления и планирования работ по его уменьшению.
\- **Улучшение процесса код-ревью**: Информация о проблемах кода, предоставляемая SonarQube, может быть использована при проведении код-ревью для более детальной оценки изменений.

 Важные моменты:
\- Для работы с опцией `--sonar` необходимо наличие доступа к SonarQube серверу и настроенного проекта в нем.
\- В зависимости от размера проекта и сложности кода, анализ может занимать значительное время.
\- Важно регулярно проводить анализ и работать над устранением выявленных проблем для поддержания высокого уровня качества кода.
\- Настройка SonarQube сервера и интеграция с проектом может потребовать дополнительных шагов конфигурации и подготовки, включая настройку ключа проекта, токенов доступа и других параметров.


Опция `--maven-export` в системе сборки `ya make` предназначена для экспорта артефактов Java проекта в репозиторий Maven.

Maven — это инструмент для автоматизации сборки проектов на Java, который широко используется в разработке для управления зависимостями, сборкой проекта и его документацией. Репозитории Maven используются для хранения и распространения библиотек и других артефактов, необходимых для сборки Java проектов.

Как это работает:
При использовании опции `--maven-export`, `ya make` выполняет сборку проекта и генерирует артефакты (например, .jar файлы), соответствующие стандартам Maven. Затем эти артефакты загружаются в указанный Maven репозиторий, делая их доступными для использования в других проектах как зависимости.

Как это работает:
Использование опции `--maven-export` инициирует процесс, в ходе которого артефакты проекта (например, скомпилированные JAR-файлы) подготавливаются и отправляются в указанный Maven репозиторий. Этот процесс включает в себя генерацию POM-файлов (Project Object Model), которые описывают проект и его зависимости, и самих артефактов в соответствии с требованиями Maven.

Пример использования:
Команда для сборки и экспорта артефактов в Maven репозиторий может выглядеть следующим образом:
ya make -t  --maven-export
Для успешного экспорта в Maven репозиторий необходимо также указать дополнительные параметры, такие как URL репозитория, идентификаторы группы и артефакта, версию и, при необходимости, учетные данные для аутентификации в репозитории. Эти параметры обычно настраиваются в конфигурационных файлах проекта или передаются через дополнительные опции командной строки.

Зачем это нужно:
\- **Управление зависимостями**: Экспорт артефактов проекта в Maven репозиторий позволяет другим проектам легко подключать и использовать эти артефакты как зависимости.
\- **Версионирование и распространение**: Maven репозитории поддерживают версионирование артефактов, что облегчает управление разными версиями библиотек и их распространение среди разработчиков и проектов.
\- **Автоматизация сборки**: Интеграция с Maven позволяет автоматизировать процесс сборки проектов, использующих экспортированные артефакты, и обеспечивает совместимость с широко распространенными инструментами и практиками разработки на Java.

Важные моменты:
\- Необходимо иметь доступ к Maven репозиторию, куда будут экспортироваться артефакты, и правильно настроить параметры для подключения к этому репозиторию.
\- Важно соблюдать правила именования и версионирования артефактов в соответствии со стандартами Maven, чтобы обеспечить их корректное использование в качестве зависимостей.
\- Экспорт в Maven репозиторий может потребовать дополнительных шагов для подготовки артефактов, таких как генерация POM-файлов и их настройка.

Использование опции `--maven-export` в `ya make` обеспечивает тесную интеграцию процессов сборки с экосистемой Maven, упрощая управление зависимостями и сборкой проектов на Java.

Наверное не надо было описывать, интеграция Аркадии с Мавен, уточнить


Скорее всего не описываем

Опция `--version=VERSION` в системе сборки `ya make` используется в контексте экспорта артефактов Java проекта в репозиторий Maven. Эта опция позволяет указать версию экспортируемых артефактов, что является ключевым аспектом управления зависимостями в Maven и обеспечивает корректное версионирование библиотек или приложений в процессе их разработки и деплоя.

Как это работает:
В Maven каждый артефакт (обычно это JAR-файл) идентифицируется уникальным сочетанием groupId, artifactId и версии. Версия артефакта позволяет отслеживать его изменения во времени, управлять совместимостью и обеспечивать стабильность сборки проектов, использующих эти артефакты как зависимости.

При использовании опции `--version=VERSION` с `ya make --maven-export`, вы явно указываете версию артефакта, которая будет использоваться при его экспорте в Maven репозиторий. Это позволяет контролировать, какая версия артефакта будет доступна для других проектов.

Пример использования:
ya make -t --maven-export --version=1.0.0
Эта команда экспортирует артефакты текущего проекта в Maven репозиторий, присваивая им версию `1.0.0`.

Зачем это нужно:
\- **Управление версиями**: Четкое указание версии артефакта важно для управления зависимостями в проектах, использующих Maven. Это позволяет разработчикам точно указывать, какие версии библиотек они хотят использовать, и избегать проблем с несовместимостью.
\- **Разработка и деплой**: Версионирование артефактов позволяет отличать стабильные релизы от версий в разработке (SNAPSHOT-версии) и управлять процессом разработки, тестирования и деплоя.
\- **История изменений**: Версии артефактов фиксируют историю изменений в коде, позволяя отслеживать, какие изменения были внесены между различными релизами.

Важные моменты:
\- **Семантическое версионирование**: Рекомендуется следовать принципам семантического версионирования (SemVer), где номер версии состоит из трех частей: MAJOR.MINOR.PATCH, что помогает другим разработчикам понимать, какие изменения были внесены в артефакт.
\- **SNAPSHOT-версии**: В Maven принято использовать суффикс `-SNAPSHOT` для версий артефактов, находящихся в активной разработке. Это сигнализирует о том, что версия может изменяться и не является стабильной.
\- **Консистентность версий**: Важно поддерживать консистентность версий артефактов внутри проекта и при их экспорте в Maven репозиторий, чтобы обеспечить корректную сборку и управление зависимостями.


Опция тестирования `-J=JAVAC_FLAGS` или в альтернативном формате `--javac-opts=JAVAC_FLAGS` для `ya make` предназначена для передачи дополнительных флагов и параметров непосредственно компилятору Java (`javac`) в процессе сборки Java-проектов. Это предоставляет разработчикам дополнительную гибкость при настройке процесса компиляции их Java кода, позволяя влиять на различные аспекты компиляции, такие как уровень предупреждений, оптимизации, обработка аннотаций и другие.

Формат опции:
\- В форме `-J=JAVAC_FLAGS` каждый из флагов `JAVAC_FLAGS` передается компилятору `javac` как есть.
\- В форме `--javac-opts=JAVAC_FLAGS` то же самое, но используется полная форма опции.

Пример использования:
Предположим, вы хотите включить в процессе компиляции проверку всех предупреждений компилятора, а также задать путь к аннотациям для JSR305. Вы можете указать это следующим образом:
ya make -t -J=“-Xlint:all -Xlint:-serial -encoding UTF-8”
или
ya make -t --javac-opts=“-Xlint:all -Xlint:-serial -encoding UTF-8”
В этом примере:
\- `-Xlint:all` включает все предупреждения компилятора.
\- `-Xlint:-serial` отключает предупреждения компилятора о `serialVersionUID` для сериализуемых классов (если, например, `-Xlint:all` был слишком “шумным”).
\- `-encoding UTF-8` указывает компилятору использовать UTF-8 как кодировку исходных файлов.

Зачем это нужно:
\- **Настройка компиляции**: Позволяет тонко настраивать процесс компиляции, что может быть необходимо для удовлетворения специфических требований проекта или для управления компромиссами между производительностью и безопасностью.

\- **Поддержка новых функций Java**: Когда вы хотите использовать новые функции языка Java или экспериментальные возможности, которые требуют добавления специфических флагов компилятора.

\- **Управление предупреждениями**: Позволяет включать или исключать определенные предупреждения, что упрощает нахождение потенциальных проблем в коде на ранних этапах разработки.

 Важные моменты:
\- Убедитесь, что флаги, которые вы передаете, совместимы с вашей версией компилятора `javac`. Некоторые флаги могут отсутствовать или работать по-разному в разных версиях.

\- Будьте внимательны при использовании флагов, которые могут значительно изменить поведение компилятора, так как это может привести к неожиданным результатам.

\- Эта опция предназначена для опытных разработчиков, которые хорошо знакомы со средствами и настройками компилятора Java.


Опция `--error-prone-flags=ERROR_PRONE_FLAGS` в контексте системы сборки `ya make` предназначена для настройки поведения Error Prone во время компиляции Java-кода. Error Prone — это плагин для компилятора Java (javac), который анализирует код на предмет распространенных ошибок программирования, которые традиционный компилятор Java не способен обнаружить. Этот инструмент помогает разработчикам находить и исправлять ошибки на ранних этапах процесса разработки, повышая тем самым качество кода и сокращая время, требуемое на отладку.

 Как это работает:
При включении Error Prone в процессе компиляции, он анализирует исходный код на предмет различных “шаблонов ошибок” — проблем в коде, которые часто приводят к ошибкам или нежелательному поведению программы. Error Prone может выдать предупреждения или ошибки для найденных проблематичных участков кода. С помощью опции `--error-prone-flags` разработчики могут настраивать, какие правила анализа будут применяться, отключать определенные правила, изменять уровень серьезности выдаваемых предупреждений и т.д.

Формат опции:
–error-prone-flags=“флаг1 флаг2 … флагN”
где каждый `флаг` задает конкретную настройку или параметр анализа Error Prone.

Пример использования:
ya make -t  --error-prone-flags=“-Xep:DeadException:WARN -XepDisableWarningsInGeneratedCode”
В этом примере:
\- `-Xep:DeadException:WARN` меняет уровень серьезности правила анализа `DeadException` на предупреждение (`WARN`). Это правило, например, может обнаруживать исключения, которые создаются, но не используются.
\- `-XepDisableWarningsInGeneratedCode` отключает вывод предупреждений Error Prone для сгенерированного кода. Это может быть полезно для сокращения “шума” в отчетах о компиляции, когда разработчик сосредоточен на анализе кода, написанного вручную.

Зачем это нужно:
\- **Повышение качества кода**: Использование Error Prone помогает обнаружить сложные для обнаружения ошибки на этапе компиляции, еще до выполнения тестов или запуска программы.
\- **Настройка анализа под специфику проекта**: Не все правила Error Prone могут быть актуальны или приемлемы для конкретного проекта. С помощью `--error-prone-flags` можно тонко настроить анализ, выбрав наиболее релевантные проверки.
\- **Управление “шумом”**: В некоторых случаях количество предупреждений от Error Prone может быть избыточным, особенно для больших проектов или при использовании генераторов кода. Эта опция позволяет уменьшить количество “ложных находок”.

Важные моменты:
\- Необходимо ознакомиться с документацией Error Prone, чтобы понять доступные флаги и правила, и корректно использовать их в контексте своего проекта.
\- Изменение уровня серьезности правил или отключение некоторых из них должно быть обосновано требованиями проекта или кодовой базой, чтобы не пропустить важные исправления в коде.
\- Включение Error Prone в сборку может незначительно увеличить время компиляции из-за дополнительного анализа кода.


Опция `--disable-run-script-generation` в системе сборки `ya make` используется специфически для проектов, написанных на Java, и предназначена для отключения автоматической генерации скриптов запуска, обычно именуемых `run.sh` для Unix-подобных систем или `run.bat` для Windows. Эти скрипты создаются в процессе сборки для упрощения процесса запуска Java приложений (`JAVA_PROGRAM`), обеспечивая быстрый и удобный способ запустить собранное приложение без необходимости вручную формировать команду `java -jar ...` с указанием всех необходимых аргументов и путей к зависимостям.

Как это работает:
В процессе сборки, когда собирается Java-проект типа `JAVA_PROGRAM`, система сборки `ya make` обычно генерирует скрипт запуска (`run.sh` или `run.bat`), который включает в себя всю необходимую информацию для запуска собранного JAR файла, включая пути к зависимостям и необходимые параметры JVM. Если же разработчик хочет отказаться от автоматического создания таких скриптов, он может использовать опцию `--disable-run-script-generation`.

 Пример использования:
ya make -t  --disable-run-script-generation
Использование этой команды приведет к тому, что в процессе сборки скрипты `run.sh` или `run.bat` не будут сгенерированы, даже если сборка завершится успешно.

Зачем это нужно:
\- **Кастомизация запуска**: В некоторых случаях разработчикам может потребоваться более глубокая кастомизация процесса запуска приложения, несовместимая с стандартным скриптом запуска.
\- **Сложные сценарии запуска**: Для приложений, требующих специальной предварительной настройки окружения, аргументов JVM, которые сложно представить стандартным скриптом.
\- **Интеграция и деплой**: В случаях, когда проект интегрируется в сложную систему деплоя или CI/CD, автоматические скрипты запуска могут быть не нужны или даже мешать.

\- При отключении генерации скриптов запуска ответственность за корректный запуск приложения полностью ложится на разработчика. Ему необходимо самостоятельно подготовить все необходимые скрипты или команды запуска.
\- Необходимо тщательно продумать и протестировать альтернативные способы запуска вашего приложения, чтобы убедиться в их корректности и отсутствии проблем при запуске в различных окружениях.
\- Эта опция может быть особенно полезна при разработке библиотек или компонент, которые встраиваются в другие приложения или сервисы и не предназначены для независимого запуска.


Опция `--sonar-project-filter=SONAR_PROJECT_FILTERS` в контексте использования системы сборки `ya make` ориентирована на работу с инструментом анализа качества кода SonarQube во время выполнения тестирования или анализа кода. 

Эта опция позволяет уточнить и ограничить анализ SonarQube только определенными проектами или подпроектами, которые соответствуют заданным критериям или фильтрам. Это особенно полезно в больших или многоуровневых проектах, где не требуется анализировать всю кодовую базу целиком, а лишь ее часть.

Как это работает:
При работе с SonarQube, весь кодовый проект или множество проектов могут быть проанализированы на наличие различных типов ошибок, проблем безопасности, “запахов” кода (code smells) и других потенциальных улучшений. Однако, если вам нужен анализ только специфической части кодовой базы, использование фильтра `--sonar-project-filter` дает возможность сузить область анализа до проектов или путей, соответствующих заданным шаблонам или критериям фильтрации.

Формат опции:
\--sonar-project-filter=“фильтр1 фильтр2 … фильтрN”
где каждый `фильтр` определяет паттерн или критерий, который будет использоваться для отбора проектов для анализа. Фильтры могут быть оформлены в виде простых строк, регулярных выражений или иных форматах, приемлемых системой сборки и инструментом SonarQube.

 Пример использования:
Предположим, вам нужно проанализировать только те проекты, путь которых содержит `frontend`, а также специфический модуль `authentication` в другом месте кодовой базы. В таком случае, ваша команда могла бы выглядеть следующим образом:
ya make -t --sonar --sonar-project-filter=“*frontend* *authentication*”
Здесь анализ SonarQube будет применен только к проектам, в путях которых встречается `frontend` или `authentication`.


Опция `--sonar-default-project-filter` предназначена для использования в системе сборки `ya make` в контексте подготовки проекта к анализу качества кода инструментом SonarQube.

 Эта опция позволяет установить значение по умолчанию для фильтра, который применяется к проектам или модулям в рамках анализа SonarQube, определяя таким образом, какие конкретные цели сборки (проекты или модули) будут анализироваться SonarQube. 

SonarQube — это автоматизированная система для контроля качества кода, которая помогает обнаруживать различные проблемы в исходном коде, такие как ошибки, уязвимости, “запахи кода” и другие потенциальные проблемы.

Пример использования:
Допустим, вы хотите, чтобы анализ SonarQube касался только определенных частей вашего проекта, например, модулей, имена которых содержат “auth” или “util”. В таком случае, команда может выглядеть следующим образом:
ya make --sonar --sonar-default-project-filter=“*auth*,*util*”
Эта команда подготовит проект к анализу в SonarQube, но фактический анализ будет проводиться только по тем частям кода, которые соответствуют установленным фильтрам.

 Как это работает:
\- При запуске анализа SonarQube с помощью `ya make --sonar`, инструмент анализирует код на предмет различных проблем и выдает соответствующие отчеты и метрики качества кода.
\- Опция `--sonar-default-project-filter` позволяет ограничить область анализа, указав фильтры (паттерны), которым должны соответствовать анализируемые проекты или модули. 

 Зачем это нужно:
\- **Фокусировка анализа**: Направление ресурсов SonarQube на анализ наиболее важных или измененных частей кода для ускорения процесса анализа и получения наиболее релевантных результатов.
\- **Управление ресурсами**: Эффективное использование вычислительных мощностей за счет исключения из анализа несущественных частей проекта или временно не актуальных модулей.
\- **Гибкость конфигурации**: Возможность задать разные конфигурации анализа для разных сценариев сборки, например, различая полный анализ и анализ только изменений.

 Важные моменты:
\- Необходимо тщательно выбирать фильтры, чтобы не пропустить важные для анализа части кода.
\- Следует учитывать, как изменения в кодовой базе могут влиять на соответствие целей сборки заданным фильтрам.
\- Для эффективного использования этой опции рекомендуется хорошо знать структуру проекта и логику именования его модулей.

Использование `--sonar-default-project-filter` обеспечивает более точный контроль над тем, какие части проекта подвергаются анализу качества кода при интеграции с SonarQube, тем самым улучшая эффективность анализа и позволяя разработчикам сфокусироваться на наиболее значимых аспектах кодовой базы.


НЕ ОПЦИЯ

Система SonarQube предоставляет функции для фильтрации проектов и управления ими. Если вам нужно задать фильтр по умолчанию для проектов в SonarQube, обычно это осуществляется через интерфейс настроек проекта в веб-интерфейсе. Вот как вы можете это сделать:

1. **Войдите в Веб-Интерфейс**: Войдите в ваш аккаунт SonarQube через браузер.

2. **Панель Администрирования**: Перейдите в раздел администрирования SonarQube.

3. **Фильтры**: Найдите раздел 'Фильтры' или 'Filters' в настройках.

4. **Создание/Настройка Фильтра**: Вы можете создать новый фильтр или настроить уже существующий, указав критерии для отображения проектов по умолчанию. Это может включать конфигурацию по ключевым словам, статусу качества, датам анализа и другим параметрам.

5. **Сохранение Фильтра**: После того, как вы настроите критерии, сохраните фильтр. Он будет применяться для отображения списка проектов в соответствии с заданными параметрами.

6. **Использование по Умолчанию**: Если вы хотите сделать созданный фильтр фильтром по умолчанию для всех пользователей, нужно убедиться, что существует такая опция в SonarQube и её можно активировать.


Опция `-N=SONAR_PROPERTIES` или в полной форме `--sonar-property=SONAR_PROPERTIES` в системе сборки `ya make` предназначена для настройки анализа кода инструментом SonarQube во время выполнения тестирования или любого другого процесса анализа, инициированного через `ya make`. 

Эта опция позволяет задать одно или несколько дополнительных свойств, которые будут переданы в SonarQube в качестве параметров конфигурации анализа.

SonarQube — это комплексное решение для непрерывного анализа качества кода, которое позволяет обнаруживать различные типы проблем в исходном коде, как ошибки, уязвимости, потенциальные оптимизации, “запахи кода” (code smells) и др.

Как это работает:
Во время запуска `ya make --sonar`, когда активируется анализ SonarQube, опция `--sonar-property` используется для передачи дополнительных параметров или настроек непосредственно в SonarQube. Это позволяет точно настроить или изменить поведение анализатора для текущего запуска.

Формат опции:
\-N=name\[=val\] или --sonar-property=name\[=val\]
Здесь:
\- `name` — имя свойства, которое вы хотите задать или изменить.
\- `val` — значение этого свойства. Если значение не указано, используется `"yes"` по умолчанию.

Можно указать несколько свойств, разделив их пробелами и используя кавычки для обертывания всей последовательности, или же повторяя опцию для каждого свойства отдельно.

Пример использования:
ya make --sonar --sonar-property=“sonar.exclusions=**/test/** sonar.language=java”
Эта команда укажет SonarQube исключить из анализа все файлы, находящиеся в директориях `test` любого уровня вложенности, и задать основной язык проекта как Java.

Или так:
ya make --sonar -N=sonar.exclusions=**/test/** -N=sonar.language=java

Почему это важно:
\- **Гибкость анализа**: Позволяет индивидуально настраивать анализ SonarQube под конкретные требования проекта, увеличивая его эффективность и релевантность результатов.
\- **Исключения и фильтрация**: Возможность исключать из анализа нерелевантные части кода уменьшает “шум” и сосредотачивает внимание на важных участках кода.
\- **Конфигурация на уровне запуска**: Не требует изменения основного файла конфигурации SonarQube для внесения временных или проектно-специфичных изменений.

Важные моменты:
\- **Понимание параметров**: Необходимо знать доступные свойства и их возможные значения для корректной конфигурации SonarQube.
\- **Документация SonarQube**: Желательно ознакомиться с официальной документацией SonarQube для понимания всех поддерживаемых свойств и их влияния на процесс анализа.
\- **Взаимосвязь параметров**: Некоторые параметры могут взаимодействовать друг с другом, что следует учитывать при их настройке.


Опция `--sonar-do-not-compile` в системе сборки `ya make` используется во время подготовки к анализу кода инструментом SonarQube и сообщает системе о пропуске этапа компиляции Java исходных кодов. При использовании данной опции не требуется компилировать Java файлы проекта перед его анализом SonarQube. Как следствие, свойство `-Dsonar.java.binaries`, обычно указывающее на расположение скомпилированных классов Java, не будет автоматически настроено в процессе запуска анализа.

Как это работает:
Обычно, для анализа качества кода SonarQube требует указания местоположения скомпилированных бинарных файлов Java классов, это делается через свойство `sonar.java.binaries`. Однако, в некоторых сценариях, особенно когда анализируется только статический код и не требуется проверка байт-кода, компиляцию можно пропустить. Опция `--sonar-do-not-compile` позволяет обойти шаг компиляции, уведомляя систему сборки и SonarQube о том, что бинарные файлы не будут использоваться в данном запуске анализа.

Пример использования:
ya make --sonar --sonar-do-not-compile
В данном случае, `ya make` запустит анализ SonarQube без предварительной компиляции Java кода, и свойство `-Dsonar.java.binaries` не будет установлено.

Зачем это нужно:
\- **Быстрота анализа**: Пропуск шага компиляции может значительно ускорить процесс анализа, особенно для больших проектов.
\- **Фокус на статическом анализе**: Если интерес представляет только статический анализ исходного кода (например, проверка стиля кодирования, наличие “запахов” кода и т.д.) без анализа байт-кода, компиляция не требуется.
\- **Проблемы с компиляцией**: В случае сложностей с компиляцией проекта или когда компиляция невозможна из-за внешних зависимостей, данная опция может обеспечить возможность анализа кода без необходимости решать все проблемы сборки.

Важные моменты:
\- **Ограниченный анализ**: Пропуск компиляции исключает возможность анализа байт-кода, что может уменьшить глубину и полноту анализа SonarQube.
\- **Настраиваемость SonarQube**: Необходимо учитывать, что для некоторых проверок или метрик SonarQube может потребоваться доступ к скомпилированным классам. В этом случае, такие проверки не будут выполнены.
\- **Конфигурация SonarQube**: При использовании данной опции могут потребоваться дополнительные настройки SonarQube для корректного анализа, включая настройку источников кода, путей к тестам и так далее.

Использование опции `--sonar-do-not-compile` дает гибкость в процессе анализа кода, позволяя сосредоточиться на статических аспектах качества кода без необходимости компиляции, но следует учитывать потенциальные ограничения и адаптировать настройки SonarQube под конкретные требования анализа.


Опция `--sonar-java-args=SONAR_JAVA_ARGS` в контексте системы сборки `ya make` используется для тонкой настройки параметров Java Virtual Machine (JVM), на которой будет запущен сканер SonarQube в процессе анализа кода. Эта опция позволяет передать дополнительные аргументы и свойства JVM непосредственно к процессу сканера SonarQube, тем самым влияя на его работу и поведение.

SonarQube — это платформа для непрерывного анализа качества кода, которая помогает разработчикам находить и исправлять различные проблемы в коде на ранних стадиях разработки. Сканер SonarQube является ключевым компонентом этой системы, анализирующим исходный код на соответствие заранее установленным правилам и стандартам качества.

Как это работает:
При запуске сканера SonarQube через `ya make`, JVM, на которой выполнится сканер, можно настроить, передав дополнительные параметры для оптимизации работы JVM, управления использованием памяти, режимом сборки мусора и другими аспектами выполнения Java-приложений.

 Формат опции:
–sonar-java-args=“аргумент1 аргумент2 … аргументN”
где `аргументы` — это строки, содержащие параметры запуска JVM, такие как параметры памяти (например, `-Xmx512m`), свойства системы (например, `-Dproperty=value`) и другие флаги командной строки JVM.

 Пример использования:
ya make --sonar-java-args=“-Xmx512m -XX:\+UseG1GC -Dsonar.verbose=true”
В этом примере:
\- `-Xmx512m` устанавливает максимальный размер кучи (heap) для JVM в 512 мегабайт, что может быть полезно для анализа больших проектов.
\- `-XX:+UseG1GC` включает сборщик мусора G1, который может улучшить производительность сканера в некоторых случаях.
\- `-Dsonar.verbose=true` включает режим подробных сообщений для сканера SonarQube, что может быть полезно для диагностики проблем с анализом.

 Зачем это нужно:
\- **Оптимизация производительности**: Настройка параметров JVM позволяет оптимизировать производительность сканера SonarQube, особенно при работе с крупными проектами.
\- **Управление потреблением ресурсов**: Адекватное управление использованием памяти и настройка сборки мусора могут помочь избежать проблем с производительностью или сбоями из-за нехватки ресурсов.
\- **Диагностика и отладка**: Включение подробного логирования и других параметров может помочь в разрешении проблем с анализом кода.

 Важные моменты:
\- Необходимо ознакомиться с документацией по доступным параметрам JVM для выбора корректных аргументов в зависимости от используемой версии Java.
\- Стоит быть осторожным с увеличением лимитов памяти, так как это может повлиять на общую производительность системы, особенно при ограниченных ресурсах.
\- Изменения, вносимые через `--sonar-java-args`, могут иметь широкие последствия для работы сканера SonarQube и должны быть тщательно протестированы.


Опция `--get-deps=GET_DEPS` в контексте системы сборки `ya make` используется для компиляции и сбора всех зависимостей текущего проекта и их последующего копирования в указанную директорию. Это особенно полезно для сценариев, когда требуется собрать все необходимые зависимости в одном месте на цели распространения кода, архивации или создания изолированной среды для деплоя или тестирования.

Как это работает:
Когда вы работаете над проектом, особенно в большом и сложном, он может зависеть от множества внешних библиотек, модулей или других проектов. `ya make` с опцией `--get-deps` позволяет автоматически определить все эти зависимости, скомпилировать их при необходимости, и собрать выходные файлы (например, JAR для Java) в одной целевой директории.

Это упрощает управление зависимостями, предоставляя полный набор всех необходимых ресурсов для работы проекта, что является ключевым фактором для обеспечения его переносимости и корректной работы в различных средах исполнения.

 Формат опции:
\--get-deps=путь/к/целевой/директории
где `путь/к/целевой/директории` — это путь к директории, в которую будут скопированы все найденные и собранные зависимости.

 Пример использования:
ya make -t --get-deps=./dependencies
В этом примере все зависимости проекта будут собраны и помещены в директорию `./dependencies` относительно текущего расположения в файловой системе.

Зачем это нужно:
\- **Создание архивов зависимостей**: Упрощение процесса сбора всех внешних и внутренних зависимостей проекта в одном месте для архивации или распространения.
\- **Деплой и развертывание**: Предоставление полного набора необходимых зависимостей для деплоя проекта в новой среде или на другой машине, где нет доступа к общим системам управления зависимостями.
\- **Изоляция среды**: Создание полностью изолированной среды, содержащей все необходимые зависимости, для тестирования или других нужд разработки.

 Важные моменты:
\- **Производительность**: Процесс сбора всех зависимостей может занять значительное время, особенно для крупных проектов с большим числом зависимостей.
\- **Актуальность зависимостей**: Следует убедиться, что все собранные зависимости актуальны и соответствуют требуемым версиям, определенным в проекте.
\- **Управление дубликатами**: При сборе зависимостей в одну директорию может возникнуть проблема дублирования файлов, особенно если разные зависимости включают одни и те же библиотеки или модули.


Опция  кажется уже встречалась, перепроверить было ли в контексте тестирования

Опция `-s` или в расширенной форме `--sources` в контексте системы сборки `ya make` используется для создания JAR-файлов, которые содержат не только скомпилированный байт-код Java классов, но и исходный код этих классов. Эта опция применяется в процессе компиляции и сборки Java-проектов и является особенно полезной для библиотек, которые будут использоваться другими проектами или разработчиками.

Как это работает:
При сборке Java-проектов `ya make` по умолчанию создает JAR-файлы, содержащие скомпилированные классы. Опция `-s` или `--sources` указывает системе сборки также включать в JAR-файл исходный код соответствующих классов. Результатом работы является JAR-файл (или файлы), где в одном архиве совместно расположены и скомпилированный байт-код, и исходные Java-файлы.

Пример использования:
ya make -t -s
или
ya make -t --sources
Эта команда проинструктирует `ya make` собрать проект таким образом, что в результате созданы JAR-файлы будут содержать как скомпилированные классы, так и исходный код.

Зачем это нужно:
\- **Документация и изучение кода**: JAR-файлы с исходным кодом упрощают понимание и изучение кода библиотек, так как разработчики могут просматривать исходный код непосредственно в своей среде разработки (например, в IDE как IntelliJ IDEA или Eclipse), не покидая контекста работы.
\- **Удобство отладки**: Наличие исходного кода в JAR-файлах делает процесс отладки более эффективным, поскольку разработчики могут прослеживать выполнение кода через исходные файлы, лучше понимая логику работы и быстрее находя ошибки.
\- **Лицензирование и распространение**: Для некоторых видов лицензий на программное обеспечение требуется предоставление исходного кода вместе с бинарными файлами, что также упрощается за счет создания JAR-файлов с исходниками.

Важные моменты:
\- **Размер файлов**: Стоит учитывать, что JAR-файлы, содержащие и исходный код, и скомпилированные классы, будут иметь больший размер по сравнению с обычными JAR-файлами, что может повлиять на время скачивания и использования дискового пространства.
\- **Безопасность**: При распространении JAR-файлов с исходным кодом важно учитывать потенциальные риски безопасности и приватности, связанные с предоставлением исходников.
\- **Компромисс между доступностью исходного кода и его защитой**: При работе над закрытыми или коммерческими проектами может потребоваться найти баланс между доступностью кода для отладки и необходимостью его защиты.

Использование опции `-s` или `--sources` обеспечивает добавленную стоимость к JAR-файлам за счет включения исходного кода, упрощая процессы отладки, изучения и соблюдения лицензионных требований.


